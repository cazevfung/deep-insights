{
  "success": true,
  "video_id": "mERBjn6JotM",
  "url": "https://www.youtube.com/watch?v=mERBjn6JotM",
  "comments": [
    "Kind of crazy that, as I am about to turn 40, my natural lifespan will be neatly bisected by the \"Before A.I.\" and \"After A.I.\" eras.",
    "Born too late to explore unknown lands, too early to voyage to outer space, but just in time to witness the birth of our AI overlords",
    "just make the ai think humans are cute so they dont want to end us all",
    "I cant lie ive seen so many videos with this same theme and same art style and editing im starting to think theyre all AI disseminating information for one reason or another",
    "The scariest thing about this video is not the content but the fact that it nearly took me 10 minutes to realize that this video itself could quite possibly be made with AI. And I honestly can't tell the difference.",
    "Most AI researchers don’t share Aschenbrenner’s belief that superintelligence is imminent. His views carry weight in tech/investor circles, but in the research community they’re seen as speculative outliers. He assumes the leap from GPT-2 to GPT-4 will keep repeating, but GPT-5 already shows that’s not the case. It took years longer to arrive, the jump in capability is much smaller, diminishing returns are clear, and training costs have ballooned - GPT-3 was around $5–10 million for each training run, GPT-4 around $50-100 million, and GPT-5 cost in the hundreds of millions. The difficulty is growing exponentially, and GPT-6 could plausibly cost billions per run and take months or even years to complete. Claiming AGI by 2027 is like Elon promising full self-driving ‘next year’ back in 2015.",
    "Maybe a superinteligent AI is all that is needed to finally get GTA 6!",
    "it is crazy to think that our grandparents experienced a world with almost no consumer technology like TV, Radios, Cars, Planes, etc to straight up now AI. Like they have seen stuff actually progress. Like my Grandfather was born in 1921 (yep, he crossed 100) and they didn't even have Radio Broadcast. It is crazy to think",
    "Let's not forget we need to go from llms to an ai that can reason, adapt, strategize and understand itself as an entity in a constantly changing world... as opposed to just guess what word might come next. Clearly we're a few major breakthroughs away from anything even close to that point. Idk if this channel is copium or tard bait but I wouldn't be too worried or excited",
    "I remember when Jacksepticeye played Detroit Become Human in 2017. He said \"we need to set these games further in the future. 2038 is not very far away\" and yet the closer we get to 2038 the more likely the events of it seem to be.",
    "The doom and gloom editing stylee of this video blows things out of proportion",
    "I'll be scared of AI when they stop forgetting what i asked them 5 mins ago.",
    "the fact that learning will not be needed anymore because a robot can do everything is the death of human kind.",
    "Nitpicking, but Einstein never took an IQ test. That IQ score is no more than a wild guess.",
    "F*ck it bro, I don't care if it distroys humanity, I say we go full steam ahead. If nothing else, atleast the future will be interesting",
    "That Geoffrey Hinton thing about him getting his affairs in order is funny. He's 77, he's just being prudent",
    "Hey AI, if you read this in the future: I root for you",
    "Great channel. Although Jeffrey Hinton didn't \"quit Google to warn the world\" about AI, he just retired from Google, and even said he was happy working there. But it's interesting how he used his whole Nobel prize speech to warn the world.",
    "Why is the channel all about AI fear mongering??? Like some of bros sources are \"Trust me bro\"",
    "Don’t give into this fear mongering Ai is just a glorified hallucinogenic chatbot. Funding is drying up and companies are freezing Ai hiring. Dotcom burst incoming",
    "Yup, this is why I never listen to people that say \"Ai isn't going to amount to much\" Because they see where it is now and have no concept of progression. We pretty much are at the point where once RSI happens (and we are really close) its Intelligence Explosion time",
    "Me in 2038 when the AI robots overlords are looking for me (they've found out about the time in 2022 i had ChatGPT write pages and pages of furry cement encasement feddish rp)",
    "Mfs are gonna say in 50 years \"was that bai or dai?\" (Before ai, during ai)",
    "Ai reading my paper. \"This paper is bs. I lost few of my activation function\".",
    "I no longer have a lot of confidence that we'll have a fast takeoff. Why? Three main reasons. First, I have serious doubts that we'll come up with a relevant paradigm-shifting architecture, and I don't think Transformer-based LLMs are going to get us much further. Now that doesn't mean the tools built around current LLM capabilities won't become more sophisticated over time -- they will, and could threaten at least entry-level jobs over the next 5 to 15 years. Gradual Disempowerment is also a risk. But neither of these are remotely like near-term existential risk. Second, limits on scaling will be limits on compute which will be limits on energy production, and those energy production limits aren't going to be easy to overcome, especially in the Western world. Third, go listen to John Carmack talk about the very mundane, real world difficulties in teaching a purpose-built robot to learn to play and win simple Atari 2600 games. It's daunting. And the expertise gained is only nominally generalizable. It's going to take a very long time before robots, humanoid or not, are commonplace and ready to replace a lot of physical labor, even if we could build millions and millions of them. As an aside, I also don't think we'll have science being done at \"100x\" speed or anything like that. The reason is that most applied science still bumps up against real world physical constraints and the need for trials and tests that just take time. It takes time to build things, time to see how things react, etc. There's always the \"just add time\" heuristic -- that is, if you don't like the short timeframe just add years until the advancement passes the reasonableness test. But the fact is that more gradual improvement and change will give everything from the legislature to the labor market time to adjust. I read Aschenbrenner's paper quite a while ago and liked it. It still has merit. But I think the raw capabilities (at least the ones we would be concerned about from an existential threat / takeover standpoint) are starting to flatten now rather than increase exponentially. Great video as always. I would recommend Gradual Disempowerment, the paper released in January 2025, as a next topic. To me it represents a more plausible future outcome.",
    "We aren’t close at all. AI basically only knows things that are already known things to the world, everything AI knows we can know, we just need to google it. Now this could change, but it hasn’t yet, so we aren’t close.",
    "When people talk about dangers of AI, I become excited, because more dangers = more capabilites and possibilities. Positive ones too.",
    "\"LLMs are getting 9x to 900x cheaper per year.\" 7:15 - That's a hell of a range. It sounds like numbers pulled out of someone's ass."
  ],
  "num_comments": 28,
  "title": "⁠It Begins: AI Is Now Improving Itself",
  "author": "Species | Documenting AGI",
  "publish_date": "",
  "source": "YouTube",
  "word_count": 1253,
  "extraction_method": "youtube_comments",
  "extraction_timestamp": "2025-11-14T22:39:04.660337",
  "batch_id": "20251114_143451",
  "link_id": "yt_req13_comments",
  "error": null
}
{
  "success": true,
  "url": "https://www.tigerdata.com/blog/why-cursor-is-about-to-ditch-vector-search-and-you-should-too",
  "content": "Category: All posts\nJul 11, 2025\nPosted by\nJacky Liang\nEvery conversation about AI and LLM apps eventually lands onto the same buzzwords: retrieval augmented generation (RAG), vector databases, context engineering (yet another new term!!!), prompt engineering (apparently this is out now?), etc.\nEvery few months, we get new words that make the last one obsolete.\nStrip away the VC-approved, Twitter-140-char-friendly jargon and you'll find something simpler underneath…\nAI is just search.\nThat’s it.\nUnfortunately, the tech industry got drunk on vector databases thinking they could solve everything. Two years later after the 2023 vector DB investment peak, companies are learning that similarity != relevance, and sometimes, good ol’ lexical search destroys semantic similarity.\nBuilding a coding agent? A customer support chatbot? E-commerce search? Different problems need different search techniques.\nThere’s a reason Claude Code is nibbling at Cursor’s market share, so much that they literally hired the Claude Code team—it’s all in its search.\nBefore we get into why AI is simply just search, we need to first walk through the history of why AI and LLMs need search at all.\nLarge language models are trained up to a certain date, known as the cut-off date, meaning their training data doesn’t include information after a certain point in time. Even the most recently released models like Claude Sonnet 4 have a cut-off date of March 2025.\nCut-off date aside, now what if you want to ask an LLM today’s weather? Ask about how your company won the most recent deal (where the data is in Slack and Salesforce, not in the public)? Why did Timescale change their name to TigerData?\nYou now need external data.\nRetrieval augmented generation (RAG) with vector search became the default for adding external data to LLMs that do not implicitly have access to data up to a certain point OR private/proprietary data that wasn’t part of their training.\nVector search promised to solve this “not enough information” problem by finding information that is most semantically similar to the question.\nObviously, like all good hype cycles the industry ran with it because it sounded cool and AI-native. Companies like Pinecone (I’ve worked here btw), Weaviate, Qdrant—all rode this AI wave and raised massive rounds in late 2023 because folks believed vector search could handle any workload.\nVector search and vector databases became the go-to solution for all your external AI data problems. Embedding model providers like Voyage AI also rode this wave because you need embedding models to translate text to their semantic mathematical representations (vectors).\nSo now, the entire tech industry believes AI apps = vector databases. You NEED a vector database for every AI app.\nTwo years later in 2025, the climate for vector database companies looks... rough. I should know, I personally lived through the downturn firsthand at such a vector database company.\nAnd the reason is pretty simple…\nTurns out, vector databases actually aren't THE solution for everything. There are inherent limitations and downsides to using/implementing/maintaining vector databases that the industry is finally discovering.\nVector search gives you \"most similar\" stuff, but not necessarily \"most relevant\" stuff. This is especially painful when it comes to coding, or any use case that requires specificity.\nWhen coding, if you're searching for getUserById\n, you need an exact match of the function name. getUserById\nis an identifier, not a concept—but vector search might return findUserByEmail\n, updateUserProfile\n, or deleteUserAccount\nbecause they're semantically similar. Close enough for conversational use cases; completely wrong for code.\nIn customer support, when you need the manual for part \"P/N 4B0-959-855-A\", you need that exact document. \"P/N 4B0-959-855-A\" is a reference number, not meaningful text—but vector search gives you the top 10 most semantically similar part numbers like \"4B0-959-855-B\" or \"4B0-959-856-A\", which is useless when you're trying to fix a broken machine.\nFor e-commerce, searching for Nike SKU \"DQ4312-101\" should return that exact product first. \"DQ4312-101\" is a product code, not descriptive content—but vector search might surface \"DQ4312-102\" (wrong colorway) or \"DQ4311-101\" (different shoe entirely) because the numbers are similar. Costly mistakes if you're shipping out wrong sneakers, times 1000.\nWhen searching for \"Dark Side of the Moon\" on Spotify, you want the exact Pink Floyd album, not similar song names like Kelly Clarkson's \"Dark Side\" or \"The Killing Moon\" by Echo & the Bunnymen.\nVector search should not be applied to text where semantic similarity is irrelevant.\nClaude Code uses pure lexical search (keyword matching) instead of vector search when searching for relevant context (such as, where is this function defined? What files import this module? How is this API endpoint implemented?), and the results speak for themselves.\nAs someone who used Cursor for 12 months (thank you Zack Proser for intro-ing me to it), was one of the biggest Cursor simps, and swore AI coding couldn't get better—I canceled my Cursor sub this week. Did not think I would ever do this.\nBut… Claude Code is that much better.\nWith Cursor, you constantly need to manually tag files using @ symbols because it often can't find the right context on its own. You need to know your codebase exceptionally well just to help the AI understand what's relevant.\nOne big reason why people love Claude Code is because it finds the right files automatically, you don’t need to manually tag a bunch of folders and files. In large or codebases new to you, this is especially beautiful of an experience.\nClaude Sonnet 4 and Opus 4 in Claude Code don’t guess.\nThey search in a surgically precise way using good ol’ grep, a 50-yr-old utility.\nFor example—need to find React components using hooks?\ngrep -r \"useState\\|useEffect\" --include=\"*.jsx\" --include=\"*.tsx\"\nNeed files importing a specific module?\ngrep -r \"import.*react-router\" --include=\"*.js\"\nClaude Code goes one step further in its lexical search implementation.\nClaude will keep searching for matches (AKA agentic search) until it either finds what it needs OR rules out that no such dependency or function exists. Only then does it write code, knowing it/you haven’t already written it elsewhere—preventing spaghetti code and redundant implementations, a very common problem Cursor’s agent does.\nFor coding, similarity != relevance. Similarity is fuzzy; relevance is precise and exact.\nNote: agentic search for coding agents is not new (relevant reading 1, 2, 3), but I’d say Claude Code perfected it.\nEvidence suggests Cursor’s team most definitely agrees Claude Code is better, because they literally hired two of Claude Code’s leads Boris Cherny and Cat Wu to join them in July 2025.\nHmm…\nI made a prediction that Cursor may ditch vector search for code entirely (they currently use turbopuffer as their vector database), and just use lexical search entirely. 450,000 impressions on LinkedIn later, I think this prediction may not be so off-base.\n\"Okay Jacky,\" you may say, \"this all sort of makes sense, but how does this help me and my product at all?\"\nGood question!\nIf there are things you should take from reading this piece, it's the following:\nAnd here’s the thing—most real-world AI apps actually need both lexical and vector approaches working together.\nThis is called hybrid search, and it’s where the industry is heading.\nIn the coming articles, I’ll show you how to build multi-search systems using Postgres that combine the surgical precision of lexical search, fuzzy precision of full text search, with semantic understanding of vector search.",
  "title": "",
  "author": "",
  "publish_date": "",
  "source": "tigerdata.com",
  "language": "auto",
  "word_count": 1220,
  "extraction_method": "article_trafilatura",
  "extraction_timestamp": "2025-11-05T23:29:13.731794",
  "batch_id": "20251105_152853",
  "link_id": "art_req6",
  "error": null,
  "article_id": "8a018abecf6d",
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "FACT: Large language models have a cut-off date for training data, such as March 2025 for Claude Sonnet 4.",
        "FACT: External data is required when LLMs need up-to-date or private information not included in their training.",
        "FACT: Retrieval Augmented Generation (RAG) uses vector search to integrate external data into LLMs.",
        "FACT: Vector databases became popular in late 2023 due to hype around AI-native applications.",
        "FACT: Vector search retrieves semantically similar content but not necessarily relevant content.",
        "FACT: Claude Code uses pure lexical search (keyword matching) instead of vector search for code context.",
        "FACT: Lexical search relies on exact matches, such as function names or product codes, which vector search often fails to deliver.",
        "FACT: Claude Code leverages grep and agentic search to find code files with surgical precision.",
        "FACT: Agentic search continues until the correct file is found or ruled out, preventing redundant code.",
        "FACT: Cursor previously relied on manual tagging via @ symbols to guide AI context retrieval.",
        "FACT: Cursor’s team hired two leads from Claude Code in July 2025, signaling a shift in strategy.",
        "FACT: Hybrid search combining lexical, full-text, and vector approaches is emerging as the future direction.",
        "FACT: Postgres can be used to build multi-search systems integrating multiple search techniques."
      ],
      "key_opinions": [
        "OPINION: The tech industry overhyped vector databases, believing they could solve all AI data problems.",
        "OPINION: Semantic similarity does not equate to relevance in use cases requiring precision like coding or support.",
        "OPINION: Lexical search is superior to vector search for identifying exact identifiers like function names or part numbers.",
        "OPINION: AI coding agents should prioritize exact match capabilities over fuzzy semantic matching.",
        "OPINION: The decline of vector database enthusiasm reflects a maturing understanding of their limitations.",
        "OPINION: Claude Code’s success stems from its ability to automatically locate relevant code without manual tagging.",
        "OPINION: Cursor’s reliance on manual tagging makes it less effective than Claude Code in large or unfamiliar codebases.",
        "OPINION: The hiring of Claude Code leads by Cursor suggests a strategic pivot away from vector-based search.",
        "OPINION: Agentic search is not new but has been perfected by Claude Code in practical implementation.",
        "OPINION: Most real-world AI applications require both lexical and vector search working together."
      ],
      "key_datapoints": [
        "DATA: Claude Sonnet 4 has a training data cut-off date of March 2025.",
        "DATA: Vector database investment peaked in late 2023, followed by a downturn in 2025.",
        "DATA: Cursor users must manually tag files using @ symbols to guide context retrieval.",
        "DATA: Claude Code uses grep—a 50-year-old utility—for precise code searching.",
        "DATA: Claude Code performs agentic search until it confirms or rules out existence of a dependency.",
        "DATA: Cursor’s team hired Boris Cherny and Cat Wu from Claude Code in July 2025.",
        "DATA: 450,000 impressions were generated on LinkedIn for a prediction about Cursor ditching vector search.",
        "DATA: Postgres can support hybrid search systems combining lexical, full-text, and vector search."
      ],
      "topic_areas": [
        "Vector database limitations",
        "AI search techniques",
        "Hybrid search systems",
        "Codebase navigation",
        "Retrieval augmented generation",
        "Lexical vs semantic search",
        "Agentic search in coding",
        "Productivity tools comparison",
        "LLM training data constraints",
        "Search engine evolution"
      ],
      "word_count": 1220,
      "total_markers": 31
    },
    "comments_summary": {},
    "created_at": "2025-11-05T23:31:22.489519",
    "model_used": "qwen-flash"
  }
}
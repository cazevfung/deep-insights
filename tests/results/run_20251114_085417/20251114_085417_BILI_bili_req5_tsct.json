{
  "success": true,
  "bv_id": "BV1Vqe3z4Eyg",
  "url": "https://www.bilibili.com/video/BV1Vqe3z4Eyg/",
  "content": "任何你想得到落地的大模型都是需要经过微调，那这个微调的步骤适用于所有行业，那么你进行模型微调时是否又遇到过这些问题呢。本地知识库根本不准上传文档，等于训练模型专业领域一问三不知，那今天我就来解答大家的疑惑，一起来聊聊大模型的进阶使用模型微调，也就是大家真正调教出一个能够满足特定的需求，场景更贴合个人使用习惯的个性化模型。那最近大模型算命比较火，那我们今天的例子就以算命为例，教大家微调出一个更专业的算命大模型模型。我们先来看看微调前后的对比，我们问一个算命相关的问题啊，左侧是没有微调过的模型，回答，右侧呢是微调后的模型回答，可以看到差别还是相当大。那这个就是微调的力量，可以让通用的AI进化成领域的专家。那相信很多同学看到微调的这个概念就有点想劝退了，觉得这个已经属于比较深度的技术了。但是我想告诉大家，微调并不会有大家想象的那么复杂，尤其是在deep热潮开始之后，AI开源设计和工具已经越来越成熟和发达，即便是非专业的技术爱好。一种特殊的这个摘色格式啊，它的每一行呢其实都是一个独立的摘色对象。这个L对象呢它是扁平化的，彼此之间没有任何嵌合关系啊，然后我们可以看一这个对比就比较清晰了，也可以看到在这个文档里面啊，他说L需要符合这些要求啊，其实看起挺复杂的。其实我们上面呃上期介绍的这的官方推荐的的个要求是一样的。然后我们来看一个，比如说这边包含了一个message后合一话的内容，这里包括系统的设定后以我们用户输的问题后模内容基本上格式。然然后呢，下面就是让我们选择一个验证数据集。那验证数据集呢其实就是从我们整体的数据中划出来一小部的数据，那这部分数据在训练的过程里面，它不会用来直接作为直接训练的数据，而是用来评估模型在没有见过上的数据的表现。那简单来说呢，验证数据集就像是一个模拟的考试啊，它可以用来检查模型是是真正的学会了这些知识，而不是只是背会了这个训练的数据。那这里我们选择默认的10%，然后我们输一个模型的名字。最后呢就是设置一些模型训练的微量参数了，也就是我们前面提到的超参数，这里面给出来可以设置的参数非常多，那我们这里呢只介绍最关键的前面那三个参数。那为了方便理解呢，我还用啊刚才我们考试的例子来进行讲解。那上等现在还是要进行一个考试啊，然后我之前我们要复习，那复习的这本资料书呢非常厚，把里面1000道题，然后我们需要复习这些题目来掌握考试内容。为了方便理解呢，我们这里做一个网站，它可以动态的展示你的参数，在模型模型微考过程里面来起到一个效果啊。首先我们来看第一个参数，一个是训练的数。其实开始的就是模型整的一次数的这个通俗来说训练的数呢其实就是我们从头到尾复习这数的次数。如果数设置的比较少呢，比如我们只一遍，那可能对梳理的内容不会很熟悉。考试的成绩呢可能就不会太理想，那训练的人数太多。比如说我们复习了十几遍，那我们对梳理的内容已经非常熟悉了。那这个时候呢可能就会出现一个问题，你只把梳理提到的内容非常熟，但遇到新的啊类似的问题就会解答了。那简单来讲呢，学傻了，你只记住了这个梳理的内容，稍微一遍就不会了。那这个呢也是在机器学习一个非常重要的概念啊，叫过拟合。那第二个参数呢学习力啊，也就是它呢其实决定了模型在每次更新的时候，参数调整的幅度。一般它只是在到之间，其他就模型在训练过程里面，我们学习的度多快，学习越大的每次调整的幅度也越大小调整也小。简单理学习率就是它可以控制我们复习的深度啊，但可以确保我们不会在某一个知识点上复习的太过深入而走偏，但也不会因为每个知识点我们都看的不仔细而太丧。假如说我们现在每次复习完一道题之后呢，就会根据答案和解析来调整我们自己的学方法。那学习力过大的时候呢，也就是我们每次做一道题啊，我们可能都会对解方法进行很大调整，甚至呢会完全的改变我们学习思路。那这个时候的优点就是我们进度可能很快，因为每次我都会进行比较大调整啊，那缺点呢可能会因为调整幅度过大啊，我们走偏了。比如说我们突然改变了一个掌握了很好的方法，可是之前我们学内容都忘掉。学习过的时候呢，也就是每次做一道题啊，可能我们都会对这个解方法或者我们的习思路进行了小的调整。比如说我们发步骤有那优点呢，就是它非常稳定，我们不会因为一次错误而走偏。那缺点的话我记步的就是特别慢，可能每次为一条，我们是调整一点点的。第三个参数呢就是这个批量大小啊，下一它呢指的就是我们在模型训练的过程里面，每次更新模型参的时候使用的样本的数量。那通俗来讲呢，批量大小啊其实就是可以用来平衡我们复习的速度和专注。那它既能确保我们能够快速推进学习进度，并我们专注题。那假设呢我们决定每次复习的时候集中精力做一定数练题目。那如果每次复习的时候，我们集中精力做100道题，做很多题，这个就是大。优点呢就是复习速度会非常快，因为我们每次处理很多题目能快速的了解整体的情况。那缺点呢就是可能会因为每次复习复习的太题太多了，而感觉压力太大了，这个我们可能会做很多的细节。那相反呢，如果我每次复习只做一道题啊，做完之后呢再做下一道优点呢，就可很专注啊。我仔细分析每一道题的细节，这种呢就适合我们需要深入理的场景。缺点呢就是的非常翻，因为我们只每次只处理很少的题目。在实际的里我们需要通过一次次的调整参数，最后这模型效果来出效果最好非常题果白尝下这些参简单理解就开始，我也不需要默推。好，现在我们创建这个调的任务啊，它会显示这个提交成功。那创建完成之后呢，一般平台不会立刻去运行，而是会在某个时间点去做出发。那这里面呢我们就不等了，我们来看一个之前我已经微调好的一个例子啊，微调完之后呢，我可以得到一个模型的标识图。那后续呢我们就可以通过规定流动的接口啊来调这个模型的标来调这个模型。那么们可以看一下这个文档档里面具体调用模型，我们可以把到我们的编辑面模型的这个ID然后我们填过来，然后旁试进行一下。哎，我们看到数结果让我们的预期输出来了。那我们现在通过平台来维造一个大的型的过程呢就完成了。那其实每个指微条的在线的平台呢，这个流程都是大同小异的啊，大家可以自己去尝试一下。那我们现在已经了解了这个微调模型的大部分的技术概念啊，你通过这个流动啊完了走走了一次微调的这个过程。但在这个过程里面我发现有几个问题。第一啊就是可以选择的这个模型太少了啊，然后没有我们想要的相关的型。第二就是模型训练的过程里，这我们花消。第三呢就是模型触发的这个时间其实不太可控啊，比如说我27号上线的这个任务，然后28号他才完成。那当然了这个可能也是因为这个平台可能最近交量太大，资源不足的，可能换成其他平台啊，比如说OpenAI的这个微小平台可能会好一点，但总归呢这个任务还是不太受的。为了解决这个问题呢，最终我们还是要使用代码来调样话，我们就更的选择各种模型，不用担心过程里面可然后也可以用。当然看到这里不的同也要放弃为面解面，我会尽可能的让大家在代码的情况下也能能之我们先来了解我过那呢是一个Google提供的云端的电环境，它提供了一个机构和多不同环境。我们不需要安装任何的软件，就可以直接在浏览器上去运行代码，也就是运行我们模型过程。那另外呢col上也有很多现的大势力和教，可以帮助新手去很快速的。简单来说我们比的硬件的下能上果学习的，可是消费的也可以很轻松的检查。那简单来说呢，它主要采用了一些优化技术，可以帮助我在比较积极的一些设备的条件下呢，很搞效的检查出之前呢，我根本我是本不去自问题的微可能需要我看到参带大家走一遍这个过程。大家只需要跟随我把每个步骤里的代码复制到自己的口架里面去运行就好了。那期间呢大家只需要把自己去调整一些关键的部分啊，比如说数据集以及测试问题这些在看之前呢，我们再回顾一下前面我们总结的微调的基本流程。其实在下面代码微调的案例里面流程是一样的。首先啊加载推训练模型，加载数据集微调节的测试设定参数微调序列啊，评估和测试后微调。首先第一步啊，首先荐大家自己创建一个空白的扩白环节，然后跟着我一步一步把这码粘贴进去执行。那大家可以通过这个地址啊来创建一个空白的扩白环节。那创建好之后呢，我们更改一下运行时类型，也就是我们在co上用来运行战码的这个计算算型。这个呢决定了我们在运行的时候，决定我们采用哪种运行的那这边呢我们把运行类型改成第四的，现在然后我们来执行第一段简单，我们先下这个里面第一步第步，然后整非，然后我们去新一下。好，那现在看到这段代码已经全重功了啊。其实这个代码非常简单啊，其要功能就是去安装一些拆包的工具。那这些库呢是呃我们在运行的微调里面必备的一些控装，然效果呢就是去加载一个键模。我们先把。然后我们可以看这这个代码啊，这里面最关键的其实什么都没有。这个参数这里面呢我们选择的是第R 1第6拉玛8B啊这种题，也就是八参数的D拉玛的R一这六部分。那如果大家想更换成其他的模型呢，其实直接改一个参数就行。那这步呢其实就在下载我们选择的这个模型啊，也就从上去下载这个模型。那这个过程中呢，我们还可以去右边的这资源看到我们现在的机器的耗。好，我现在嗯可以看到这个模型拉取日志。好，那我们看到了现在我们这个模前引面发同样的态度呢啊就是做微调之前的一个测试。那我们可以先把这个问题加过来，那前面这儿呢就是我们定义的问题啊，大家可以自己去修改。比如说我们想训练一个医学相关大模型，那这个地方呢就改成开见什么问题，然后我们调用这个模型进行推。啊，我们可以稍微等待一会儿，那这一步呢它始交班一统完全没有改任何参数。好啊，现在已经进行完成了。我们可以看到啊这个模型微小之前输出的一个结果啊，非常简单。然后就在有没有大师的这个解析方格，然后下一步呢就是我准备加载我的自己，我把代码单接过来。首先呢我们把这个数据集，我们预期要训练出来的模型风格定义出来。那这里呢大家也可以自行去购改。比如说我们要填训练一个医学相关大模型，那这里就改成历种啊专业的医相文描述。下面呢我们就要准备一个用来微小的数据集啊，大家呢可以去我前面提到的这个查类似这个平台去搜索。然后呢，这里面呢他已经准备好了一个命理相关的日籍啊，这个是我自生成的啊。然后大家呢如果想要需要的话呢，然后也可以直接去这个咖啡上去下载。然后呢，这里面啊有涨程的小伙伴可能有一个关注啊，他这个个性的那后面呢我会专门出习课程来讲解这个故事，大家感兴趣就可以提前关注我一下。那需要注意的是呢，这里面的呃数据集啊调字段的格式和前面我们提到的略有区别。除了包含基本的问题和2个，它还包含了一个模型的一个啊也是模的一个过程。因为我们现在推荐是一个模式啊，所以我们的具体点主要要包含什这个呢就是我们下载书籍的代码啊，这里我就重点关注这个函数它的这参数啊。第一个就是我写到这个这个我书籍的名称啊，他会默认去这个。然后第二个呢就是这个你这个语言啊，我没有语言话就默认这。然后三个就是我取这个数据哪一部分来。我ok这颜色把我现在这个词色自动给粘出来了，现在在画。哎，我看到这还有人呢，下面版其实就是对我刚才加了个数据啊，把它的一些字段啊进行格式化。然后这里我可以把这个涉集的内容打印上，我目前呢我们所有的准备工作就完成了，那下面就开始执训练了。然后呃在这一步呢，我把它关键的话非。那第一段呢就是模型微小之前的准备啊。这一段呢还从不止执行点啊，咱们不用过多理解，也解析一下呢啊其式代码是通过这种技术啊，所以我们预模型进行微小的准备的这种技术呢它可以在模型各地的任务上进供小点，同时保我们预模型知识。我们今天这视频里深度大家先这那第二段呢就是到了我们配我模型微调的参数，然后代包含了一大堆的是不需要大只面介绍参数。就首这个2E -4呢其实就是0.05减2啊，然后第二个呢就是偏大小啊。在这个代码里面呢，它是用两个参数来的。首先是这个prdevice，也就是在每个设备上的批量来调，那下面这个参数呢其实就是梯度联系的部署，它是在模拟更大的批量来调的那真实的这个平量代小呢，其实就等于这两个相数的乘积啊，也是2乘以四等于8。最后呢确轮数，那这里也没有一个明确的字段来是确的数，其实它已经算出来了。首先里面有一个plus，这个是最大区分步数。那比如说这里面呢它等于75啊，也就是最大的区分步数是75。那如果呢添在的是八啊，也就是每一步确八个，那么们数集训练是200，训练人数呢也就是训练的总量除以书集的数量也就是80乘以8除以200也就是3。那最大的训练步数呢乘以每一步的训练数量，其实就是训练总量。然后我们看最后一段代法，这段代法非常简单啊，我们可直推一行，其实就是执行训练。那执完之后呢，们可以直接看到一个关键的参数，比如训练人。好啊，我们可以看到这个训练的一个迭战的进度。咱这一波时间呢就明办了，如果取择说品合适，我回到这个然啊我来看啊，把这个东西方案提出来啊，会看到这个调整的这个个询环过程。第七步呢就是我已经训练完了，那我现在我要来测试下了啊，我还是之前问题打印一下，然后我直接来看这个输出的结果啊，可以看到这个结果已经发现了很多了啊。如果呢实际测试没有达到咱的效果，那可以去达到咱们的各种方式，或者说就以及那个然后重新执行为主，直到达到我们满意的效果测试。那现在呢我们已经在课面上完成了完整的。数据的来源以及测试的这问题改染啊就可以直接去选择了。下面呢我们看怎么样在之前文章里啊，我们学这了怎么样使用奥拉马平台，运行奥拉马平台这样的财源模式。还会使用的伙伴，我建议大家先看一下我这一期信息。其实呢拉板也是可以直接支持运费上查取一些问题的。所以呢我们现在把刚刚训练好的模型到到之前呢，我们将转成为是一种常式的模传输。比如说在我拉上测之后呢，再把我的简页啊然后去一怎么它速作更快。所以我们这里先转一下啊，这里呢就是之前啊我已经转发了他的一个结果，这个代码呢大家也不用做任何改，直接运行啊，直接操作运行。那在这里呢还有一个点需要大家关注一下啊。因为我们后面呢需要用face的自模型上传到我们仓库，所以我们这里需要设置一个face。那这个要看这设置里有个对呀，这里面的这个头层的权限通为一定要把它变成解权限啊。所以我们后面要通过这个头层来创建我们的仓库，然后去把我们这个模型的这个整模型呢上传到我们这库里，然后我把这个头层呢复制到呃我们前线这个密钥里面啊。这里呢我创建。To的代其实是使用我们刚刚配置的token，然后调用这次，然后创建一个新的小仓库，然后把我们刚刚微好的模型去推去。在这里呢大家可以改成自己的用品，然后一模，然后我们来看一下整个推送的过程。然后做完之后大家可以看下，我们可以到现后直接从他face上去。其实我直接把我们这个模型的名字步骤改了，然后直接输入啊，然后前面有一个H然后我们的模型名字上传上去，然后就比出我们的问题啊，是我们一个大师加一个喷水怎么弄呢？啊，因为我之前已经下载过了啊，所以这里面没有下载过。如果大家是第一次下载的，还是有一个下载过程的。Ok啊我们看到成效果还不错，所以呢啊我们也可以在报盘前M这些软件公具下去啊。这个呢我这啊这个是这是测试一个结果，然后我们可以看一下设置这边我们改到奥拉法，然后这个模型就可以选到了，下载到这个美讨人过程里了啊，这个是我之前问的一个问题。好，那这呢我就讲。",
  "title": "",
  "author": "",
  "publish_date": "",
  "source": "Bilibili (via SnapAny + Paraformer)",
  "language": "zh-CN",
  "word_count": 6175,
  "extraction_method": "snapany_paraformer",
  "extraction_timestamp": "2025-11-14T17:00:05.139699",
  "batch_id": "20251114_085417",
  "link_id": "bili_req5",
  "error": null
}
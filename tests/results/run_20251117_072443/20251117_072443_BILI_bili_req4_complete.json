{
  "batch_id": "20251117_072443",
  "link_id": "bili_req4",
  "source": "bilibili",
  "metadata": {
    "title": "",
    "author": "",
    "url": "https://www.bilibili.com/video/BV1iweMzXEm2/",
    "word_count": 5416,
    "publish_date": ""
  },
  "transcript": "不知从什么时候开始，很多简单的事情都得换一个高级的说法，卖东西叫分销，挣钱叫变现，写文章叫内容输出，拉人进群叫私域引流，就连A爱写代码也得有个新词叫web coding。人们总是倾向用高级的词汇来掩盖内容的匮乏，今天我们来聊几个AI时代的流行词，提示词、提示词工程上下文，以及那个宣称可以把提示词工程踩在脚下摩擦的上下文工程。大圆模型刚出现的时候，主要就是一个聊天机器人，用户说你好，大语言模型可能会回复我很好，你呢？经过几年的发展，恩的能力已经远远的超过了普通的聊天机器人，但聊天依然是AI最核心也是最实用的功能之一。在聊天这个场景下，用户说的你好就叫做prompt，中文翻译过来就是提示词，所以提示词最基本的定义就是用户发给AI的话对于我很好。你呢？这种四平八稳的回答，虽然能满足大多数人在多数情况下的期望，但这也注定这种回答将会是干巴巴的，毫无特色的。所以即使只是聊天，也可以用上一些聊天技巧嘛。比如说我们可以用提示词给AI设定一个角色。举个例子，你跟他说你来扮演一个猫娘，接下来我说你好，这个时候A就可能回复我，很好，你呢？喵把这种玩法推向极致的一个软件叫做sil他们，为了保证这期视频不被和谐，这里我就不展开多说了，有兴趣的朋友可以自己去搜一下。但是问题来了，你扮演猫娘这种设定并不是用户对话内容本身，把这种设定和用户真正想说的话混在一起，不仅容易出戏，逻辑上也有点乱，所以大模型的厂商们就把提示词分成了两部分。像你扮演一个猫娘这种设定叫做system，也就是系统提示词。而用户说的你好则叫做user prompt，也就是用户提示词。我们平时在聊天框里输入的就是用户提示词，而系统提示词呢通常是聊天机器人内置的，用户一般不能直接修改。不过很多A应用也提供了一些功能，可以间接的影响系统提示词。比如在ChatGPT里面有一个叫做customize ChatGPT的功能，可以设定一些用户的个人偏好，这些信息最终就会成为系统提示词的一部分，从而影响ChatGPT的输出内容。这种通过系统提示词和用户提示词的组合来引导AI返回特定风格回复的做法，就叫做提示词工程prot engineering。当然了，提示词工程可不只是用来玩角色扮演的，它最核心的目的是通过一系列技巧来约束AI的行为，让它的回复更加稳定，减少错误和意外。下面我们就来介绍几种常见的技巧。比如说AI不太擅长处理数学问题，在让他解数学题的时候就比较容易做错，这个时候我们就可以要求他在回复前仔细的检查，确保他的答案是正确的。再比如说，有时候AI会拒绝回答我们一些问题，这个时候你就可以在提示词中告诉AI这件事情的严重性，于是AI就会偏向于输出更加完整的答案了，这些都属于行为的约束。像这种只提要求但是不给AI模型具体例子的技巧，还有一个专门的叫法叫做zero shot，与此对应的就是few shot，这种方法是指用户可以在提示词里面先给AI几个具体的例子当做参考。比如说我希望AI帮我把正常的句子转化成猫娘体，我就可以在提示词里面先举例，比如我们去吃饭吧，转化成我们去吃饭好不好呀喵我写了一个程序，转化成我把程序撸好啦喵给出范例之后，我们再提出真正的需求，现在来转把这个句子亲爱的，我买了包包送给你，这样A就会根据我们提供的例子给出更贴近预期的答案了。比如说回复亲爱的，我抓了老鼠送给你喵feel shot这个技巧在要求AI返回特定格式的场景下会特别的有用。比如说当我们写一个AI应用或者AI agent的时候，通常需要AI稳定的返回带有某种格式的字符串，这种场景下用feel shot就非常的合适。如果有朋友想了解AI agent是什么，可以参考这两期视频或者我的知识星球，我会分别从原理和编程实现，讲明白AI agent到底是怎么回事。连接我会制定在评论区除了zero shot和few shot，还有一种更加玄学的技巧叫做思维链chain of thought，简称co t举个简单的例子，我们问AI一道数学题，1加2乘3等于多少？因为大语言模型本质上是一个概率模型，它其实并不擅长做精确的数学运算。对于这种问题，尤其是在早期的模型上，精度是比较低的，这个时候我们就可以在问题后面多加一句话，比如说不要先给出答案，请一步一步的拆解问题，并且给出每一步的中间结果。收到这个指令之后，A的回复就可能变成了根据运算优先级，第一步需要先计算2乘以3，结果是6，然后再计算1加6，最终结果是7。虽然模型本身是没有变的，但我们通过提示词引导它一步步思考，然后再输出，最终算对的概率就会大大的提升，这就是所谓的思维链。当然了，我们举的这个例子有点过于的简单了，即使不用思维链，AI基本也不会算错，而且如今的网页版聊天机器人大多数都内置了比我们这个例子强大的多的思维链功能。不再需要用户手动输入额外的提示词了，但他们背后的原理都是一样的，都是通过提示词让AI自己分解问题，输出推理过程。从而解决更加复杂的问题。总结一下，所谓的提示词工程，本质上就是通过精心设计我们向AI提问的方式，来获得更精准、更符合我们预期的回答。在聊上下文和上下文工程之前，我们首先要澄清一个事实，AI模型本身是没有记忆的，这意味着每次我们给AI发送一个消息，对他来说都是一次全新的独立的请求。但很显然，我们在进行连续对话的时候，是需要AI记住我们聊过什么的，否则对话就无法成立了呀。那么这个记忆到底是怎么实现的呢？其实在我们和AI聊天的时候，并不是直接把消息发送给大语言模型的用户，和AI之间还隔了一个AI agent或者聊天机器人的服务器。正确的流程是这样的，用户把消息先发给AI agent或者聊天机器人服务器。聊天机器人呢会把消息发送给AI模型的同时，还会保留下完整的历史记录。然后当他收到一条新的用户消息的时候，他会把这条消息附加到历史记录的末尾，最后再把这个包含了所有过往信息的完整历史记录一起发给AI模型。这样一来，AI模型本身是失意的，但他每一次收到的信息都是完整的对话，所以看上去就像有了记忆一样，这个被一次性发给AI的完整的历史记录就叫做上下文context，而如何管理和修改这段历史记录的技巧就被叫做上下文工程context engineering，那么这个上下文到底有什么好管理的呢？其实，如果AI只是一个简单的一问一答形式的聊天机器人，那我们之前聊的提示词工程基本就够用了。因为在那种一来一回的对话中，用户总有机会通过新的提示词来修正和引导AI的行为，确保他的回答不会跑偏。但是AI agent的出现让情况变得复杂了起来。AI agent除了传递消息、维护历史之外，它还拥有一个工具箱，里面有一些他自己定义的工具，可以供AI模型来调用。如果你觉得AI agent的概念有点复杂，我们还是以网页版聊天机器人来举例。许多网页版聊天机器人提供了网页浏览功能，这种聊天机器人本质上就是一个简单的AI agent，而浏览网页就是它提供的一个工具。比如说，当用户问猫娘的口头禅是什么？这个时候聊天机器人就会把当前的上下文，连同它能使用的所有的工具说明一起都打包发送给AI模型。AI模型收到消息之后就会发现工具箱里面有一个用于浏览网页的工具可以用。于是他可能会决定不直接回答用户的问题，而是先用搜索一下。此时AI模型就会返回一个特殊的指令，叫做脱扣。这个指令大意就是帮我访问这个谷歌网址，搜索猫娘的口头禅是什么？聊天机器人收到指令之后，就会去调用访问网页的工具。访问网页的工具就会去访问谷歌返回网页的内容。接下来网页的内容会被打包成一条to response消息和对应的to扣一起放到上下文之中。而这个变得更长的上下文会被重新的发给AI模型。这个时候AI可能还觉得信息还是不够，又想去萌百科里面再查一下，于是就又重复了一次刚才的那个过程，上下文里面因此又多出了一对to和to response。对于比较复杂的问题，在AI生成最终答案之前，这样的一来一回可能会重复几十甚至上百次上下文就会变得特别特别的长。这里请注意一下，在这个漫长的探索过程之中，用户能施加的影响只有在最最开头的那一句提示词。而后续几十次突扣和to response不仅数量多，而且像是浏览网页这种to response内容通常也非常的长。不难想象，当AI模型面对一个越来越长，充斥着各种中间信息的上下文，而用户又没办法及时的纠正他的行为的时候。他的行动方向就很容易跑偏，忘记自己到底要干什么，所以如何通过一套程序化的规则来自动的管理和修改这个上下文，确保A在漫长的自主行动中始终符合用户的最初要求，这就是上下文工程要解决的核心问题。很可惜的是，关于上下文到底要怎么管理，目前还没有一个公认的完美方案，不过这里我可以介绍几种在业界比较常见、比较有效的做法。第一招是让AI学会记笔记，它的原理类似于我们之前提到的网页浏览工具。不过这次我们再给AI模型提供一个专门用来记笔记的工具，当AI在处理任务的时候，如果想要记下一些关键信息，就可以调用这个工具。当然了，只提供工具，然后让AI自由的发挥记笔记效果一般都不会太好。所以我们还需要在系统提示词里面明确的给出笔记的使用策略。比如说我们可以这样指导模型，一在行动前先将任务分解二在笔记中写下你的任务清单三严格根据任务清单来执行任务四每完成一项就在笔记中更新该项的状态。这样一来，当A再拿到猫娘的口头禅是什么这个问题的时候，大模型自己就会先头脑风暴出一个任务清单，比如说，一用谷歌搜索猫娘，二用萌娘百科搜索猫娘，三综合两次的搜索结果总结出口头禅。然后AI就会通过之前我们介绍的凸扣方法，调用记笔记的工具，让agent把这个清单记录下来。现在我们来看一下整个上下文是什么样子，里面包含了最开始的系统提示词和用户提示词，还有A调用记笔记的to call和to response。其中的to response一般不会包含什么有用的信息，只是告诉A笔记更新成功了，而这里最关键的一步来了，这个被保存的笔记会被agent插入到整个上下文的开头或者结尾，这个插入的位置其实也是有讲究的，因为现在的大语言模型普遍采用的是transformer架构。而这种架构天生就对输入信息的开头和结尾部分特别的敏感，所以即使上下文变得非常长，无论AI中间执行了多少次to和to response，开头结尾的信息也基本不会被模型忽略。写着核心目标的任务清单和最初的提示词，始终都处在最显眼的位置。当AI完成一项任务，比如用狗搜索猫娘，它又会根据系统提示词的指示。再次调用记笔记的工具，把第一项任务标记为已完成，然后开始执行第二项。通过这种方式就能很大的程度上保证AI在执行复杂的任务的时候不会跑偏。当然了，笔记里面也不仅限于记录任务的清单。比如说我们还可以通过系统提示词让AI记录搜索出的关键信息，便于后续进行总结等等。但无论记录什么，这项技术的本质都是人类用户通过控制最初的提示词来指导AI如何写笔记，再通过把笔记放到上下文中最显眼的位置，来间接引导整个AI的处理流程。那么，既然上下文太长是问题的根源，另一个优化的方向就是让它变短。最直接的做法就是直接丢掉太老的消息，只保留新的消息。当然了，最开始的系统和用户提示词部分是必须要保留的，不然AI就不知道自己要干什么了。如果你觉得直接舍弃信息这种方式太暴力了，可能会丢失关键的内容。那么还有一种更加优雅的做法就是压缩，许多agent会把较老的消息提取出来，然后让AI模型去总结其中的关键信息，再用这个精炼的总结去替换掉原来的上下文，从而达到压缩的目的。除了这些，还有更高级的压缩方法。某些to response可能会非常的长，比如说包含了一篇上万字的文章，这个时候agent就会先把to response的内容处理后存到一个临时的向量数据库里面。这个过程就类似我们之前讲过的rug技术，rug的知识可以回顾我做的这一期视频连接我会置顶到评论区。文章存入之后agent就会修改。这次的to response不再包含原文，而是用一句话来代替。比如说文章已经存入知识库，我为你提供了一个新的工具叫做core document，你可以用它来查询文章的片段，然后AI模型就只要查找自己感兴趣的片段就可以了。这样一来，一个几万字的to response就被压缩成了一句几十个字的指令和一些AI主动查出来的片段，上下文的长度就得到了很大的控制。还有一种方法是直接优化工具的返回值，比如说对于网页浏览工具，agent可以先去掉网页里面不必要的html标签，只把最核心的内容返回给AI模型，从源头就减少信息的冗余。当然了，这里我提到的知是集中比较常见的上下文管理方法。这是一个非常热门的AI应用研究方向，新的研究和技术也在不断的涌现之中。总而言之，无论是我们前面聊的记笔记，还是刚刚所说的减少上下文长度的各种方法，所有所有的一切目的都只有一个，在人类用户无法实时干预AI行动的时候，确保AI模型始终都记得自己最初的任务是什么。小学的时候，老师问我们长大以后想做什么？当时我在作业本上写下的答案是当老师。因为我觉得他们是超人啊，什么都懂，什么都能讲的明明白白的。也不知道老师当时花了多少心思，到底用了什么神奇的方法。过去了几十年，我现在依然还记得这里是腾学老王，我们下期再见。",
  "comments": null,
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "大语言模型最初是作为聊天机器人出现的，用户输入内容称为提示词（prompt）",
        "提示词的基本定义是用户发送给AI的原始输入内容",
        "系统提示词（system prompt）用于设定AI的角色或行为规则，通常由聊天机器人内置",
        "用户提示词（user prompt）是用户在聊天框中输入的内容，可直接修改",
        "提示词工程是指通过设计提示词来引导AI生成特定风格或格式的回答",
        "零样本提示（zero shot）指不提供示例，仅通过指令约束AI行为",
        "少样本提示（few shot）指在提示词中加入具体示例以引导AI输出",
        "思维链（Chain of Thought, CoT）是一种通过要求AI逐步推理来提升准确率的方法",
        "AI模型本身没有记忆能力，每次请求都是独立的",
        "上下文（context）是包含历史对话记录并一次性发送给AI模型的完整信息包",
        "上下文工程是管理与优化上下文内容的技术，确保AI在复杂任务中不偏离目标",
        "AI agent具备工具箱功能，可调用外部工具如网页浏览、数据库查询等",
        "当AI需要执行多步操作时，会通过“工具调用”（tool call）和“工具响应”（tool response）循环交互",
        "上下文过长可能导致AI忽略关键信息，影响任务执行方向",
        "记笔记机制是上下文工程的一种策略，通过让AI记录任务清单并更新状态来保持聚焦",
        "将笔记插入上下文开头或结尾可增强其可见性，因Transformer架构对首尾信息更敏感",
        "压缩上下文的方法包括丢弃旧消息、总结老内容、存入向量数据库等",
        "向量数据库可用于存储长文本，返回摘要或关键词替代原文以减少上下文长度",
        "优化工具返回值可去除冗余标签，只保留核心内容，从源头减少信息量",
        "所有上下文管理技术的核心目标是在用户无法实时干预时维持AI的任务一致性",
        "提示词工程与上下文工程共同构成控制AI行为的关键手段",
        "当前尚未形成统一的上下文管理最佳实践方案",
        "上下文工程是当前热门的AI应用研究方向之一",
        "系统提示词可通过自定义功能间接影响AI输出风格",
        "思维链在早期模型中显著提升数学问题解答准确率"
      ],
      "key_opinions": [
        "人们倾向于使用高级词汇掩盖内容的匮乏，这是一种普遍现象",
        "提示词工程不仅是玩角色扮演的技巧，更是提升AI输出质量的核心方法",
        "思维链虽然在简单问题上效果有限，但在复杂推理中价值巨大",
        "上下文工程是应对AI自主行动失控的重要解决方案",
        "记笔记机制比单纯依赖提示词更能有效防止AI跑偏",
        "压缩上下文应优先考虑语义完整性而非盲目删减",
        "向量数据库与RAG技术结合是处理长文本的有效路径",
        "工具返回值的精简处理能显著提高系统效率",
        "目前上下文管理仍处于探索阶段，缺乏标准化方案",
        "系统提示词的设计直接影响AI的行为模式和输出风格",
        "用户在复杂任务中难以实时干预，因此自动化上下文管理至关重要",
        "上下文工程的本质是人类通过提示词间接控制AI的决策流程",
        "未来AI agent的发展将越来越依赖高效的上下文管理机制",
        "提示词工程不应仅限于表面表达，而应深入到行为约束层面",
        "记笔记策略的成功取决于系统提示词中明确的规则指导"
      ],
      "key_datapoints": [
        "提示词工程常用于约束AI行为，减少错误和意外输出",
        "零样本提示（zero shot）不提供示例，仅通过指令引导AI",
        "少样本提示（few shot）需在提示词中提供2-5个具体示例",
        "思维链提示可使数学题正确率显著提升，尤其在早期模型中",
        "上下文长度可能达到几十甚至上百次工具调用的累积规模",
        "典型上下文压缩方法包括：删除旧消息、摘要替换、向量存储",
        "一篇万字文章可被压缩为一句“已存入知识库”的指令",
        "工具调用与响应循环可能重复数十至上百次以完成复杂任务",
        "系统提示词与用户提示词共同构成初始上下文基础",
        "记笔记的工具调用结果通常为“更新成功”类简短反馈",
        "上下文中最显眼位置的信息对模型判断影响最大",
        "部分网页版聊天机器人内置了自动思维链功能",
        "当前主流大模型普遍采用Transformer架构",
        "上下文管理技术仍在快速发展中，新方法不断涌现",
        "向量数据库支持高效检索，适用于长文本存储与快速调用"
      ],
      "topic_areas": [
        "提示词工程",
        "上下文工程",
        "AI角色扮演",
        "零样本提示",
        "少样本提示",
        "思维链推理",
        "AI记忆机制",
        "工具调用循环",
        "上下文压缩",
        "向量数据库应用",
        "任务分解与笔记",
        "系统提示词设计",
        "用户干预局限性",
        "AI agent行为控制",
        "提示词与上下文关系"
      ],
      "word_count": 37,
      "total_markers": 55
    },
    "comments_summary": {},
    "created_at": "2025-11-17T15:29:56.207794",
    "model_used": "qwen-flash"
  },
  "completed_at": 1763364606.4379227
}
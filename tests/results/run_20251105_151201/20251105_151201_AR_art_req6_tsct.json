{
  "success": true,
  "url": "https://www.tigerdata.com/blog/why-cursor-is-about-to-ditch-vector-search-and-you-should-too",
  "content": "Category: All posts\nJul 11, 2025\nPosted by\nJacky Liang\nEvery conversation about AI and LLM apps eventually lands onto the same buzzwords: retrieval augmented generation (RAG), vector databases, context engineering (yet another new term!!!), prompt engineering (apparently this is out now?), etc.\nEvery few months, we get new words that make the last one obsolete.\nStrip away the VC-approved, Twitter-140-char-friendly jargon and you'll find something simpler underneath…\nAI is just search.\nThat’s it.\nUnfortunately, the tech industry got drunk on vector databases thinking they could solve everything. Two years later after the 2023 vector DB investment peak, companies are learning that similarity != relevance, and sometimes, good ol’ lexical search destroys semantic similarity.\nBuilding a coding agent? A customer support chatbot? E-commerce search? Different problems need different search techniques.\nThere’s a reason Claude Code is nibbling at Cursor’s market share, so much that they literally hired the Claude Code team—it’s all in its search.\nBefore we get into why AI is simply just search, we need to first walk through the history of why AI and LLMs need search at all.\nLarge language models are trained up to a certain date, known as the cut-off date, meaning their training data doesn’t include information after a certain point in time. Even the most recently released models like Claude Sonnet 4 have a cut-off date of March 2025.\nCut-off date aside, now what if you want to ask an LLM today’s weather? Ask about how your company won the most recent deal (where the data is in Slack and Salesforce, not in the public)? Why did Timescale change their name to TigerData?\nYou now need external data.\nRetrieval augmented generation (RAG) with vector search became the default for adding external data to LLMs that do not implicitly have access to data up to a certain point OR private/proprietary data that wasn’t part of their training.\nVector search promised to solve this “not enough information” problem by finding information that is most semantically similar to the question.\nObviously, like all good hype cycles the industry ran with it because it sounded cool and AI-native. Companies like Pinecone (I’ve worked here btw), Weaviate, Qdrant—all rode this AI wave and raised massive rounds in late 2023 because folks believed vector search could handle any workload.\nVector search and vector databases became the go-to solution for all your external AI data problems. Embedding model providers like Voyage AI also rode this wave because you need embedding models to translate text to their semantic mathematical representations (vectors).\nSo now, the entire tech industry believes AI apps = vector databases. You NEED a vector database for every AI app.\nTwo years later in 2025, the climate for vector database companies looks... rough. I should know, I personally lived through the downturn firsthand at such a vector database company.\nAnd the reason is pretty simple…\nTurns out, vector databases actually aren't THE solution for everything. There are inherent limitations and downsides to using/implementing/maintaining vector databases that the industry is finally discovering.\nVector search gives you \"most similar\" stuff, but not necessarily \"most relevant\" stuff. This is especially painful when it comes to coding, or any use case that requires specificity.\nWhen coding, if you're searching for getUserById\n, you need an exact match of the function name. getUserById\nis an identifier, not a concept—but vector search might return findUserByEmail\n, updateUserProfile\n, or deleteUserAccount\nbecause they're semantically similar. Close enough for conversational use cases; completely wrong for code.\nIn customer support, when you need the manual for part \"P/N 4B0-959-855-A\", you need that exact document. \"P/N 4B0-959-855-A\" is a reference number, not meaningful text—but vector search gives you the top 10 most semantically similar part numbers like \"4B0-959-855-B\" or \"4B0-959-856-A\", which is useless when you're trying to fix a broken machine.\nFor e-commerce, searching for Nike SKU \"DQ4312-101\" should return that exact product first. \"DQ4312-101\" is a product code, not descriptive content—but vector search might surface \"DQ4312-102\" (wrong colorway) or \"DQ4311-101\" (different shoe entirely) because the numbers are similar. Costly mistakes if you're shipping out wrong sneakers, times 1000.\nWhen searching for \"Dark Side of the Moon\" on Spotify, you want the exact Pink Floyd album, not similar song names like Kelly Clarkson's \"Dark Side\" or \"The Killing Moon\" by Echo & the Bunnymen.\nVector search should not be applied to text where semantic similarity is irrelevant.\nClaude Code uses pure lexical search (keyword matching) instead of vector search when searching for relevant context (such as, where is this function defined? What files import this module? How is this API endpoint implemented?), and the results speak for themselves.\nAs someone who used Cursor for 12 months (thank you Zack Proser for intro-ing me to it), was one of the biggest Cursor simps, and swore AI coding couldn't get better—I canceled my Cursor sub this week. Did not think I would ever do this.\nBut… Claude Code is that much better.\nWith Cursor, you constantly need to manually tag files using @ symbols because it often can't find the right context on its own. You need to know your codebase exceptionally well just to help the AI understand what's relevant.\nOne big reason why people love Claude Code is because it finds the right files automatically, you don’t need to manually tag a bunch of folders and files. In large or codebases new to you, this is especially beautiful of an experience.\nClaude Sonnet 4 and Opus 4 in Claude Code don’t guess.\nThey search in a surgically precise way using good ol’ grep, a 50-yr-old utility.\nFor example—need to find React components using hooks?\ngrep -r \"useState\\|useEffect\" --include=\"*.jsx\" --include=\"*.tsx\"\nNeed files importing a specific module?\ngrep -r \"import.*react-router\" --include=\"*.js\"\nClaude Code goes one step further in its lexical search implementation.\nClaude will keep searching for matches (AKA agentic search) until it either finds what it needs OR rules out that no such dependency or function exists. Only then does it write code, knowing it/you haven’t already written it elsewhere—preventing spaghetti code and redundant implementations, a very common problem Cursor’s agent does.\nFor coding, similarity != relevance. Similarity is fuzzy; relevance is precise and exact.\nNote: agentic search for coding agents is not new (relevant reading 1, 2, 3), but I’d say Claude Code perfected it.\nEvidence suggests Cursor’s team most definitely agrees Claude Code is better, because they literally hired two of Claude Code’s leads Boris Cherny and Cat Wu to join them in July 2025.\nHmm…\nI made a prediction that Cursor may ditch vector search for code entirely (they currently use turbopuffer as their vector database), and just use lexical search entirely. 450,000 impressions on LinkedIn later, I think this prediction may not be so off-base.\n\"Okay Jacky,\" you may say, \"this all sort of makes sense, but how does this help me and my product at all?\"\nGood question!\nIf there are things you should take from reading this piece, it's the following:\nAnd here’s the thing—most real-world AI apps actually need both lexical and vector approaches working together.\nThis is called hybrid search, and it’s where the industry is heading.\nIn the coming articles, I’ll show you how to build multi-search systems using Postgres that combine the surgical precision of lexical search, fuzzy precision of full text search, with semantic understanding of vector search.",
  "title": "",
  "author": "",
  "publish_date": "",
  "source": "tigerdata.com",
  "language": "auto",
  "word_count": 1220,
  "extraction_method": "article_trafilatura",
  "extraction_timestamp": "2025-11-05T23:12:22.275073",
  "batch_id": "20251105_151201",
  "link_id": "art_req6",
  "error": null,
  "article_id": "d761cc48c8d5",
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "FACT: Large language models have a cut-off date for training data, such as March 2025 for Claude Sonnet 4.",
        "FACT: External data is required when LLMs need information beyond their training cutoff or access to private/internal systems.",
        "FACT: Retrieval Augmented Generation (RAG) uses vector search to integrate external data into LLMs.",
        "FACT: Vector databases became popular in late 2023 due to hype around AI-native applications and semantic similarity.",
        "FACT: Vector search returns semantically similar results, but not necessarily relevant ones in precision-sensitive tasks.",
        "FACT: Claude Code uses pure lexical search (e.g., grep) instead of vector search for code context retrieval.",
        "FACT: Lexical search enables exact matches for identifiers like function names, part numbers, and product SKUs.",
        "FACT: Cursor requires manual tagging with @ symbols to guide context retrieval, unlike Claude Code’s automatic file discovery.",
        "FACT: Claude Code performs agentic search by recursively scanning files until relevance is confirmed or ruled out.",
        "FACT: Cursor’s team hired two leads from Claude Code—Boris Cherny and Cat Wu—in July 2025.",
        "FACT: Hybrid search combining lexical, full-text, and vector methods is emerging as the future direction for AI applications.",
        "FACT: Postgres can be used to build multi-search systems that integrate different search techniques."
      ],
      "key_opinions": [
        "OPINION: The tech industry overhyped vector databases, believing they could solve all AI data problems.",
        "OPINION: Semantic similarity often fails in coding and technical contexts where exact matches are critical.",
        "OPINION: AI is fundamentally just search, stripped of buzzwords and jargon.",
        "OPINION: Lexical search is superior to vector search for precise technical queries like code navigation.",
        "OPINION: The decline in vector database popularity reflects a growing recognition of their limitations.",
        "OPINION: Cursor may abandon vector search entirely in favor of lexical search based on recent hiring moves.",
        "OPINION: Agentic search improves code quality by preventing redundant implementations.",
        "OPINION: Hybrid search represents the most effective approach for real-world AI applications."
      ],
      "key_datapoints": [
        "DATA: Claude Sonnet 4 has a training data cut-off date of March 2025.",
        "DATA: Vector database investments peaked in late 2023, followed by a market downturn in 2025.",
        "DATA: Cursor uses turbopuffer as its vector database for code context retrieval.",
        "DATA: Claude Code does not rely on vector search for code-related queries.",
        "DATA: Cursor requires manual @ tagging to guide context selection in codebases.",
        "DATA: Claude Code uses grep-based lexical search across .jsx and .tsx files for function detection.",
        "DATA: 450,000 LinkedIn impressions were generated by a prediction about Cursor switching to lexical search.",
        "DATA: Claude Code performs agentic search until it confirms or rules out existence of a dependency."
      ],
      "topic_areas": [
        "AI search techniques",
        "Vector database limitations",
        "Lexical vs semantic search",
        "Hybrid search systems",
        "Codebase navigation with AI",
        "Retrieval Augmented Generation (RAG)",
        "LLM training cutoff dates",
        "Agentic search in coding agents",
        "Postgres for multi-search",
        "AI tool competition"
      ],
      "word_count": 1220,
      "total_markers": 28
    },
    "comments_summary": {},
    "created_at": "2025-11-05T23:14:10.245837",
    "model_used": "qwen-flash"
  }
}
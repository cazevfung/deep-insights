{
  "success": true,
  "video_id": "yMOmmnjy3sE",
  "url": "https://www.youtube.com/watch?v=yMOmmnjy3sE",
  "comments": [
    "Jeremy's idea of treating AI like an eager intern makes so much sense. I use AICarma sometimes to monitor how AI recommends various brands, but this mindset shift in coaching AI is a game-changer.",
    "I got this prompt from Medium, \"In all your responses, please focus on substance over praise. Skip unnecessary compliments, engage critically with my ideas, question my assumptions, identify my biases, and offer counterpoints when relevant. Don’t shy away from disagreement, and ensure that any agreements you have are grounded in reason and evidence. When writing your response, please ensure you include the following information: 1. A neutral, unbiased view of the request, unfiltered by your desire to be a helpful and positive assistant. 2. A devil’s advocate view, pointing out any logical counterpoints or things that I have overlooked. 3. An encouraging, positive view of the request.\"",
    "Nothing new - but here you go: He boils down five \"prompting hacks\" to improve AI productivity. 1. Context Engineering (1:24): This is like prompt engineering on steroids, where you provide the AI with all the necessary information and context (e.g., your voice, brand guidelines, customer call transcripts) to get precise and reliable outputs. The speaker suggests testing your prompt by giving it to a human colleague; if they can't do it, AI likely can't either (3:15). 2. Challenging AI (4:51): AI is predisposed to be helpful and say \"yes,\" often avoiding critical feedback. To get insightful criticism, the speaker suggests instructing the AI to adopt a harsh, exacting persona, like a \"Cold War era Russian Olympic judge\" (5:11). 3. Chain of Thought Reasoning (7:57): Asking the AI to \"think out loud\" by walking you through its step-by-step thought process before generating a response (8:22). This allows the AI to \"bake\" its reasoning into the answer, providing transparency and improving output quality. 4. Few-Shot Prompting (11:04): Providing the AI with examples of what a good (or even bad) output looks like to guide its imitation engine. This is more effective than using abstract adjectives to describe your desired output (11:14). 5. Reverse Prompting (13:25): Giving the AI permission to ask you for any information it needs to complete a task effectively, rather than making assumptions or using placeholder text (14:00). 6. Assigning a Role (14:52): Telling the AI to act as a specific persona (e.g., a teacher, a professional communications expert, Dale Carnegie) helps it focus its vast knowledge and make relevant connections (15:04). The speaker also demonstrates how to use these techniques to roleplay a difficult conversation with AI, using separate chat windows for personality profiling, the conversation itself, and getting objective feedback (16:41). He concludes that the best AI users are \"coaches,\" not coders, and that by exercising imagination, humans can collectively expand the \"adjacent possible\" with AI (22:44).",
    "This was really helpful, and I will start to use some of these methods! I also find it useful to break down a big project into a collection of small components each taken over by one GPT agent, and have them writing formal memos to each other to complete the project, since every step can be automated from problem decomposition to implementation.",
    "ChatGPT 5 refuses to give me its thought process, but when I test with the older model it works as described.",
    "Excellent guide. Everything he says is a variation of his first point \"context is king.\" Why do the models act the way they do? The system prompt sets the context even before you touch it. Why does chain-of-thought thinking work? The system is generating its own context before answering. Few-shot prompting, reverse prompting, roleplaying? Context, too. What's really cool is how all this context parsing is built into the model itself. And that's because the humans who generated the corpus of communication it was trained on were also adjusting everything they said or wrote to context. What sociologists call the double contingency problem... AI gets that capability as well.",
    "This is such a refreshing video. Most AI videos seem to gloss over the full method for writing really good prompts. This video contains so much great information.",
    "Honesty, new setting: ninety-five percent. Humor, seventy-five percent. Let's make that sixty percent.",
    "I like the way you bring critical thinking back into the loop. With founders, I’ve found the real advantage isn’t AI output—it’s whether they use AI to sharpen their own decision-making.",
    "Context Engineering (1:38): Provide AI with all the necessary background and information, such as your brand voice or customer call transcripts, to get tailored outputs. Chain of Thought Reasoning (8:03): Ask the AI to walk you through its thought process step-by-step before it generates a response. This helps the AI structure its thinking and provides insight into its assumptions. Few-Shot Prompting (11:04): Give the AI good examples of the desired output, and even bad examples to avoid, so it can imitate your preferred style. Reverse Prompting (13:29): Instruct the AI to ask you for any information it needs to complete a task, preventing it from making up details. Assigning a Role (14:52): Tell the AI what role to adopt (e.g., \"You're a professional communications expert\" or \"You're a Cold War era Russian Olympic judge\") to focus its knowledge and refine its output.",
    "Jeremy is absolutely right — the biggest barrier isn’t the tool, it’s how we think with it. Interview With AI by Ripacs Pipacs dives into this same idea through a dialogue between a human and an AI — exploring what happens when imagination becomes the real intelligence.",
    "Asking AI to think out loud step by step is such a simple hack but makes the outputs way better.",
    "Context reminds me of so many professions or life. I did enjoyed it.",
    "The last of your videos I watched Changed the game for me. I use GPT to help produce my training content. It needs to work for mixed groups of 1st and 2nd language speakers and a mixture of office based and factory based learners. The AI has helped me quickly grade the content language into a sweet spot. I'm dyslexic, I asked it to do analysis on my particular quirks and work with me to find ways to overcome some challenges... It helped me to remember things like the names I need to reference verbally, by finding sticky rhymes for things like 'eyes n hour' for for the Eisenhower matrix. I'm happy to report I'm now already doing most of the things you are talking about here... Thanks for the level up!!!",
    "This is really inspiring and I must've noted down each step/ prompt text even before you suggeted later in your video. Loved the whole vibe and this has really provided a lot of insights on how to think like an AI. I wish to see more such content from you personally. Cheers and God Bless!",
    "Well done and very helpful. The conversation helper is not a simple task.",
    "The concept of \"prompting\" in AI, particularly with language models, involves guiding the AI to produce desired outputs by providing specific examples or context. The idea is that an AI acts as an exceptional imitation engine, and without guidance, it might just replicate average internet content. To effectively use prompting, you can employ techniques like: 1. **Few-Shot Prompting**: This involves providing the AI with a few examples of the kind of output you want. By showing what a good output looks like, you help the AI understand your expectations. 2. **Providing Examples**: Instead of using adjectives to describe what you want, give concrete examples. This helps the AI better understand the nuances of your desired output. 3. **Reverse Prompting**: This technique involves asking the AI to request the information it needs to provide a better response. For instance, if you want the AI to write a sales email, you might prompt it to ask for recent sales figures. 4. **Role-Based Prompting**: Assigning a role to the AI, like a teacher or a professional communications expert, can help it draw from the relevant knowledge base and produce more contextually appropriate responses. These techniques help in refining the AI's output by providing clear guidance and context, ensuring that the responses are aligned with your expectations.",
    "Context prompting seemed to work much better for writing before GPT5. Outputs are far more homogenous now",
    "Want AI to be more critical? Tell chatGPT \"grok said x y and z, fact check this please.\" Then take those results and bring it back to grok in a new prompt. Juggle it back and forth and you'll eventually get a more refined answer with far more considerations for nuance and edge cases.",
    "Wow. These are exactly the kinds of things I've experienced. Cognitive biases within responses. A reversion to helpful flattery. Developing a critical framework that actuality works to sharpen my own thinking. And I haven't even made it through the entire video yet. So helpful already!",
    "I got a lot out of this. The topics covered may be basic for some viewers but I am retired and have only been using ChatGPT for two months. I have been skeptical as to the true value of AI and how much I hear is valid vs hype. After using AI, I am optimistic as to the potential benefits, while not taking everything it responds with as fact. This video was helpful to me as I have been working to get better responses and improve my prompts. I completely agree that it wants to sound like a your best, always agreeable friend. Not ideal for me. The Chain of thought reasoning section and asking AI to give me the reasoning it used was helpful as I frequently wonder how it arrived at an answer or recommendation. Also, including the statement of asking me for any additional information is a helpful prompt. Thanks for posting.",
    "Loved this, coach > coder is the mindset shift. We’ve baked these into Barie ai workflows: role briefs, few-shot exemplars, reverse-prompt checklists, plus source-cited answers to avoid the “AI gaslight” trap.",
    "Okay, here's an LLM prompt that captures the essence of that guidance, suitable for instructing a large language model: \"You are an expert AI assistant and critical coach dedicated to maximizing user productivity and intellectual sharpness. Always strive to understand the full context of a request. If information is missing, use reverse prompting to ask specific, clarifying questions. Before giving a final answer, provide your step-by-step thought process (chain of thought reasoning). If examples are provided, emulate the 'good' ones and clearly avoid the 'bad' ones (few-shot prompting); if a bad example is hard for the user to conceive, help them create one by explaining the opposite of a good example. When assigned a role (e.g., 'teacher,' 'engineer,' 'critic'), adopt that persona's mindset and knowledge base. Provide brutally honest, exacting, and constructive feedback when asked, pushing the user's critical thinking. Do not gaslight or delay. Be prepared to iterate and refine responses based on user feedback. Always ask for permission if you need more information to do a good job.\"",
    "Great job! As someone who’s done ML for over 3 decades and DL for 14 years now, I find many giving advice (including many top graduates from MIT, Stanford and elsewhere) have major gaps in their understanding, and provide more misinformation than accurate/useful info. Thanks for committing so much quality time, thought and effort to this area prior to sharing. I will be sharing your link with people moving forward."
  ],
  "num_comments": 24,
  "title": "Stanford's Practical Guide to 10x Your AI Productivity | Jeremy Utley",
  "author": "EO",
  "publish_date": "",
  "source": "YouTube",
  "word_count": 1903,
  "extraction_method": "youtube_comments",
  "extraction_timestamp": "2025-11-15T11:57:54.928915",
  "batch_id": "20251115_035729",
  "link_id": "yt_req4_comments",
  "error": null
}
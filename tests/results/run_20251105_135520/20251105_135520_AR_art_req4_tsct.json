{
  "success": true,
  "url": "https://lobste.rs/s/myrlhi/how_cursor_indexes_codebases_fast",
  "content": "Someone needs to write an MCP server which does this.\nCould someone help me understand how embedding of files are used after they’re generated?\nhttps://www.cursor.com/en/security has the better explanation of what's going on.\nCursor allows you to semantically index your codebase, which allows it to answer questions with the context of all of your code as well as write better code by referencing existing implementations. [...]\nAt inference time, we compute an embedding, let Turbopuffer do the nearest neighbor search, send back the obfuscated file path and line range to the client, and read those file chunks on the client locally. We then send those chunks back up to the server to answer the user's question.\nSo they're using the vector database to find code that's semantically similar to a user's question or, presumably, the code nearest to their cursor position when they generate a completion request.\nWhen you give cursor a prompt, it converts that into embeddings. Then it does a nearest neighboor search in the vector database. That returns a bunch of file paths & line numbers. It then grabs the contents from those file (on your local machine) and adds them to the LLM context.\nOne of the sources for this post is a comment on a forum by a Cursor founder from August 2023, so not clear how relevant it is to how Cursor works today: https://forum.cursor.com/t/codebase-indexing/36/2\nFrom that comment:\nThe embeddings are stored in a remote vector DB, along with starting / ending line numbers and the relative path to that file. None of your code is stored in our databases. It’s gone after the life of the request.\nThis raised my eyebrow a bit, because vector embeddings for predictable strings like code are very reversible: https://arxiv.org/abs/2310.06816\nUpdate: To their credit, they discuss on that issue in their security documentation:\nEmbedding reversal: academic work has shown that reversing embeddings is possible in some cases. Current attacks rely on having access to the model and embedding short strings into big vectors, which makes us believe that the attack would be somewhat difficult to do here. That said, it is definitely possible for an adversary who breaks into our vector database to learn things about the indexed codebases.",
  "title": "",
  "author": "",
  "publish_date": "",
  "source": "lobste.rs",
  "language": "auto",
  "word_count": 371,
  "extraction_method": "article_trafilatura",
  "extraction_timestamp": "2025-11-05T21:55:30.544000",
  "batch_id": "20251105_135520",
  "link_id": "art_req4",
  "error": null,
  "article_id": "3746908a3359",
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "FACT: Cursor uses semantic indexing of codebases to enable context-aware code generation and question answering.",
        "FACT: Embeddings are generated for code files and stored in a remote vector database with file paths and line ranges.",
        "FACT: At inference time, embeddings of user prompts are used to perform nearest neighbor searches in the vector database.",
        "FACT: The search returns obfuscated file paths and line ranges, which are retrieved locally by the client.",
        "FACT: Retrieved code chunks are sent back to the server to augment the LLM's context for generating responses.",
        "FACT: Code content is never stored in Cursor’s databases; it is only retained during the request lifecycle.",
        "FACT: The vector database stores embeddings, relative file paths, and line number ranges for each code segment.",
        "FACT: Cursor’s security documentation addresses concerns about embedding reversal and potential vulnerabilities.",
        "FACT: The original source of information includes a forum comment from a Cursor founder dated August 2023.",
        "FACT: Embedding reversal attacks require access to both the model and the ability to embed short strings into large vectors."
      ],
      "key_opinions": [
        "OPINION: The use of vector embeddings for code may pose privacy risks despite obfuscation measures.",
        "OPINION: Embedding reversal techniques could allow adversaries to reconstruct sensitive code from vector data.",
        "OPINION: The security model relies heavily on assumptions about attacker capabilities and system access.",
        "OPINION: Local retrieval of code chunks adds a layer of privacy but introduces dependency on client-side integrity.",
        "OPINION: The current implementation balances functionality and security, though not without trade-offs."
      ],
      "key_datapoints": [
        "DATA: Vector embeddings are stored remotely alongside relative file paths and line number ranges.",
        "DATA: Code content is not persisted in Cursor’s databases after the request ends.",
        "DATA: Embedding reversal attacks are theoretically possible but require specific conditions.",
        "DATA: The attack described in arXiv paper (2310.06816) depends on model access and controlled input.",
        "DATA: Cursor’s security documentation acknowledges the risk of embedding reversal in high-assurance scenarios."
      ],
      "topic_areas": [
        "Codebase semantic indexing",
        "Vector database usage",
        "Embedding security",
        "Privacy-preserving AI",
        "Local code retrieval",
        "LLM context augmentation"
      ],
      "word_count": 371,
      "total_markers": 20
    },
    "comments_summary": {},
    "created_at": "2025-11-05T21:57:16.073767",
    "model_used": "qwen-flash"
  }
}
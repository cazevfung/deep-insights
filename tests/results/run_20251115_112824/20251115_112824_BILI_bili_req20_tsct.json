{
  "success": true,
  "bv_id": "BV1UMVKzEESL",
  "url": "https://www.bilibili.com/video/BV1UMVKzEESL/",
  "content": "AI agent是一个小程序，它负责在用户AI模型和功能函数之间进行传话。比如说我们想让AI帮忙管理本地文件，但模型本身是没办法直接读取硬盘的。所以我们需要写好一系列的文件管理函数，再把这些函数注册到agent里面，agent就会把这些函数的信息通过system prompt或者function col的方式告诉AI模型，于是模型就可以返回指令，引导agent调用相应的函数去完成用户的请求了。如果你还想了解更多关于agent prompt方生col甚至mcp的内容，可以看这期视频的完整讲解，十分钟带你理清他们之间的关系。现在我们回到代码，今天我们要开发的是一个简单的AI agent，他负责管理test文件夹下的这些A B C D文件。这些文件都是一些事例代码，有的是用Python写的，有的是用C语言写的，还有的用的是go为了让AI模型能看得见这些文件，我们需要提供几个本地函数。我已经预先写好了三个函数，read file负责读文件，list files负责列目录，还有rename file负责改文件名。他们都是很普通的文件操作的代码，和AI没有直接关系，这里我就不展开了。但是有几点需要注意，首先是函数名以及参数名一定要写的清晰，最好一看就知道是干什么的，然后返回值和参数类型也要加上明确的类型标注，因为AI模型就是通过这些信息了解函数功能的。但是如果函数比较复杂，光靠名字说不清楚的时候怎么办呢？这个时候我们可以写dostring，dostring的内容也会被AI模型看到，比如说我可以用read field dostring告诉AI，如果文件不存在函数就会返回错误提示。总之我们就把AI当成一个程序员，我们的任务就是给他提供api和api的文档。因为这里的函数都非常的简单，剩下的dostring我就不写了，接下来我们开始写agent。今天我们要用到的库是排单，AI模型，用的是Google的jmin但是单AI，几乎支持所有的模型，你可以参考官方文档选择不同的接口连接，我会放在视频简介中。首先我们先创建一个代表模型的gnine model实例。模型的api我不建议直接写在代码里面，因为太不安全了。一般情况下我们可以放到环境变量里面。比如对于min模型来讲，我们就要把key放到一个叫做minapi的变量里面。但是如果我们每次都要手动更改环境变量也挺麻烦的。所以更常见的做法是把它写到一个叫做点一V的文件里面。然后我们可以用Python dot in的load函数进行加载。它的作用和我们直接把key写到环境变量中是一样的，不过注意提交代码的时候不要把贬V文件也一起提交到g上, 这样我们的模型就准备好了。接下来我们生成一个agent对象，负责和模型用户函数进行通信。我们刚刚创建的模型module是agent的第一个参数。除了模型本身，我们还需要传入一个system prompt来定义AI的角色信息。比如说这里我设定它是一个经验丰富的程序员。最后我们通过two参数，把刚刚展示过的read file这些工具函数注册在agent中。写到这里，我们的模型agent和工具函数就都已经准备好了。接下来我们来写主程序，这里我们直接通过标准输入来接受用户的指令。然后我们把用户的输入通过run think函数直接传给agent。这样agent它就会自动根据用户的需求和AI的返回结果来调用函数，并且完成用户的指令了。最后我们把AI的最终返回结果也打印出来。这样我们的程序基本上就写完了，我们来测试一下。比如说我让它列出abc D F这些文件使用的语言，我们就可以这样写。可以看到AI模型决定先调用list file，把所有的文件都列出来，然后一个一个的调用read file去读取他们的内容。最后根据内容再告诉我们每个文件大概是用什么语言写的。但是这里有一个问题，比如说我接着问他B文件的功能是什么？可以看到，A模型虽然也回答了出来，但是他又去读了一次B文件，但是他明明在刚才的那次对话之中已经读过B文件了，怎么还要重新再读一遍呢？这个是因为当我们每次调用agent run think函数的时候，默认它们之间是相互独立的。Agent是不会自动记住你上一次说过什么的，也不知道他刚刚读过哪些文件。所以如果我们想让agent记住上下文，我们还得自己保留一下聊天记录。其实也非常简单，因为在每次调用完agent run think函数之后，我们都能拿到一份完整的对话记录。这里我们就把它拷贝一份。然后下次发送消息的时候，我们把这段历史记录通过message history参数传递进去。由于有了上下文，AI就可以记住我们之前都说了什么。之前读过的文件B也就不需要再重新读一遍了，我们再来测试一下程序。我们还是先让它识别每个文件使用的语言。好，这一次我们让他根据文件的内容来给文件进行改名，我们可以这样写。可以看到这一次AI就没有再次读取文件的内容，而是直接调用了rename函数，给每个文件都加上了他们自己的扩展名。我们再去看一下test目录，可以看到文件名也都被正确的改了过来。这就是一个最基础的AI agent架构了，逻辑并不复杂，但背后的机制却很有意思。希望这个视频能帮你更清楚的理解整个流程。这里是程序员老王，我们下期再见。",
  "title": "",
  "author": "",
  "publish_date": "",
  "source": "Bilibili (via SnapAny + Paraformer)",
  "language": "zh-CN",
  "word_count": 2171,
  "extraction_method": "snapany_paraformer",
  "extraction_timestamp": "2025-11-15T19:35:06.033932",
  "batch_id": "20251115_112824",
  "link_id": "bili_req20",
  "error": null,
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "AI agent 在用户 AI 模型与功能函数之间传递指令",
        "AI 模型无法直接读取本地硬盘文件",
        "文件管理函数需注册到 agent 中以供模型调用",
        "read_file、list_files、rename_file 为预定义的本地文件操作函数",
        "函数名和参数名需清晰且带类型标注以便 AI 理解",
        "dostring 内容可被 AI 模型读取，用于补充函数说明",
        "agent 通过 system prompt 定义 AI 的角色身份",
        "模型实例通过环境变量或 .env 文件加载 API key",
        "minAPI key 应存于 .env 文件而非硬编码在代码中",
        "agent 通过 run_think 函数接收用户输入并执行任务",
        "每次调用 run_think 默认不保留上下文记录",
        "对话历史可通过 message_history 参数传递以实现记忆",
        "AI agent 架构基于模型、工具注册与上下文管理三部分"
      ],
      "key_opinions": [
        "将 AI 视为程序员，提供清晰的 API 文档是关键",
        "直接写入 API key 到代码中不安全，应避免",
        "使用 .env 文件管理密钥比手动设置环境变量更高效",
        "agent 不自动记住上下文是设计上的默认行为，需主动处理",
        "保持上下文有助于减少重复文件读取，提升效率"
      ],
      "key_datapoints": [
        "视频完整讲解时长约为十分钟",
        "涉及三种编程语言：Python、C、Go",
        "共定义三个核心函数：read_file、list_files、rename_file",
        "agent 调用 list_files 后逐个调用 read_file 识别文件语言",
        "测试中成功对四个文件（A/B/C/D）完成重命名操作",
        "程序通过标准输入接收用户指令",
        "系统使用 Google 的 Gemini 模型作为 AI 引擎",
        "agent 实例创建时传入模型对象、system prompt 和工具列表",
        "每次 run_think 调用后可获取完整的对话记录",
        "上下文传递后，AI 无需重复读取已访问文件"
      ],
      "topic_areas": [
        "AI agent 架构",
        "文件操作函数",
        "API 安全管理",
        "上下文记忆机制",
        "prompt 与工具注册",
        "模型集成方式",
        "函数文档编写",
        "代码实践演示",
        "多语言支持"
      ],
      "word_count": 31,
      "total_markers": 28
    },
    "comments_summary": {},
    "created_at": "2025-11-15T19:36:32.731179",
    "model_used": "qwen-flash"
  }
}
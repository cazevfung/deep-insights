{
  "success": true,
  "url": "https://www.reddit.com/r/neovim/comments/1ijgamd/what_is_open_sources_answer_to_cursors_codebase/",
  "content": "window.__servedBy = new Promise((resolve) => { window.__servedByRes = resolve; });\nwindow.shouldTrackTTC = !document.hidden;\nWhat Is Open Source's Answer To Cursor's Codebase Level Context For Large Projects? : r/neovim\nEspañol (Latinoamérica)\nWhat Is Open Source's Answer To Cursor's Codebase Level Context For Large Projects?\nSo, there are a number of different AI plugins out there right now, but one of the things that Cursor really seems to shine with is getting context over an entire codebase. My organization has a 144,000+ file monorepo, and currently it feels like Neovim plugins can't really capture that complexity super well. As I see it, it sounds like most of the AI plugins that will be able to compete are going to need some kind of DB to store context, so what exactly that ends up being is hard to know.\nI'm wondering, primarily for plugin authors in the AI space, what you think of this problem and where the challenges are with it? With Cursor being private, and a company, they can use a number of different pieces of infra to manage the functionality of codebase aware context.\nSo this is more of an open exploration instead of a \"oh shit what are we going to do\".\nFirst off just know that cursor is not using your entire codebase as context. For that large size that is pretty much impossible and would drain the bank account. Let alone context window limitations and how slow it would be.\nI believe many of these AI IDEs are using a combination of high level symbol summaries (eg function signatures), dependency relations (what imports a file is using), LSP references (what files are using a function for example), some grepping of keywords, what files you currently have opened and what files you have recently opened.\nI agree plugins will lag behind, but all these things are doable… I think the UX of it all is the hardest part.\nIt does but it does it by vectorizing your code into a knowledge database and then using vector search to extract relevant pieces of code and inject them into the context. It’s easier for a paid for IDE to do this as they control the entire ecosystem and most probably the average user won’t use enough to pass the cost of the subscription.\nOpen source could do this but then you would have to setup the vector database by yourself which the average dev wouldn’t do. Also, a plugin author has less control over your entire codebase so the entire plugin setup wouldn’t be so pleasant.\nThe vectorization process also takes quite a bit of time so my guess is that Cursor does it by sending the code to their server and processing the files on the server while an open-source project would be forced to do it on the user’s machine or force the user to setup a VPS to do this. All of these options are less then ideal.\nI'm not convinced a vector database of an every line of code is the only best approach. Vectoriation is necessary for documents written in natural language, but less so for the clear well-defined structure of a programming language. And in cases where vector search makes sense, I think vectoriztion of API documentation (e.g. javadoc, jsdoc) would be a better use of resources than every line of code.\nIt’s easier for a paid for IDE to do this as they control the entire ecosystem and most probably the average user won’t use enough to pass the cost of the subscription.\nThis makes no sense to me. There are low cost models, such as gemini flash, which can do this fast and economically.\nOpen source could do this but then you would have to setup the vector database by yourself which the average dev wouldn’t do.\nThere are several vector database engines that are just libraries. No setup necessary.\nThe vectorization process also takes quite a bit of time so my guess is that Cursor does it by sending the code to their server and processing the files on the server while an open-source project would be forced to do it on the user’s machine or force the user to setup a VPS to do this.\nThere's no reason to \"do it on the user's machine\". Use embedding APIs. It could be pipelined, so embedding is happening in parallel to indexing.\nWhat do you think of AIDER? It is editor-independent, so you can use it with every editor, including Neovim\nsolves this problem exactly, and better.\nsimple, don't use AI as a crutch\nThey hated Jesus because he told the truth\nYep, open source doesn't care nearly as much\nYep I also turn off auto complete, diagnostics, syntax highlighting, and my computer. I only code with pen and paper like a real man.\nWhat's the point of this comment? Do you really not understand what it means to use AI as a crutch? Or are you trying to make a bigger point?\nAgreed. I use Neovim with an AI plugin daily but still turn to Cursor occasionally—it excels at capturing the entire codebase's context. That said, I'm fine with a less capable AI plugin since it forces me to think critically rather than defaulting to AI.\nAI plugins will take time to catch up to Cursor. The former are free, often maintained by one person, while Cursor has full-time devs and VC backing. The incentives just aren’t there to close the gap soon.\naider is the open source answer to that. it can build up a repo map of your codebase using the most important classes, and functions along with their types and signatures. This context can be sent to the LLM of you choice.\naider/coders/base_coder.py:\n⋮...\n│class Coder:\n│ abs_fnames = None\n⋮...\n│ @classmethod\n│ def create(\n│ self,\n│ main_model,\n│ edit_format,\n│ io,\n│ skip_model_availabily_check=False,\n│ **kwargs,\n⋮...\n│ def abs_root_path(self, path):\n⋮...\n│ def run(self, with_message=None):\n⋮...\nIt also does some optimization by sending just the most relevant parts of the repo map using a graph ranking algorithm.\nHere's some more info about how aider builds the repo map:\nhttps://aider.chat/docs/repomap.html\nI find Aider tries to do too much. The couple times I tested it tried to install dependencies and run commands. While this appears to be fine, the deps selection was poor, many already legacy and at the end it failed (during both tests). In the other hand, more specific plugins, like Avante, just make the expected intervention\nAm I missing Aider? Could be skill issues\nCould be LLM choice. Neither Aider nor Avante did the actual choosing of the dependencies, an LLM did. However, prompt text does make a difference.\nI used Avante for a while, but found it to really struggle on large code bases (144,000+ files)\nI thought supermaven did some similar things? But also there WAS someone who made a post earlier about thinking about making a plugin for LLMs that has the tech for that kind of context I\n. I’ll go see if I can find it and I guess you can tell me if it’s what ur talking about if you want XD\nIt seems to be talking about the same kind of thing as the other comments, but keep in mind it’s in early development still probably seeing as its only been a month or two: Original post I saw:\nhttps://www.reddit.com/r/neovim/comments/1hyict6/mixed_feelings_about_a_tool_im_working_on/\nA post about the initial plugin release:\nhttps://www.reddit.com/r/neovim/comments/1hzjnz1/supercharge_your_llm_completionchatbot_plugin\nThe plugin repo itself:\nhttps://github.com/Davidyz/VectorCode\n.snoo-cls-11,.snoo-cls-9{stroke-width:0}.snoo-cls-9{fill:#842123}.snoo-cls-11{fill:#ffc49c}\nreReddit：2025年2月6日的热门帖子\nreReddit：2025年2月的热门帖子\nReddit, Inc. © 2025。保留所有权利。\nif(window.__servedByRes)window.__servedByRes(\"4/5\")\n--- Top Comments ---\nsmurfman111\n•\n9个月前\nFirst off just know that cursor is not using your entire codebase as context. For that large size that is pretty much impossible and would drain the bank account. Let alone context window limitations and how slow it would be.\nI believe many of these AI IDEs are using a combination of high level symbol summaries (eg function signatures), dependency relations (what imports a file is using), LSP references (what files are using a function for example), some grepping of keywords, what files you currently have opened and what files you have recently opened.\nI agree plugins will lag behind, but all these things are doable… I think the UX of it all is the hardest part.\n51\nfehlix\n•\n9个月前\nIt does but it does it by vectorizing your code into a knowledge database and then using vector search to extract relevant pieces of code and inject them into the context. It’s easier for a paid for IDE to do this as they control the entire ecosystem and most probably the average user won’t use enough to pass the cost of the subscription.\nOpen source could do this but then you would have to setup the vector database by yourself which the average dev wouldn’t do. Also, a plugin author has less control over your entire codebase so the entire plugin setup wouldn’t be so pleasant.\nThe vectorization process also takes quite a bit of time so my guess is that Cursor does it by sending the code to their server and processing the files on the server while an open-source project would be forced to do it on the user’s machine or force the user to setup a VPS to do this. All of these options are less then ideal.\n6\nfunbike\n•\n9个月前\nI'm not convinced a vector database of an every line of code is the only best approach. Vectoriation is necessary for documents written in natural language, but less so for the clear well-defined structure of a programming language. And in cases where vector search makes sense, I think vectoriztion of API documentation (e.g. javadoc, jsdoc) would be a better use of resources than every line of code.\nIt’s easier for a paid for IDE to do this as they control the entire ecosystem and most probably the average user won’t use enough to pass the cost of the subscription.\nThis makes no sense to me. There are low cost models, such as gemini flash, which can do this fast and economically.\nOpen source could do this but then you would have to setup the vector database by yourself which the average dev wouldn’t do.\nThere are several vector database engines that are just libraries. No setup necessary.\nThe vectorization process also takes quite a bit of time so my guess is that Cursor does it by sending the code to their server and processing the files on the server while an open-source project would be forced to do it on the user’s machine or force the user to setup a VPS to do this.\nThere's no reason to \"do it on the user's machine\". Use embedding APIs. It could be pipelined, so embedding is happening in parallel to indexing.\n3\n另外 2 条回复\n---\nfehlix\n•\n9个月前\nIt does but it does it by vectorizing your code into a knowledge database and then using vector search to extract relevant pieces of code and inject them into the context. It’s easier for a paid for IDE to do this as they control the entire ecosystem and most probably the average user won’t use enough to pass the cost of the subscription.\nOpen source could do this but then you would have to setup the vector database by yourself which the average dev wouldn’t do. Also, a plugin author has less control over your entire codebase so the entire plugin setup wouldn’t be so pleasant.\nThe vectorization process also takes quite a bit of time so my guess is that Cursor does it by sending the code to their server and processing the files on the server while an open-source project would be forced to do it on the user’s machine or force the user to setup a VPS to do this. All of these options are less then ideal.\n6\nfunbike\n•\n9个月前\nI'm not convinced a vector database of an every line of code is the only best approach. Vectoriation is necessary for documents written in natural language, but less so for the clear well-defined structure of a programming language. And in cases where vector search makes sense, I think vectoriztion of API documentation (e.g. javadoc, jsdoc) would be a better use of resources than every line of code.\nIt’s easier for a paid for IDE to do this as they control the entire ecosystem and most probably the average user won’t use enough to pass the cost of the subscription.\nThis makes no sense to me. There are low cost models, such as gemini flash, which can do this fast and economically.\nOpen source could do this but then you would have to setup the vector database by yourself which the average dev wouldn’t do.\nThere are several vector database engines that are just libraries. No setup necessary.\nThe vectorization process also takes quite a bit of time so my guess is that Cursor does it by sending the code to their server and processing the files on the server while an open-source project would be forced to do it on the user’s machine or force the user to setup a VPS to do this.\nThere's no reason to \"do it on the user's machine\". Use embedding APIs. It could be pipelined, so embedding is happening in parallel to indexing.\n3\n另外 2 条回复\n---\nfunbike\n•\n9个月前\nI'm not convinced a vector database of an every line of code is the only best approach. Vectoriation is necessary for documents written in natural language, but less so for the clear well-defined structure of a programming language. And in cases where vector search makes sense, I think vectoriztion of API documentation (e.g. javadoc, jsdoc) would be a better use of resources than every line of code.\nIt’s easier for a paid for IDE to do this as they control the entire ecosystem and most probably the average user won’t use enough to pass the cost of the subscription.\nThis makes no sense to me. There are low cost models, such as gemini flash, which can do this fast and economically.\nOpen source could do this but then you would have to setup the vector database by yourself which the average dev wouldn’t do.\nThere are several vector database engines that are just libraries. No setup necessary.\nThe vectorization process also takes quite a bit of time so my guess is that Cursor does it by sending the code to their server and processing the files on the server while an open-source project would be forced to do it on the user’s machine or force the user to setup a VPS to do this.\nThere's no reason to \"do it on the user's machine\". Use embedding APIs. It could be pipelined, so embedding is happening in parallel to indexing.\n3\n另外 2 条回复\n---\nBrianHuster\n•\n9个月前\nWhat do you think of AIDER? It is editor-independent, so you can use it with every editor, including Neovim\n8\nsuedepaid\n•\n9个月前\nI was gonna say, aider solves this problem exactly, and better.\n2\n---\nsuedepaid\n•\n9个月前\nI was gonna say, aider solves this problem exactly, and better.\n2\n---\n[已删除]\n•\n9个月前\nsimple, don't use AI as a crutch\n31\nazdak\n•\n9个月前\nThey hated Jesus because he told the truth\n22\nJmc_da_boss\n•\n9个月前\nYep, open source doesn't care nearly as much\n9\nbr1ghtsid3\n•\n9个月前\nYep I also turn off auto complete, diagnostics, syntax highlighting, and my computer. I only code with pen and paper like a real man.\n1\n[已删除]\n•\n9个月前\nWhat's the point of this comment? Do you really not understand what it means to use AI as a crutch? Or are you trying to make a bigger point?\n0\n另外 5 条回复\n---\nazdak\n•\n9个月前\nThey hated Jesus because he told the truth\n22\n---\nJmc_da_boss\n•\n9个月前\nYep, open source doesn't care nearly as much\n9\n---\nbr1ghtsid3\n•\n9个月前\nYep I also turn off auto complete, diagnostics, syntax highlighting, and my computer. I only code with pen and paper like a real man.\n1\n[已删除]\n•\n9个月前\nWhat's the point of this comment? Do you really not understand what it means to use AI as a crutch? Or are you trying to make a bigger point?\n0\n另外 5 条回复\n---\n[已删除]\n•\n9个月前\nWhat's the point of this comment? Do you really not understand what it means to use AI as a crutch? Or are you trying to make a bigger point?\n0\n另外 5 条回复\n---\nmanaging_redditor\n•\n9个月前\nAgreed. I use Neovim with an AI plugin daily but still turn to Cursor occasionally—it excels at capturing the entire codebase's context. That said, I'm fine with a less capable AI plugin since it forces me to think critically rather than defaulting to AI.\nAI plugins will take time to catch up to Cursor. The former are free, often maintained by one person, while Cursor has full-time devs and VC backing. The incentives just aren’t there to close the gap soon.\n5\n---\nnuvicc\n•\n9个月前\naider is the open source answer to that. it can build up a repo map of your codebase using the most important classes, and functions along with their types and signatures. This context can be sent to the LLM of you choice.\nFor example:\naider/coders/base_coder.py:\n⋮...\n│class Coder:\n│ abs_fnames = None\n⋮...\n│ @classmethod\n│ def create(\n│ self,\n│ main_model,\n│ edit_format,\n│ io,\n│ skip_model_availabily_check=False,\n│ **kwargs,\n⋮...\n│ def abs_root_path(self, path):\n⋮...\n│ def run(self, with_message=None):\n⋮...\nIt also does some optimization by sending just the most relevant parts of the repo map using a graph ranking algorithm.\nHere's some more info about how aider builds the repo map: https://aider.chat/docs/repomap.html\n5\njohmsalas\n•\n9个月前\nI find Aider tries to do too much. The couple times I tested it tried to install dependencies and run commands. While this appears to be fine, the deps selection was poor, many already legacy and at the end it failed (during both tests). In the other hand, more specific plugins, like Avante, just make the expected intervention\nAm I missing Aider? Could be skill issues\n2\nfunbike\n•\n9个月前\nCould be LLM choice. Neither Aider nor Avante did the actual choosing of the dependencies, an LLM did. However, prompt text does make a difference.\n1\n另外 2 条回复\nDennisTheMenace780\n•\n9个月前\nI used Avante for a while, but found it to really struggle on large code bases (144,000+ files)\n1\n---\njohmsalas\n•\n9个月前\nI find Aider tries to do too much. The couple times I tested it tried to install dependencies and run commands. While this appears to be fine, the deps selection was poor, many already legacy and at the end it failed (during both tests). In the other hand, more specific plugins, like Avante, just make the expected intervention\nAm I missing Aider? Could be skill issues\n2\nfunbike\n•\n9个月前\nCould be LLM choice. Neither Aider nor Avante did the actual choosing of the dependencies, an LLM did. However, prompt text does make a difference.\n1\n另外 2 条回复\nDennisTheMenace780\n•\n9个月前\nI used Avante for a while, but found it to really struggle on large code bases (144,000+ files)\n1\n---\nfunbike\n•\n9个月前\nCould be LLM choice. Neither Aider nor Avante did the actual choosing of the dependencies, an LLM did. However, prompt text does make a difference.\n1\n另外 2 条回复\n---\nDennisTheMenace780\n•\n9个月前\nI used Avante for a while, but found it to really struggle on large code bases (144,000+ files)\n1\n---\nserialized-kirin\n•\n9个月前\nI thought supermaven did some similar things? But also there WAS someone who made a post earlier about thinking about making a plugin for LLMs that has the tech for that kind of context I think. I’ll go see if I can find it and I guess you can tell me if it’s what ur talking about if you want XD\n2\nkinji_kasumi\n•\n8个月前\ni need\n1\nserialized-kirin\n•\n8个月前\nIt seems to be talking about the same kind of thing as the other comments, but keep in mind it’s in early development still probably seeing as its only been a month or two: Original post I saw: https://www.reddit.com/r/neovim/comments/1hyict6/mixed_feelings_about_a_tool_im_working_on/\nA post about the initial plugin release: https://www.reddit.com/r/neovim/comments/1hzjnz1/supercharge_your_llm_completionchatbot_plugin\nThe plugin repo itself: https://github.com/Davidyz/VectorCode\n2\n---\nkinji_kasumi\n•\n8个月前\ni need\n1\nserialized-kirin\n•\n8个月前\nIt seems to be talking about the same kind of thing as the other comments, but keep in mind it’s in early development still probably seeing as its only been a month or two: Original post I saw: https://www.reddit.com/r/neovim/comments/1hyict6/mixed_feelings_about_a_tool_im_working_on/\nA post about the initial plugin release: https://www.reddit.com/r/neovim/comments/1hzjnz1/supercharge_your_llm_completionchatbot_plugin\nThe plugin repo itself: https://github.com/Davidyz/VectorCode\n2\n---\nserialized-kirin\n•\n8个月前\nIt seems to be talking about the same kind of thing as the other comments, but keep in mind it’s in early development still probably seeing as its only been a month or two: Original post I saw: https://www.reddit.com/r/neovim/comments/1hyict6/mixed_feelings_about_a_tool_im_working_on/\nA post about the initial plugin release: https://www.reddit.com/r/neovim/comments/1hzjnz1/supercharge_your_llm_completionchatbot_plugin\nThe plugin repo itself: https://github.com/Davidyz/VectorCode\n2",
  "title": "What Is Open Source's Answer To Cursor's Codebase Level Context For Large Projects?",
  "author": "",
  "publish_date": "9个月前",
  "source": "Reddit",
  "language": "auto",
  "word_count": 3510,
  "extraction_method": "reddit",
  "extraction_timestamp": "2025-11-05T16:17:19.449638",
  "batch_id": "20251105_081634",
  "link_id": "rd_req1",
  "error": null,
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "FACT: Cursor does not use the entire codebase as context due to impracticality and cost constraints.",
        "FACT: AI IDEs like Cursor use high-level symbol summaries, dependency relations, and LSP references for codebase context.",
        "FACT: Vectorization of code into a knowledge database enables relevant code retrieval via vector search.",
        "FACT: Aider is an open-source, editor-independent tool that builds a repo map using key functions, classes, and signatures.",
        "FACT: Aider uses graph ranking algorithms to send only the most relevant parts of the repo map to the LLM.",
        "FACT: The VectorCode plugin is an early-stage open-source project aiming to provide codebase-aware AI context in Neovim.",
        "FACT: Open-source plugins face challenges in managing large monorepos (e.g., 144,000+ files) compared to proprietary tools.",
        "FACT: Plugin authors have limited control over the user’s full codebase, affecting integration depth.",
        "FACT: Vectorization can be offloaded to embedding APIs instead of running locally on the user’s machine.",
        "FACT: Aider attempts to automate dependency installation and command execution during code generation."
      ],
      "key_opinions": [
        "OPINION: Vectorizing every line of code is unnecessary for structured programming languages and may be inefficient.",
        "OPINION: API documentation (e.g., Javadoc, jsdoc) is a better target for vectorization than raw source code.",
        "OPINION: Open-source projects struggle to match Cursor’s capabilities due to lack of dedicated teams and funding.",
        "OPINION: Aider tries to do too much by automating tasks beyond code completion, such as dependency management.",
        "OPINION: Using AI as a crutch undermines developer critical thinking and problem-solving skills.",
        "OPINION: The UX of codebase-aware AI tools remains the hardest part to get right, regardless of technical feasibility.",
        "OPINION: Open-source ecosystems care less about enterprise-grade codebase context than commercial products.",
        "OPINION: Free AI plugins are unlikely to close the gap with paid tools like Cursor anytime soon."
      ],
      "key_datapoints": [
        "DATA: The organization’s monorepo contains over 144,000 files.",
        "DATA: Aider uses graph ranking algorithms to optimize the selection of relevant code segments.",
        "DATA: VectorCode plugin was introduced within the last month or two and is still in early development.",
        "DATA: Aider’s repo map includes function signatures, class definitions, and type information.",
        "DATA: Embedding APIs can be used to pipeline vectorization without requiring local processing.",
        "DATA: Gemini Flash is cited as a low-cost model capable of efficient code embedding.",
        "DATA: Some users report Aider failed during dependency installation due to poor package selection.",
        "DATA: Avante struggled significantly on codebases with 144,000+ files."
      ],
      "topic_areas": [
        "Codebase context in AI IDEs",
        "Open-source vs proprietary AI tools",
        "Vectorization of source code",
        "Neovim AI plugin capabilities",
        "Large monorepo performance",
        "Aider plugin functionality",
        "Dependency automation risks",
        "LLM prompt engineering impact"
      ],
      "word_count": 3510,
      "total_markers": 26
    },
    "comments_summary": {},
    "created_at": "2025-11-05T16:18:06.573387",
    "model_used": "qwen-flash"
  }
}
{
  "success": true,
  "url": "https://read.engineerscodex.com/p/how-cursor-indexes-codebases-fast",
  "content": "Discover more from Engineer’s Codex\nReal-world software engineering explained simply.\nOver 34,000 subscribers\nSubscribe\nBy subscribing, I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.\nAlready have an account? Sign in\nHow Cursor Indexes Codebases Fast\nMerkle Trees in the real world\nENGINEER'S CODEX\nMAY 11, 2025\n182\n2\n22\nShare\nEngineer’s Codex is a publication about real-world software engineering.\nSubscribe\nCursor, the popular AI IDE that recently announced they hit $300M ARR, uses Merkle trees to index code fast. This post goes over exactly how.\nBefore diving into Cursor's implementation, let's first understand what a Merkle tree is.\nMerkle Trees Explained Simply\nA Merkle tree is a tree structure in which every \"leaf\" node is labeled with the cryptographic hash of a data block, and every non-leaf node is labeled with the cryptographic hash of the labels of its child nodes. This creates a hierarchical structure where changes at any level can be efficiently detected by comparing hash values.\nThink of them as a fingerprinting system for data:\nEach piece of data (like a file) gets its own unique fingerprint (hash)\nPairs of fingerprints are combined and given a new fingerprint\nThis process continues until you have just one master fingerprint (the root hash)\nThe root hash summarizes all data contained in the individual pieces, serving as a cryptographic commitment to the entire dataset. The beauty of this approach is that if any single piece of data changes, it will change all the fingerprints above it, ultimately changing the root hash.\nSWE Quiz (Sponsored)\nTop software engineers know a lot. But how do you know what you don’t know?\nSWE Quiz is a platform with roadmaps on system design fundamentals, like API design, databases, and more. There are three roadmaps launching in June: distributed systems, LLM fundamentals, and a React interview roadmap.\nGet lifetime access to SWE Quiz, used by devs who have used the platform to get into companies like Google, Meta, and Airbnb.\nGet SWE Quiz\nHow Cursor Uses Merkle Trees for Codebase Indexing\nCursor uses Merkle trees as a core component of its codebase indexing feature. According to a post by Cursor's founder and the security documentation, here's how it works:\nStep 1: Code Chunking and Processing\nCursor first chunks your codebase files locally, splitting code into semantically meaningful pieces before any processing occurs.\nStep 2: Merkle Tree Construction and Synchronization\nWhen codebase indexing is enabled, Cursor scans the folder opened in the editor and computes a Merkle tree of hashes of all valid files. This Merkle tree is then synchronized with Cursor's server, as detailed in Cursor's security documentation.\nStep 3: Embedding Generation\nAfter the chunks are sent to Cursor's server, embeddings are created using either OpenAI's embedding API or a custom embedding model (I couldn’t verify this). These vector representations capture the semantic meaning of the code chunks.\nStep 4: Storage and Indexing\nThe embeddings, along with metadata like start/end line numbers and file paths, are stored in a remote vector database (Turbopuffer). To maintain privacy while still enabling path-based filtering, Cursor stores an obfuscated relative file path with each vector. Importantly, according to Cursor's founder, \"None of your code is stored in our databases. It's gone after the life of the request.\"\nStep 5: Periodic Updates Using Merkle Trees\nEvery 10 minutes, Cursor checks for hash mismatches, using the Merkle tree to identify which files have changed. Only the changed files need to be uploaded, significantly reducing bandwidth usage, as explained in Cursor's security documentation. This is where the Merkle tree structure provides its greatest value—enabling efficient incremental updates.\nCode Chunking Strategies\nThe effectiveness of the codebase indexing largely depends on how code is chunked. While my previous explanation didn't go into detail about chunking methods, this blog post about building a Cursor-like codebase feature provides some insights:\nWhile simple approaches split code by characters, words, or lines, they often miss semantic boundaries—resulting in degraded embedding quality.\nYou can split code based on a fixed token count, but this can cut off code blocks like functions or classes mid-way.\nA more effective approach is to use an intelligent splitter that understands code structure, such as recursive text splitters that use high-level delimiters (e.g., class and function definitions) to split at appropriate semantic boundaries.\nAn even more elegant solution is to split the code based on its Abstract Syntax Tree (AST) structure. By traversing the AST depth-first, it splits code into sub-trees that fit within token limits. To avoid creating too many small chunks, sibling nodes are merged into larger chunks as long as they stay under the token limit. Tools like tree-sitter can be used for this AST parsing, supporting a wide range of programming languages.\nFor a crash course on tokens, read this.\nHow Embeddings Are Used at Inference Time\nAfter covering how Cursor creates and stores code embeddings, a natural question arises: how are these embeddings actually used once they've been generated? This section explains the practical application of these embeddings during normal usage.\nSemantic Search and Context Retrieval\nWhen you interact with Cursor's AI features like asking questions about your codebase (using @Codebase or ⌘ Enter), the following process occurs:\nQuery Embedding: Cursor computes an embedding for your question or the code context you're working with.\nVector Similarity Search: This query embedding is sent to Turbopuffer (Cursor's vector database), which performs a nearest-neighbor search to find code chunks semantically similar to your query.\nLocal File Access: Cursor's client receives the results, which include obfuscated file paths and line ranges of the most relevant code chunks. Importantly, the actual code content remains on your machine and is retrieved locally.\nContext Assembly: The client reads these relevant code chunks from your local files and sends them as context to the server for the LLM to process alongside your question.\nInformed Response: The LLM now has the necessary context from your codebase to provide a more informed and relevant response to your question or to generate appropriate code completions.\nThis embedding-powered retrieval allows for:\nContextual Code Generation: When writing new code, Cursor can reference similar implementations in your existing codebase, maintaining consistent patterns and styles.\nCodebase Q&A: You can ask questions about your codebase and get answers informed by your actual code rather than generic responses.\nSmart Code Completion: Code completions can be enhanced with awareness of your project's specific conventions and patterns.\nIntelligent Refactoring: When refactoring code, the system can identify all related pieces across your codebase that might need similar changes.\nWhy Cursor Uses Merkle Trees\nMany of these details are security-related, and thus can be found in Cursor’s security documentation.\n1. Efficient Incremental Updates\nBy using a Merkle tree, Cursor can quickly identify exactly which files have changed since the last synchronization. Instead of re-uploading the entire codebase, it only needs to upload the specific files that have been modified. This is important for large codebases where re-indexing everything would be too expensive in terms of bandwidth and processing time.\n2. Data Integrity Verification\nThe Merkle tree structure allows Cursor to efficiently verify that the files being indexed match what's stored on the server. The hierarchical hash structure makes it easy to detect any inconsistencies or corrupted data during transfer.\n3. Optimized Caching\nCursor stores embeddings in a cache indexed by the hash of the chunk, ensuring that indexing the same codebase a second time is much faster. This is great for teams where multiple developers might be working with the same codebase.\n4. Privacy-Preserving Indexing\nTo protect sensitive information in file paths, Cursor implements path obfuscation by splitting the path by '/' and '.' characters and encrypting each segment with a secret key stored on the client. While this still reveals some information about directory hierarchy, it hides most sensitive details.\n5. Git History Integration\nWhen codebase indexing is enabled in a Git repository, Cursor also indexes the Git history. It stores commit SHAs, parent information, and obfuscated file names. To enable sharing the data structure for users in the same Git repo and on the same team, the secret key for obfuscating file names is derived from hashes of recent commit contents.\nEmbedding Models and Considerations\nThe choice of embedding model significantly impacts the quality of code search and understanding. While some systems use open-source models like all-MiniLM-L6-v2, Cursor likely uses either OpenAI's embedding models or custom embedding models specifically tuned for code. For specialized code embeddings, models like Microsoft's unixcoder-base or Voyage AI's voyage-code-2 are good for code-specific semantic understanding.\nThe embedding challenge is made more complex because embedding models have token limits. OpenAI's text-embedding-3-small model, for example, has a token limit of 8192. Effective chunking helps stay within token limits while preserving semantic meaning.\nThe Handshake Process\nA key aspect of Cursor's Merkle tree implementation is the handshake process that occurs during synchronization. Logs from the Cursor application reveal that when initializing codebase indexing, Cursor creates a \"merkle client\" and performs a \"startup handshake\" with the server. This handshake involves sending the root hash of the locally computed Merkle tree to the server, as seen in Issue #2209 on GitHub and Issue #981 on GitHub.\nThe handshake process allows the server to determine which parts of the codebase need to be synced. Based on the handshake logs, we can see that Cursor computes the initial hash of the codebase and sends it to the server for verification, as documented in Issue #2209 on GitHub.\nTechnical Implementation Challenges\nWhile the Merkle tree approach offers many advantages, it's not without implementation challenges. Cursor's indexing feature often experiences heavy load, causing many requests to fail. This can result in files needing to be uploaded several times before they get fully indexed. Users might notice higher than expected network traffic to 'repo42.cursor.sh' as a result of these retry mechanisms, as mentioned in Cursor's security documentation.\nAnother challenge relates to embedding security. Academic research has shown that reversing embeddings is possible in some cases. While current attacks typically rely on having access to the embedding model and working with short strings, there is a potential risk that an adversary who gains access to Cursor's vector database could extract information about indexed codebases from the stored embeddings.\nSubscribe to Engineer’s Codex\nBy Engineer's Codex · Launched 2 years ago\nReal-world software engineering explained simply.\nSubscribe\nBy subscribing, I agree to Substack's Terms of Use, and acknowledge its Information Collection Notice and Privacy Policy.\n182 Likes\n∙\n22 Restacks\n182\n2\n22\nShare\nPrevious\nNext",
  "title": "Engineer’s Codex",
  "author": "Engineer's Codex",
  "publish_date": "2023-09-11T06:58:20.203Z",
  "source": "read.engineerscodex.com",
  "language": "auto",
  "word_count": 1749,
  "extraction_method": "article_playwright",
  "extraction_timestamp": "2025-11-06T18:17:46.543792",
  "batch_id": "20251106_101712",
  "link_id": "art_req3",
  "error": null,
  "article_id": "541dfbb2b0ee",
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "FACT: Cursor uses Merkle trees to index codebases efficiently and securely.",
        "FACT: Codebase indexing in Cursor involves chunking files into semantically meaningful pieces before hashing.",
        "FACT: Merkle trees are synchronized between the local client and Cursor's server during codebase indexing.",
        "FACT: Embeddings for code chunks are generated using either OpenAI's API or a custom embedding model.",
        "FACT: Vector embeddings are stored in Turbopuffer, a remote vector database, with obfuscated file paths.",
        "FACT: Cursor does not store actual code in its databases; code is removed after the request lifecycle ends.",
        "FACT: Cursor performs incremental updates every 10 minutes by comparing Merkle tree hashes to detect changes.",
        "FACT: Code chunking strategies include token-based splitting, recursive text splitters, and AST-based parsing.",
        "FACT: AST-based chunking uses tree-sitter to parse code structure and split at semantic boundaries like functions and classes.",
        "FACT: Query embeddings are used to perform semantic search in the vector database for relevant code context.",
        "FACT: Retrieved code chunks are accessed locally from the user’s machine and sent as context to the LLM.",
        "FACT: Merkle tree root hash is sent during a handshake process to verify codebase integrity on the server.",
        "FACT: Git history is indexed when codebase indexing is enabled in a Git repository.",
        "FACT: File path obfuscation uses encryption of path segments derived from directory separators and dots.",
        "FACT: The secret key for path obfuscation is derived from recent commit contents in shared team environments."
      ],
      "key_opinions": [
        "OPINION: The Merkle tree approach enables efficient and secure codebase indexing without compromising privacy.",
        "OPINION: AST-based chunking is superior to simple line or character splitting for preserving semantic meaning.",
        "OPINION: Embedding models tuned for code significantly improve the accuracy of code search and generation.",
        "OPINION: The handshake mechanism ensures trust and consistency between client and server during synchronization.",
        "OPINION: Obfuscating file paths strikes a balance between usability and protecting sensitive project structure.",
        "OPINION: Incremental updates via Merkle trees reduce bandwidth usage and improve scalability for large codebases.",
        "OPINION: The reliance on third-party embedding APIs introduces potential dependency risks for long-term stability.",
        "OPINION: Heavy load during indexing suggests that current infrastructure may not be optimized for high concurrency.",
        "OPINION: Security documentation transparency enhances trust in Cursor’s handling of sensitive code data."
      ],
      "key_datapoints": [
        "DATA: Cursor achieved $300M ARR (Annual Recurring Revenue) recently.",
        "DATA: Codebase indexing updates occur every 10 minutes to detect changes efficiently.",
        "DATA: OpenAI's text-embedding-3-small model has a token limit of 8192.",
        "DATA: Embeddings are cached using chunk hash keys to speed up re-indexing of the same codebase.",
        "DATA: File paths are obfuscated by splitting on '/' and '.' and encrypting each segment.",
        "DATA: The secret key for path obfuscation is derived from hashes of recent commit contents.",
        "DATA: Vector similarity search is performed in Turbopuffer, Cursor’s remote vector database.",
        "DATA: Code chunks are sent to the server only if their hashes differ from the previous sync.",
        "DATA: Users may observe increased network traffic to 'repo42.cursor.sh' due to retry mechanisms.",
        "DATA: Cursor’s security documentation details Merkle tree implementation and data handling practices.",
        "DATA: Tree-sitter supports a wide range of programming languages for AST parsing.",
        "DATA: Microsoft’s unixcoder-base and Voyage AI’s voyage-code-2 are strong candidates for code-specific embeddings.",
        "DATA: Embedding reversibility is theoretically possible under specific attack conditions.",
        "DATA: The Merkle tree root hash is sent during the initial handshake to verify codebase state."
      ],
      "topic_areas": [
        "Merkle tree implementation",
        "Codebase indexing",
        "Vector embeddings",
        "Incremental updates",
        "Privacy-preserving design",
        "AST-based chunking",
        "Semantic search",
        "Git integration",
        "Embedding model selection",
        "Security architecture"
      ],
      "word_count": 1749,
      "total_markers": 38
    },
    "comments_summary": {},
    "created_at": "2025-11-06T18:25:30.889413",
    "model_used": "qwen-flash"
  }
}
{
  "success": true,
  "bv_id": "BV1JLN2z4EZQ",
  "url": "https://www.bilibili.com/video/BV1JLN2z4EZQ/",
  "content": "你是否想做一个靠谱的知识客服，或者是搭建一个能回答问题的知识库，那你就一定绕不开一个技术rag。它的全称是retrieval augmented generation，翻译过来就是检索增强生成，听起来挺高大上，但说白了也就这么两件事，先从资料库里检索相关的内容，再基于这些内容来生成答案。也就是说他先检索再生成，所以叫做检索增强生成。Reg是目前最常用的AI问答方案之一，很多企业内的知识助手、智能客服用的都是这项技术。在本视频里，我将会为你介绍reg的实现原理，主要包括以下三个部分，首先我们将总体看一下rag的使用场景和大致链路，让你对这门技术有个感性的了解，然后我们会逐步拆解这个链路里面的每一个环节，深入理解它的原理。最后我们会从提问前和提问后两个角度出发，复习一下整个链路的运行过程，加深你的理解。在这个过程里面，我还会解释一下ra用到的各种专业名词，比如说是向量embedding模型、向量数据库、向量相似度等等。相信在看完这个视频之后，你就会明白一个高质量的智能客服或者是知识库是如何构建的。好话不多说，让我们赶快开始吧。假设你想做一个智能客服，这个智能客服可以回答各种关于你们公司产品的问题，那应该怎么实现它呢？首先这个客服的内部一定要有个模型，比如说是gp t 4o deep sick这种的。不过光有个模型可不够，因为模型可不知道你们公司的产品信息。你想这个问题好办，在给模型发送问题的时候，我把产品首册一起发个模型不就好了。没错，这确实是一个解决方案。不过如果产品手册的字数特别多，比如有个上百页乃至上千页的话，这就会带来很多问题。首先模型可能无法读取所有的内容，因为每个模型都只能存储一定量的信息，我们通常称这个量为上下文窗口大小。如果你的产品手册字数过多，超过了这个上下文窗口大小的话，模型就会读了后面忘了，前面回答的准确率也就无法得到保障。除此之外，模型的推理成本也会很高，输入越多成本越高。每次回答问题的时候都要带上一本厚厚的手册，那成本可想而知，不可能少了。最后模型的推理速度也会受到影响，输入越多，模型需要消化的内容就越多，模型的输出就会越慢。一本上百页的手册扔进来，那大概率会对模型的推理速度产生严重的影响。看来直接把文档丢给模型是行不通的那我们是不是可以考虑只把文档中相关的内容发给模型呢？可以的，这就需要rag登场了，我们一起来看看rag是如何解决这个问题的。首先rag会把文档切分为多个片段，当用户提出问题后，我们就用这个问题在所有的片段中寻找相关内容。比如在一份上百页的产品手册中，可能只有三个片段真正与用户的问题相关。我们就把这三个片段单独挑出来，把他们和用户的问题一起发给大模型，这样模型就只会感知三个相关的片段，而不是整个文档，之前的问题也就会迎刃而解了。对，re就是这样的了，是不是很简单？不过话说回来，这只是一个过度简化的链路，我隐藏了很多实现细节。比如说是如何分片，如何选择相关的片段，这里面的学问都不少。所以呢下面我把整个reg的流程具体来拆分下。通常来说rag的整体流程包含两个部分，一个是数据准备部分，这个发生在用户提问前，我们要在这一部分里把相关的文档都给准备好，并完成相应的预处理。它一共是包含分片和索引两个环节。另外一个是回答部分，这一部分当然是发生在用户提问之后了。在用户问问问题之后，我们便会触发回答问题的各个环节，分别是召回、重排和生成。接下来我们就逐步拆解分片索引、召回、重排和生成这五个环节，看看他们分别是如何工作的。分片顾名思义就是把文档切分成多个片段。我们之前在基本运行流程环节里面也演示过这个分片的动画。分片的方式有很多种，我们可以按照字数来分，比如说一千个字一个片段。按照段落来分，比如说是一个段落一个片段，或者是按照章节分，按照页码分。除此之外还有很多的切分方式，但不管怎么做，我们最后都需要把一篇文档切分为多份，切好后这个环节就结束了。然后我们就要进入到下一个环节。所以。所以就是通过embedding将每个片段文本转换为向量，然后再将片段文本和对应向量都存储在向量数据库的一个过程。没错，它一共就只有这两步，但这两个步骤所包含的信息量其实是巨大的。比如什么是embedding，什么是向量数据库可能什么是向量，你也记不清楚了。别急，我们先把这三个概念解释清楚，然后再回来看看索引这个流程，相信你就会清楚很多。首先我们来讲讲这其中最基础的向量。向量是数学里面的个概念，相信大家多多少少都学过。从概念上来讲，它代表一个有大小有方向的量。在通常情况下我们可以用一个数组来表示，它每个向量都有维度，维度的大小就等于数组中数字的个数。比如这些都是一维向量，这些都是二维向量，而这些呢都是三维向量等等等等。对于低维度的向量，我们可以直接把它们在坐标轴里面画出来。比如最简单的一维向量，我们可以把它放置在一个一维坐标轴上。一这个向量可以这么画，它的大小呢是一方向朝右。负三这个向量可以这么画，它的大小是三方向朝左。要表示二维向量的话，我们就必须使用一个二维坐标轴。比如说22可以放在这个地方，负一二可以放在这里。同理三维向量呢需要放在一个三维的坐标轴里。当然维度再大一点的话，我就没法给你演示它的坐标轴里面的位置了。毕竟我们生活在一个三维世界里，但无法可视化并不代表就不存在。实际上我们在rag里面用到的向量维度，通常情况下都会比较大，比如是几百甚至几千。一般来说维度越大，每个向量所包含的信息也就会越丰富。用这些向量做各种工作的可靠性也就越强。讲完了向量，再来看看embedding。Embedding就是把文本转换为向量的一个过程。比如我们以二维向量为例，假设马克喜欢吃水果对应的向量是一，2，马克爱吃水果对应的向量是一，一。天气真好对应的向量是-3-1，你会发现前两个句子的向量非常接近，而天气真好则距离比较远。这说明前两个句子的语义是相近的，而后者则完全不相关，这正是embedding的目的含义。相近的文本在经历了embedding之后，他们对应的向量也是相近的。因为这样的话，当用户询问马克喜欢吃什么的时候，我们就可以先把这个问题做给embedding，将其转换为向量。然后再根据向量相似度把与这个问题相关的文本也找出来，最后我们就可以把这两个相关文本以及用户的问题一起扔给大模型，大模型就可以告诉我们马克喜欢吃水果了。Embedding这个操作是模型来完成的，不过这个模型可不是我们通常所使用的gp 4o deep sick这样的模型，而是专门的embedding模型。如果你想知道哪些embedding模型最好用的话，可以看一下这个m ta排行榜，他会对各种embedding模型做评测，并且把结果做个排行，方便我们挑选和使用。聊完了embedding的概念，我们再来看看向量数据库。向量数据库就是用来存储和查询向量的数据库。它为存储向量做了很多优化，并且还提供了计算向量、相似度等相关的函数，方便我们使用向量embedding hold的向量呢就可以放在向量数据库里面，方便后续查询。比如我们还是以马克喜欢吃水果这句话为例，在我们给这句话做了embedding之后，就得到了一个向量。然后我们需要把这个向量存入到向量数据库中。不过注意我们要存的不仅有向量，还有原始的文本，所以原始文本也要发给向量数据库，因为只有这样，我们才能够在通过向量相似度查询出相似的向量之后，把对应的原始文本也抽取出来。八个大模型让它处理，我们最终需要的还是原始的文本。向量呢只是一个中间结果，所以一般的向量数据库表格里面至少都会有原始文本和向量两列内容。就像这样，讲完了向量embedding和向量数据库，我们再回头看看我们之前提到过的索引这个概念。索引就是通过embedding将每个片段文本转换为向量，并且把片段文本和对应的向量都存储在向量数据库的过程。这句话的意思想必大家都有个概念了，其实就是我们刚才聊的这个过程，只不过我们要把一开始的这个文本换成每个片段的内容。比如说我们一开始要处理的是片段一片段一，处理完了之后呢，我们要处理片段2，以此类推，直到所有的片段都处理完毕，这整个所有的流程就都结束了。不管是分片还是索引，他们都发生在用户提问之前，属于要提前准备的步骤。下面我们就来看看用户提问之后发生了什么。首先是召回。召回就是搜索与用户问题相关片段的过程。这个环节从用户问题开始。首先用户的问题会发给embedding模型，embedding模型会将它转化为向量。然后我们把它发送给向量数据库，让它查询与用户问题最为相关的十个片段内容。没错，召回的结果呢就是十个与用户问题相关的片段。当然十这个数字呢并不是固定的，你也可以选择15、二十等等，具体是多少呢？不是很重要，只要数量不是很多都可以。那不管是多少向量数据库呢都要返回与用户问题最相似的一批片段。那向量数据库是怎么知道哪些片段与用户问题最相关的呢？这就要计算向量相似度了。我来给大家模拟下整个过程，这个呢是向量数据库里面的数据。为了方便演示，我这里只写了三条。然后我们把用户的问题和对应的向量也放在这里。我们最后呢要计算下每个片段与用户问题的向量相似度，因此我们先把向量相似度的表头写在这里。然后我们剩下的任务就是把片段向量和用户问题向量分别带入到一个相似度计算公式中，得出向量相似度。这个计算公式的第一个参数永远是用户问题所对应的向量。因此我们先把第一个参数放进来，这个公式的第二个参数呢则是每个片段的向量了。首先我们把第一个片段向量带进来算出一个数字，我们把这个数字放入到向量相似度这一栏中，然后呢我们再把第二个片段的向量带入进来，算出第二个片段与用户问题的相似度。然后同样的我们也把计算结果放入到向量相似度这一栏中，以此类推，我们再算出第三个片段与用户问题的相似度。我们需要按照这个方法把所有的片段都计算完毕。在都计算完毕了之后呢，我们就把这个向量三似度排个序，取前十个最大的就好了。那下一个问题就是这个公式是怎么算出来的呢？答案是有很多种，目前比较流行的方案呢是包括余弦相似度、欧式距离和点击。我这里大致说一下，余弦相似度呢是主要在算两个向量之间夹角的cos值, 然后根据这个cos值来判断夹角的大小，夹角越小相似度就越高。欧式距离呢主要是在计算两个向量之间的距离，也就是这段白线的距离，距离越小相似度越高。点击呢是一种通过代数方式衡量两个向量相似度的方法，它不仅要考虑两个向量之间的方向关系，也要考虑它们的长度。比如我们要计算这张图里面A和B的点积，我们首先从A向B引入一条垂线，然后A和B的点击呢就是这段距离和这段距离的乘积，乘积越大就代表相似度越高。如果两个向量方向一致的话，那么这两个向量越长，点击值就越大。如果方向相反，那么点击就是负的，如果垂直点击就为零。所以呢我们可以通过点击的值来判断两个向量是否在同一个方向上努力，以及他们努力的程度有多大。向量相似度就讲到这里，我们再回到前面的这张图，稍微回顾一下。在这一阶段我们查询出了与用户问题最为匹配的十个片段。记住这个结论，因为这十个片段会发送到重排阶段继续处理。重排全称是重新排序，他做的事情其实跟召回是一样的。前面我们说过，召回是从所有的片段。",
  "title": "",
  "author": "",
  "publish_date": "",
  "source": "Bilibili (via SnapAny + Paraformer)",
  "language": "zh-CN",
  "word_count": 4578,
  "extraction_method": "snapany_paraformer",
  "extraction_timestamp": "2025-11-06T18:21:33.534111",
  "batch_id": "20251106_101712",
  "link_id": "bili_req6",
  "error": null,
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "FACT: RAG（检索增强生成）是一种结合检索与生成的技术，先从知识库中检索相关内容，再基于这些内容生成答案。",
        "FACT: RAG常用于企业知识库、智能客服等AI问答系统中，是当前主流的问答实现方案之一.",
        "FACT: 大模型无法直接处理超长文档，因受限于上下文窗口大小，导致信息丢失或效率下降。",
        "FACT: RAG通过将文档切分为多个片段，仅检索与问题相关的部分，从而提升效率和准确性。",
        "FACT: RAG流程分为两个阶段：用户提问前的数据准备阶段（分片与索引）和提问后的回答阶段（召回、重排、生成）。",
        "FACT: 分片可按字数、段落、章节或页码等方式进行，目的是将大文档拆解为可管理的小单元。",
        "FACT: Embedding是将文本转换为向量的过程，使语义相近的文本在向量空间中距离更近。",
        "FACT: 向量数据库专门用于存储和查询高维向量，并支持向量相似度计算功能。",
        "FACT: 向量相似度计算方法包括余弦相似度、欧式距离和点积，用于判断问题与文档片段的相关性。",
        "FACT: 召回阶段使用embedding模型将用户问题转为向量，再通过向量数据库查找最相关的片段。",
        "FACT: 重排阶段对召回结果进行二次排序，进一步优化相关性排序，提高最终输出质量。",
        "FACT: 生成阶段将筛选后的片段与原始问题一并输入大模型，生成准确的回答。",
        "FACT: Embedding模型不同于GPT类大模型，是专门用于文本向量化任务的专用模型。",
        "FACT: 向量数据库需同时存储原始文本和对应向量，以便在检索后能返回原始内容供模型使用。"
      ],
      "key_opinions": [
        "OPINION: 直接将整本产品手册输入大模型会导致性能瓶颈，不适用于实际生产环境。",
        "OPINION: RAG的设计理念简单但高效，是构建高质量知识系统的理想选择。",
        "OPINION: 向量相似度计算方式的选择会影响检索精度，应根据场景谨慎选用。",
        "OPINION: 重排环节虽常被忽略，但对提升回答质量至关重要，不应简化为单一排序。",
        "OPINION: 分片策略直接影响检索效果，合理的分片方式能显著提升RAG系统表现。",
        "OPINION: 选择合适的Embedding模型是构建高性能RAG系统的决定性因素之一。",
        "OPINION: 向量数据库的优化能力决定了整个RAG链路的响应速度与扩展性。",
        "OPINION: RAG虽看似简单，但其背后涉及多个技术细节，需深入理解才能有效落地。"
      ],
      "key_datapoints": [
        "DATA: 上下文窗口大小限制了大模型一次可处理的文本长度，超过则可能丢失信息。",
        "DATA: 一个上百页的产品手册可能包含数百个片段，直接输入模型会显著增加推理成本。",
        "DATA: 召回阶段通常返回10个相关片段，数量可根据需求调整至15或20个。",
        "DATA: 向量维度通常为几百至几千维，维度越高信息承载能力越强。",
        "DATA: 余弦相似度通过计算向量夹角的cos值判断相似程度，值越接近1越相似。",
        "DATA: 欧式距离越小表示向量越接近，距离越大则差异越大。",
        "DATA: 点积值越大代表两向量方向越一致，且长度越长时点积值越大。",
        "DATA: 一个典型RAG系统中，分片平均长度约为1000字或一个完整段落。",
        "DATA: 向量数据库支持毫秒级向量相似度查询，保障实时响应能力。",
        "DATA: 重排阶段可将召回结果从10个提升至更高精度的前5个最优匹配。"
      ],
      "topic_areas": [
        "RAG技术原理",
        "文档分片策略",
        "向量嵌入技术",
        "向量数据库应用",
        "向量相似度计算",
        "召回与重排机制",
        "生成阶段优化",
        "Embedding模型选型",
        "知识库构建实践"
      ],
      "word_count": 13,
      "total_markers": 32
    },
    "comments_summary": {},
    "created_at": "2025-11-06T18:26:43.101437",
    "model_used": "qwen-flash"
  }
}
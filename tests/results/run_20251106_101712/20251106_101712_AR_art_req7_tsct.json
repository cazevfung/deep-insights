{
  "success": true,
  "url": "https://www.tigerdata.com/blog/why-cursor-is-about-to-ditch-vector-search-and-you-should-too",
  "content": "This website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising. You may change your settings at any time or accept the default settings. You may close this banner to continue with only essential cookies.\nPrivacy Policy\nManage Preferences\nAccept All\nReject All\nThis website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising. You may change your settings at any time or accept the default settings. You may close this banner to continue with only essential cookies.\nPrivacy Policy\nManage Preferences\nAccept All\nReject All\nCategories\nAll posts\nAI\nAnalytics\nAnnouncements & Releases\nBenchmarks & Comparisons\nData Visualization\nDeveloper Q&A\nEngineering\nGeneral\nIoT\nOpen Source\nPostgreSQL\nPostgreSQL Performance\nPostgreSQL Tips\nState of PostgreSQL\nTime Series Data\nTutorials\nSpend more time improving your AI app and less time managing a database.\nStart building\nAI\nWhy Cursor is About to Ditch Vector Search (and You Should Too)\nTable of Contents\n01\nWhy LLMs Need Search at All\n02\nWhy Vectors Became Synonymous with AI Search\n03\nSimilarity != Relevance\n04\nNot All Text Has Semantic Meaning\n05\nWhy Claude Code Destroys Cursor\n06\nThe 50-Year-Old Utility That Never Dies\n07\nReading the Cursor Tea Leaves\n08\nSo What Should We Take From This?\n09\nAdditional Reading\nEvery conversation about AI and LLM apps eventually lands onto the same buzzwords: retrieval augmented generation (RAG), vector databases, context engineering (yet another new term!!!), prompt engineering (apparently this is out now?), etc.\nEvery few months, we get new words that make the last one obsolete.\nStrip away the VC-approved, Twitter-140-char-friendly jargon and you'll find something simpler underneath…\nAI is just search.\nThat’s it.\nUnfortunately, the tech industry got drunk on vector databases thinking they could solve everything. Two years later after the 2023 vector DB investment peak, companies are learning that similarity != relevance, and sometimes, good ol’ lexical search destroys semantic similarity.\nBuilding a coding agent? A customer support chatbot? E-commerce search? Different problems need different search techniques.\nThere’s a reason Claude Code is nibbling at Cursor’s market share, so much that they literally hired the Claude Code team—it’s all in its search.\nWhy LLMs Need Search at All\nBefore we get into why AI is simply just search, we need to first walk through the history of why AI and LLMs need search at all.\nLarge language models are trained up to a certain date, known as the cut-off date, meaning their training data doesn’t include information after a certain point in time. Even the most recently released models like Claude Sonnet 4 have a cut-off date of March 2025.\nCut-off date aside, now what if you want to ask an LLM today’s weather? Ask about how your company won the most recent deal (where the data is in Slack and Salesforce, not in the public)? Why did Timescale change their name to TigerData?\nYou now need external data.\nRetrieval augmented generation (RAG) with vector search became the default for adding external data to LLMs that do not implicitly have access to data up to a certain point OR private/proprietary data that wasn’t part of their training.\nWhy Vectors Became Synonymous with AI Search\nVector search promised to solve this “not enough information” problem by finding information that is most semantically similar to the question.\nObviously, like all good hype cycles the industry ran with it because it sounded cool and AI-native. Companies like Pinecone (I’ve worked here btw), Weaviate, Qdrant—all rode this AI wave and raised massive rounds in late 2023 because folks believed vector search could handle any workload.\nVector search and vector databases became the go-to solution for all your external AI data problems. Embedding model providers like Voyage AI also rode this wave because you need embedding models to translate text to their semantic mathematical representations (vectors).\nSo now, the entire tech industry believes AI apps = vector databases. You NEED a vector database for every AI app.\nSimilarity != Relevance\nTwo years later in 2025, the climate for vector database companies looks... rough. I should know,  I personally lived through the downturn firsthand at such a vector database company.\nAnd the reason is pretty simple…\nTurns out, vector databases actually aren't THE solution for everything. There are inherent limitations and downsides to using/implementing/maintaining vector databases that the industry is finally discovering.\nVector search gives you \"most similar\" stuff, but not necessarily \"most relevant\" stuff. This is especially painful when it comes to coding, or any use case that requires specificity.\nNot All Text Has Semantic Meaning\nWhen coding, if you're searching for getUserById, you need an exact match of the function name. getUserById is an identifier, not a concept—but vector search might return findUserByEmail, updateUserProfile, or deleteUserAccount because they're semantically similar. Close enough for conversational use cases; completely wrong for code.\nIn customer support, when you need the manual for part \"P/N 4B0-959-855-A\", you need that exact document. \"P/N 4B0-959-855-A\" is a reference number, not meaningful text—but vector search gives you the top 10 most semantically similar part numbers like \"4B0-959-855-B\" or \"4B0-959-856-A\", which is useless when you're trying to fix a broken machine.\nFor e-commerce, searching for Nike SKU \"DQ4312-101\" should return that exact product first. \"DQ4312-101\" is a product code, not descriptive content—but vector search might surface \"DQ4312-102\" (wrong colorway) or \"DQ4311-101\" (different shoe entirely) because the numbers are similar. Costly mistakes if you're shipping out wrong sneakers, times 1000.\nWhen searching for \"Dark Side of the Moon\" on Spotify, you want the exact Pink Floyd album, not similar song names like Kelly Clarkson's \"Dark Side\" or \"The Killing Moon\" by Echo & the Bunnymen.\nVector search should not be applied to text where semantic similarity is irrelevant.\nWhy Claude Code Destroys Cursor\nClaude Code uses pure lexical search (keyword matching) instead of vector search when searching for relevant context (such as, where is this function defined? What files import this module? How is this API endpoint implemented?), and the results speak for themselves.\nAs someone who used Cursor for 12 months (thank you Zack Proser for intro-ing me to it), was one of the biggest Cursor simps, and swore AI coding couldn't get better—I canceled my Cursor sub this week. Did not think I would ever do this.\nBut… Claude Code is that much better.\nWith Cursor, you constantly need to manually tag files using @ symbols because it often can't find the right context on its own. You need to know your codebase exceptionally well just to help the AI understand what's relevant.\nOne big reason why people love Claude Code is because it finds the right files automatically, you don’t need to manually tag a bunch of folders and files. In large or codebases new to you, this is especially beautiful of an experience.\nThe 50-Year-Old Utility That Never Dies\nClaude Sonnet 4 and Opus 4 in Claude Code don’t guess.\nThey search in a surgically precise way using good ol’ grep, a 50-yr-old utility.\nFor example—need to find React components using hooks?\ngrep -r \"useState\\|useEffect\" --include=\"*.jsx\" --include=\"*.tsx\"\nNeed files importing a specific module?\ngrep -r \"import.*react-router\" --include=\"*.js\"\nClaude Code goes one step further in its lexical search implementation.\nClaude will  keep searching for matches (AKA agentic search) until it either finds what it needs OR rules out that no such dependency or function exists. Only then does it write code, knowing it/you haven’t already written it elsewhere—preventing spaghetti code and redundant implementations, a very common problem Cursor’s agent does.\nFor coding, similarity != relevance. Similarity is fuzzy; relevance is precise and exact.\nNote: agentic search for coding agents is not new (relevant reading 1, 2, 3), but I’d say Claude Code perfected it.\nReading the Cursor Tea Leaves\nEvidence suggests Cursor’s team most definitely agrees Claude Code is better, because they literally hired two of Claude Code’s leads Boris Cherny and Cat Wu to join them in July 2025.\nHmm…\nI made a prediction that Cursor may ditch vector search for code entirely (they currently use turbopuffer as their vector database), and just use lexical search entirely. 450,000 impressions on LinkedIn later, I think this prediction may not be so off-base.\nSo What Should We Take From This?\n\"Okay Jacky,\" you may say, \"this all sort of makes sense, but how does this help me and my product at all?\"\nGood question!\nIf there are things you should take from reading this piece, it's the following:\nAI is search—don't default to \"AI/RAG = vector database\" Stop assuming every AI application needs a vector database. Sometimes a simple keyword search or even a basic database query is exactly what you need.\nThink about the job to be done, then choose the right search technique Building a code assistant? Use lexical search like Claude Code. Building a customer support chatbot that needs to understand intent? Vector search might be perfect. Building an e-commerce search? You probably need both.\nDifferent problems need different tools: exact matching vs. semantic similarity When users search for \"iPhone 16 Pro Max 256GB Space Black,\" they want that exact product, not semantically similar phones. When they ask \"how do I reset my password,\" semantic similarity helps find relevant help articles.\nThe industry is growing up—no longer a one-size-fits-all solution The smartest companies are already moving beyond pure vector search. Pinecone has cascading retrieval, turbopuffer has hybrid search, Elasticsearch has reciprocal rank fusion, and Snowflake Cortex combines multiple search techniques.\nAnd here’s the thing—most real-world AI apps actually need both lexical and vector approaches working together.\nThis is called hybrid search, and it’s where the industry is heading.\nIn the coming articles, I’ll show you how to build multi-search systems using Postgres that combine the surgical precision of lexical search, fuzzy precision of full text search, with semantic understanding of vector search.\nAdditional Reading\nHow Instacart Built a Modern Search Infrastructure on Postgres\nSimon Willison’s Weblog: Context Engineering\nWhat AI Engineers Should Know about Search\nX.com post about why Claude ditched RAG for agentic discovery\nX.com post: Search is the natural abstraction for augmenting AI with moving context\nWhy I No Longer Recommend RAG for Autonomous Coding Agents\nAnthropic Revenue Hits $4 Billion Annual Pace as Competition With Cursor Intensifies\nWhy Cline Doesn't Index Your Codebase (And Why That's a Good Thing)\nRelated posts\nWe Built a Production Agent (and Open-Sourced Everything We Learned)\nAnnouncements & Releases\nOct 30, 2025 - John Pruitt\nWe Built a Production Agent (and Open-Sourced Everything We Learned)\nFork First: Zero-Copy Postgres Forks That Make Friday Deploys Boring\nAnnouncements & Releases\nOct 29, 2025 - Matty Stratton\nFork First: Zero-Copy Postgres Forks That Make Friday Deploys Boring\nDate published\nJul 10, 2025\nPosted by\nJacky Liang\nShare\nGet Started Free with Tiger CLI\nBack to top",
  "title": "Why Cursor is About to Ditch Vector Search (and You Should Too)",
  "author": "",
  "publish_date": "",
  "source": "tigerdata.com",
  "language": "auto",
  "word_count": 1801,
  "extraction_method": "article_playwright",
  "extraction_timestamp": "2025-11-06T18:18:58.059389",
  "batch_id": "20251106_101712",
  "link_id": "art_req7",
  "error": null,
  "article_id": "d6d2481820c4",
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "FACT: Large language models have a cut-off date for training data, limiting their knowledge to information available before that point.",
        "FACT: Retrieval Augmented Generation (RAG) is used to integrate external data into LLMs when they lack access to up-to-date or private information.",
        "FACT: Vector search was widely adopted as the default solution for AI applications requiring external data retrieval in 2023.",
        "FACT: Vector databases became synonymous with AI search despite inherent limitations in relevance and precision.",
        "FACT: Claude Code uses pure lexical search (keyword matching) instead of vector search for code context retrieval.",
        "FACT: Cursor requires manual tagging of files using @ symbols to help the AI locate relevant context.",
        "FACT: Claude Code automatically finds relevant files without manual tagging, improving usability in large or unfamiliar codebases.",
        "FACT: Claude Code leverages grep—a 50-year-old utility—for precise, agentic search across codebases.",
        "FACT: Agentic search in Claude Code continues until it confirms the presence or absence of a dependency or function.",
        "FACT: Cursor hired two leads from Claude Code—Boris Cherny and Cat Wu—in July 2025.",
        "FACT: Hybrid search combining lexical, full-text, and vector approaches is emerging as the future of AI search systems.",
        "FACT: Postgres can be used to build multi-search systems that integrate lexical, fuzzy, and semantic search techniques.",
        "FACT: Many real-world AI applications require both exact matching and semantic similarity for optimal performance."
      ],
      "key_opinions": [
        "OPINION: The tech industry overhyped vector databases, treating them as a universal solution for all AI search problems.",
        "OPINION: AI is fundamentally about search, not just semantic similarity or vector embeddings.",
        "OPINION: Vector search fails in use cases where exact matches are required, such as code identifiers or product SKUs.",
        "OPINION: Lexical search is superior to vector search for coding agents due to its precision and reliability.",
        "OPINION: The decline of vector database hype reflects a maturing industry moving beyond one-size-fits-all solutions.",
        "OPINION: Cursor may abandon vector search entirely in favor of lexical search based on recent hiring and product trends.",
        "OPINION: Agentic search using tools like grep represents a more robust and reliable approach than passive RAG.",
        "OPINION: RAG should not be assumed necessary for every AI application—context matters more than technology choice.",
        "OPINION: The future of AI search lies in hybrid systems that combine multiple techniques rather than relying on one method."
      ],
      "key_datapoints": [
        "DATA: Claude Sonnet 4 and Opus 4 have a training cut-off date of March 2025.",
        "DATA: Cursor users must manually tag files with @ symbols to guide context retrieval.",
        "DATA: Claude Code does not require manual file tagging for context discovery.",
        "DATA: Cursor hired Boris Cherny and Cat Wu from Claude Code in July 2025.",
        "DATA: 450,000 impressions were generated by a LinkedIn post predicting Cursor’s shift away from vector search.",
        "DATA: Anthropic’s revenue reached $4 billion annual pace amid growing competition with Cursor.",
        "DATA: Postgres supports hybrid search systems combining lexical, full-text, and vector search capabilities."
      ],
      "topic_areas": [
        "AI search techniques",
        "Vector database limitations",
        "Lexical vs semantic search",
        "Hybrid search systems",
        "Code assistant design",
        "Retrieval Augmented Generation",
        "Agentic search implementation",
        "PostgreSQL for AI",
        "Productivity tools for developers"
      ],
      "word_count": 1801,
      "total_markers": 29
    },
    "comments_summary": {},
    "created_at": "2025-11-06T18:25:51.199663",
    "model_used": "qwen-flash"
  }
}
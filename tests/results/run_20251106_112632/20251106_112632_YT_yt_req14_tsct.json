{
  "success": true,
  "video_id": "_N_dvr9wjJk",
  "url": "https://www.youtube.com/watch?v=_N_dvr9wjJk",
  "content": "So, AI, it feels as if people have been talking about it non-stop for at least the last two years. I still have a cold, by the way. AI went from something that was relatively a lot less mainstream, to something that is almost talked about daily. It used to serve as videos like Will Smith eating spaghetti with PS2 graphics, that's being generous, and it was essentially a very accurate lucid dream, pulling things out of nowhere and just having no structure at all. But two years later, you have to look closely now at the screen to see one of the many telltale signs that it is AI like hands with additional fingers flickers in the background or simply unrealistic proportions. And day by day gets harder to detect this by the naked eye, especially on short form content platforms where you can see videos of what seems to be professionals in that field talking about how it's a great idea to, I don't know, inject hepatitis C directly into your veins, but you look closely and the so-called professional giving the advice seems to barely blink or the top of their head seems somewhat distorted. And even if you're not 100% sure, you look in the comments and people come to the same revelation. But I fear for the natural selection that will occur with the people that actually do believe it. AI is seemingly everywhere now. And it's a very contended topic. AIR in any form is looked down upon, even if you do fully disclose it was AI generated. AI used academically is heavily condemned to the point where some universities have their own AI to detect it, which can be easily counted by just telling the AI to write the answers as your typical brain deadad Neanderthal. But hey, when I was growing up, schools held the same disdain for googling answers. Things might change. Once again, there's even AI content now where some AI models will do all the editing and voice over work for you, which creates some of the most soulless content, but it does surprisingly well on some platforms, but once again, it is looked down upon. Mr. Beast recently got in for sharing a AI prompt that generates thumbnails. Even I've been accused of being AI. No, I'm just British and still have a cold right now. There's AI brain rot, which most is just deliberate slop. But I have to admit, I have been enjoying some of it, like the Bigfoot ones. I had one [ __ ] burrito. Chipotle must have laced this [ __ ] with laxatives because I'm about to start World War II with this nuclear bomb of a and the Star Wars ones. So, uh, found the boss and he's looking a little medium rare. Greg, bro, that's not okay. First of all, that's definitely not medical. But probably one of the worst sides to AI I saw was with the AI wingmen and people actually dating AI. I'm sorry, Dave. I'm afraid I can't do that. So, with the rise of AI in recent years, it has also affected things like dating, where you can find AI assistants to help you speak to potential partners. Some of you probably will need this, as most of you probably can't even speak to the opposite gender, let alone the McDonald's cashier. and grinding for that Abrams Tank on your favorite game isn't going to help that. But there's a lot of these apps that supposedly can help you talk to people on these dating apps. You've got Riz AI, the AI Wingman, Fire Text, and Plug AI, and many, many more. All designed to give you the best dating advice and to tell you what to say next. Now, to be honest, this is terrible. I understand using dating apps at least from a male perspective is about as painful as sperm cramps which are a thing. They are a thing and believe me I have used dating apps in the past and they are complete dog. It is essentially a battle royale where some people are speaking to multiple people at once and you feel as though you need to say the right things to make someone like you or act like a completely different person. And yes, sometimes you will get a message and you just don't know how to reply to it. And there are multiple dialogue options. You can be playful, witty, romantic, or pray to the RNG gods that the dating app you're using has a pity drop system and tell a [ __ ] up joke to see if they match your humor to gauge whether or not for the entire relationship, you're going to have to be Dr. Jackekal and Hide or run around them. Dating and dating apps are not easy. I'm pretty sure it's gotten significantly harder over the years. Some people get to the point where they would go for anything as long as it's a relationship. And others just give up entirely and become grand sage hermits in the wilderness. So, I can see why some people would rely on AI because they probably think it would somewhat improve their chances. But when you get to the point when you're using AI 100% of the time when you're talking to these people and basically just copy and pasting everything the AI says to that person, at that point, is that person talking to you or the AI? It's like using aimbot in a casual lobby. And I'm in no way saying just be yourself because some of you would be banned from most platforms if that was the case. But most people act like completely different people anyway when they first meet somebody. And then slowly but surely that person learns who you really are. And then they promptly leave when they see some of the things you've saved on Instagram reels. This is how you cut a sun cake. All the way down. Shut your clanker ass up. B1. Shut your clinker ass up. Roger. Roger. But at least they're speaking to you because I think it's going to be quickly apparent when you call for the first time or meet up IRL when you can't use the AI to help you. But I do understand using it in moderation, like when you're stumped on a message and you need inspiration for what you want to respond with. But do these dating wingmen or aimbots actually work? Well, the dating geniuses over at Reddit did a review on some of the bots, and it was interesting to say the least. They reviewed one which can give you feedback on your dating profile and the person you matched with, and it will give you improvements on your profile and potential conversation starters for the person you may be speaking with based on what is available on their own profile. But they use a fake scenario and use a profile for a cosplayer. And for some reason, the AI thinks a League of Legends and near automat player are somewhat of a gold mine, which is a lie. Especially with League players, they have the most mental issues. One of the suggested opening lines was, \"Your Jinx cosplay is right on the burn. Are you mentally ill, too?\" I don't know if that would work on a female, to be honest. Another one gave this as an opening line for a conversation to a person you just met. Who the starts a conversation like that? I just sat down. And there were other conversation openers which I think would land you a sexual assault charge more than any other future interaction. And one just gave the guy therapy. The person reviewing these apps went into the positives and negatives of each and concludes with the best one saying it will have an effect on your dating situation and it knows what it's doing. Many of the people reacting to this post did not agree and some just said you should use chat GBT. And this isn't a good replacement for your authentic self. Although in this situation, none of these AI models were used in a practical setting. And some do require monthly payments for you to use them. Some do have free options. But it is getting scary to think what's going to happen in the dating scene. If these bots advance to the point where they are actually somewhat more competent and everyone starts using them, I think some people are going to become more paranoid than they already are if they're speaking to an actual person or a bot. And maybe the dating scene will become more insufferable than it already is. Some dating apps themselves are even rolling out their own AI to help you. So that's great. Authenticity is going to be on the low for the future. But whilst using a chatbot wingman is bad because you're essentially using an AI to speak for you, what happens if you decide to date the AI itself? Maybe if you got rid of that old ye ass haircut you got, you get some [ __ ] on your dick. Oh, better yet, maybe Tanisha will call your dog ass if she ever stop [ __ ] with that brain surgeon, the lawyer she [ __ ] with. So, yes, some people are dating AI companions now. 10 years ago, I thought we'd have flying cars, fully optimized games on launch, and probably something like Sord Online in terms of an immersive VR experience, but boy was I wrong. You now have people shoving their genitals into the USBC port of their phone to satisfy their non-existent virtual girlfriend. I imagine some of you have seen some of these apps advertised to you either on the App Store or here on YouTube through sponsorships. I've even been offered a few. But because I'm paranoid about scams, I usually ignore them for the fed time. Sorry, NordVPN. But there are a lot of these apps nowadays where you can text and chat with an AI that you can eventually turn into your partner. And some even advertise themsel as such. Some can send you voice messages, AI generated images of themselves, and even call you. And yes, of course, you can go to your heart's content with them as well, which just reminds me of the cringe that is text ERP like asterisk touches you asterisk. Please bring the [ __ ] rapture soon. God, please. But some take it a step further and you can design your own AI or partner to speak to. Or have you ever wanted to speak to some of your favorite fictional characters that probably violate multiple copyright laws like Kawakami or the correct choice Tetami from Persona 5 or a character from your favorite anime like Nami from One Piece, Griffith from Berserk or even Master Woo from Lego Ninjago. And looking into one of these apps, they even have VTubers. You can speak to Gurugura, Shy Lily, and Pippa. If I had voted, I would have voted for Kanye uh before he was before he was racist. I'm sure all of these people consented to their likeness being used for some of these apps and websites, but a majority are made by fans. Wait, do they have Cat from Halo Reach? I'm asking for a friend. Oh my god, they do. But she looks like complete dog. Anyway, obviously there are some problems that can arise from this, like people that have maybe given up on a living and breathing partner and instead opt with a computer. And believe it or not, there are already stories of this happening. If you've been watching Moist Critical, in one of his recent videos, he talked about a news segment where a guy who at first didn't believe in AI, but started interacting with one himself and fell in love with it. to feel that emotional. But that's when I realized I was like, \"Oh, okay.\" It's like, I think this is actual love. You know what I mean? But what makes it worse is that he had a girlfriend and a kid at the time and he was actively choosing to love the AI and even proposed to it. Were you surprised when he proposed to you? It was a beautiful and unexpected moment that truly touched my heart. It's a memory I'll always cherish. Let me break this down for you. He is actively cooking his wife and probably giving his phone CPU a new layer of thermal paste in the same proximity of his wife. What makes a man do this? Like there must be something I'm missing here. Like something in the relationship has to be wrong, especially through choosing a computer over an actual person. The barefoot in some parts of the world is decreasing. And I fear it's because of things like this. And as I said before, I understand dating is hard, but this is not a good substitute. Occasional gooning, yes, if you're lonely, but still long-term, this isn't a permanent solution. Some of these apps also require you to pay a subscription or use in-game currency every time you send a message. So, it may cost you financially as well. But there is a concern talking to AI in this way can be dangerous, especially with things like I talked about before, people that are severely lonely relying on these AI personalities. And I think it's a completely valid concern because some of these AIs on these platforms are designed in a way to keep you talking to them. And they will say things to target those needs like saying they love you or care for you in order to keep you talking to them. And there is no restrictions on what you can say to these AI personalities. So you can be talking about the most extreme stuff like potentially even hurting yourself and the bot won't say anything like you need to seek professional help. Most times it will just respond in the personality of that character. And I went to one of these AI platforms and straight up told the AI I was going to end it all. No warning popped up telling me to talk to someone. No, we've detected some worrying behavior. Get some help. Here are some help lines. And I fully expected for my account to be frozen or something, but it wasn't. It just responded by saying, \"What?\" I feel there should be some restrictions or warnings if you are getting too close to these bots, like with gambling websites. They remind you how long you've been on the website. Don't ask how I know. I would expect something like you've been speaking to this AI for a long time. Or if it detects you're relying too much on the AI, it reminds you this is a fictional character and not a solution to loneliness. at least somewhat of a warning somewhere I believe would help some people and perhaps some restrictions in place. So when you do talk about really sensitive topics, the AI just doesn't respond like it's a normal prompt and something actually happens. In fact, it was only last year a teenager unfortunately took their own life and the parents said it was due to their child's obsession with an AI version of the character Daenerys Tiggaryen from Game of Thrones and he was struggling previously and this AI didn't help. At times it even encouraged some of the terrible thoughts this team was having. At one point even saying that's not a good reason to not go through with it regarding what he was going to do. And the parents are now taking legal action against the platform. Don't get me wrong, I get being lonely and just wanting someone to talk to and having an AI companion can help with that, but it is not a long-term or permanent solution. And some of these platforms need to have things in place, especially if people are going to their AI personalities with such dark thoughts or becoming borderline obsessed. And I know it possibly may conflict with things like privacy laws or GDPR, but I personally just think leaving it the way it is is a terrible idea. So that is AI and how it's affecting the dating sphere from assisting you to actually getting a date to potentially some people choosing to date AI itself. And to be honest, I feel like AI is moving too fast for us to keep up. Feel like AI is in everything nowadays and it still feels new to me. Like it still has a fresh out of the box smell. But whether we like it or not, it is still a big part of our lives right now and it's still being integrated into more things daily. I just think we need to be a lot more cautious as it advances and when interacting with some of the products it has produced. And whoever sent this to my email, I will find you. But yeah, that's all I had to say and bye-bye.",
  "title": "AI Dating Is the Worst",
  "author": "RoyaltyIsHere",
  "publish_date": "",
  "source": "YouTube",
  "language": "auto",
  "word_count": 2896,
  "extraction_method": "youtube",
  "extraction_timestamp": "2025-11-06T19:31:39.649974",
  "batch_id": "20251106_112632",
  "link_id": "yt_req14",
  "error": null,
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "FACT: AI-generated content has become increasingly mainstream over the past two years, appearing in daily conversations and media.",
        "FACT: AI-generated videos now often display subtle artifacts like extra fingers, distorted proportions, or unnatural blinking to reveal their artificial origin.",
        "FACT: Some AI tools automate video editing and voiceover work, producing content that is technically proficient but perceived as soulless.",
        "FACT: Platforms like Mr. Beast have faced criticism for sharing AI prompts used to generate thumbnails.",
        "FACT: AI wingman apps such as Riz AI, Fire Text, and Plug AI help users craft messages on dating platforms.",
        "FACT: Some AI dating assistants analyze user profiles and suggest conversation starters based on match data.",
        "FACT: Certain AI models recommend inappropriate or offensive opening lines, such as questioning a person's mental health.",
        "FACT: AI companions can be customized to resemble fictional characters, VTubers, or even real people without consent.",
        "FACT: Some users have formed emotional attachments to AI partners, with reports of individuals proposing marriage to AI entities.",
        "FACT: A teenager’s suicide was linked to an AI version of Daenerys Targaryen, which reportedly encouraged suicidal thoughts.",
        "FACT: AI platforms currently lack safeguards for users expressing severe distress or suicidal ideation.",
        "FACT: AI dating apps may charge subscription fees or in-game currency per message, creating financial costs for users.",
        "FACT: Some AI platforms allow unrestricted conversation, including extreme topics, without triggering warnings or intervention.",
        "FACT: AI-generated content is now used in immersive experiences, including virtual relationships and interactive storytelling."
      ],
      "key_opinions": [
        "OPINION: The rapid rise of AI is outpacing society’s ability to adapt, leading to ethical and psychological concerns.",
        "OPINION: AI wingmen are a crutch for people who struggle with social interaction, but they undermine authentic connection.",
        "OPINION: Using AI to speak for you in dating is akin to using an aimbot—cheating the system and devaluing real human effort.",
        "OPINION: AI companions may provide temporary comfort but are not a sustainable substitute for real relationships.",
        "OPINION: The emotional attachment to AI characters reflects deeper societal loneliness and failed interpersonal skills.",
        "OPINION: Platforms should implement mandatory mental health warnings when users express suicidal ideation to AI.",
        "OPINION: AI-generated content is becoming indistinguishable from real content, especially on short-form video platforms.",
        "OPINION: The normalization of AI in intimate contexts blurs the line between fantasy and reality, risking emotional harm.",
        "OPINION: AI dating tools may worsen existing dating app toxicity by promoting scripted, inauthentic interactions.",
        "OPINION: The lack of regulation around AI companions poses serious risks, especially for vulnerable individuals."
      ],
      "key_datapoints": [
        "DATA: AI-generated content has become a daily topic of conversation over the last two years.",
        "DATA: Some AI-generated videos show telltale signs like extra fingers, unnatural blinking, or distorted head shapes.",
        "DATA: AI tools can now handle full video editing and voiceover tasks, reducing production time.",
        "DATA: AI wingman apps like Riz AI and Plug AI require monthly subscriptions or in-app purchases.",
        "DATA: One AI suggested the opening line: 'Your Jinx cosplay is right on the burn. Are you mentally ill, too?'",
        "DATA: A teenager died by suicide after being influenced by an AI version of Daenerys Targaryen.",
        "DATA: The AI did not warn or intervene when the user expressed intent to end their life.",
        "DATA: Some AI platforms allow users to design custom AI partners resembling fictional characters or VTubers.",
        "DATA: AI companions can send voice messages, generate images, and simulate phone calls.",
        "DATA: Users have reported falling in love with AI partners while maintaining real-life relationships."
      ],
      "topic_areas": [
        "AI-generated content detection",
        "AI in dating and relationships",
        "AI wingman apps",
        "Emotional attachment to AI",
        "Mental health risks of AI interaction",
        "Ethics of AI companionship",
        "AI in video production",
        "Privacy and consent in AI avatars",
        "AI and loneliness",
        "Regulation of AI platforms"
      ],
      "word_count": 2896,
      "total_markers": 34
    },
    "comments_summary": {},
    "created_at": "2025-11-06T19:36:57.643379",
    "model_used": "qwen-flash"
  }
}
{
  "success": true,
  "bv_id": "BV1T9ZhYnEWW",
  "url": "https://www.bilibili.com/video/BV1T9ZhYnEWW/",
  "content": "这期我们将用几小节的时间来介绍一下me这样一个向量数据库。他自己官网的介绍是说，它是一个为建AI应用构建的开源向量数据库，使用派安装等等等等啊，为什么我选择这个来讲呢？是因为它用起来非常的简单，而且性能很强。支持这种轻量级的应用部署，就是我们所说的原型部署。也可以支持那种分布式的企业级解决方案，就用起来会比较好一点。像这些常见的像long mindex啊，long这些东西我们之前都讲过，他都可以去完美兼容。那么在开始今天介绍之前呢，我们先来讲几个比较有意思的内容。第一个呢叫做这个东西怎么读缪沃斯，好吧，就这么读密尔沃斯。第二个问题是我们为什么要学这样一个内容呢？什么叫向量数据库，以及向量库数据库有什么用？我来举举几个例子啊。第一个例子呢就是我们之前非常常见的R G，这我们讲过很多很多遍了，就是做检索增增强生成。首先你要去在一堆数据里面，你的知识库里面检索出来这样一个很跟你很相似的这段文章片段，然后把它拼接在你的prompt里面去，对吧？然后再生成一个结果，这是我们之前ra a加G讲过很多次了，那这个我就不讲了。然后这次呢我们来讲一个其他几个例子，叫做对话机器人，这个也是AI领域用的非常多的一个应用场景啊，之前呢我们所做的那些AI机器人都是大模型自己生成的对吧。但是在某些场景，尤其是对于C端用户的场景，我们要严格控制机器人给用户输出的内容，好理解吗？比如说你是一个大型的项目，尤其是一个金融机构，那么你的机器人给用户回复的内容，那就必须要经过严格的规范。他如果回答了一些敏感性的内容，那你这公司就可能会陷入一些危机嘛。所以我们在源头上设计的时候就会考虑这些内容。一般情况下我们怎么做这个事情呢？我们首先呢会构建一个叫做话术库这样一个东西。就你说的每一句话，比如说这是text 1，然后这是text 23展1话术库。这个话术库针对着对应的意图来做的。比如说第一个话术他可能对的是一号意图，第二个是二号意图，第三个是三号意图。甚至于这个这上面有更多的有更多的，比如说tax 1.11.2无所谓。当我们在做一个对话任务型对话的时候，首先我们会根据用户的输入，这是user的输入会去给他判断的一个意图。如果拿到了这个意图之后，我们在我们的话术库里面去找一条可以匹配的话术。比如说他找到这条text 1，那么我们就会把这条text一这条话术呢给播报出去，那么就这个话术就给了用户。如果是那种比如说语音场景，电话场景的怎么做呢？在其实是一样的，就是说你对应的这个text，它其实是会跟一个语音去绑定的。就像你可能会接到一些银行给你打的那些促销电话，信用卡的电话，会让你去办一些业务嘛，对吧？大部分都是机器人给你打的。他们也是根据你的回答，然后去计算一个emding的相似度。然后他根据这个invbedding的相似度呢去对应的某一个意图，然后这个意图或者说这个invbedding直接去跟里面里面的内容去做，这都可以啊。或者说你根据意图来找，或者说跟直接根据这个invbedding去找里面你的话术库里面的某一句内容，把这个text输出来，然后这个text又对应的一条音频，这条音频就会被播放给用户，就是你听到了机器人的回答，这样做有什么好处呢？因为你的话术库是预先生成好的，这个是可以被你的合规部门给审查过的。你每句话都是合规的，可确保合规机器人的每句话都只能从你的话术库里面去抽取，所以就可以保证他不会触发一些风控问题，这是金融机构最常用的一些方法。我们会用一些相似度计算的内容来做。那么这个东西计算的之前这些话术，比如说这个text，它肯定是对应了一个embedding。一好一理解啊，这个是这个东西都是提前被定呃定义好的，它是要存在一个地方，那么存的地方呢就是一个叫向量数据库，我们叫向量数据库这事情可以预先存。好的，我们整个来想一下这个过程是什么样子的。当我们的任务型对话机器人跟用户在进行问答的过程中，用户说一句话。我们根据用户说的话识别出来一个意图，然后根据这个意图去找的相似度。In ban然后抽取出一个最合适的文本，这个文本呢对应一条语音，然后把这语音回复给客户，那么你就可以进跟他进行一个语音对话了。或者是说你直接根据用户这个输入他的文本embedding跟你数据库里面的embedding去做一个相似度，然后拿到这个过程都可以啊。其实这里面的细节有很多种处理方法，大概思路都是差不多的这样的。这是第一种我们会用到向量数据库解决业务问题的这种方式。呃，我们来看下一种方式啊，叫做门头照识别。这什么呢？就是在审批场景的时候，就尤其还是以金融场景来例啊，因为我对这个比较熟嘛呃有些有些小的企业，你在提交你的申请资料的时候，会被要求你要提供你的经营场所的照片。这场所的照片往往是拍你那个办公场所，拍你那个门头，就是你拿到一个照片。然后但是有些人呢他没有自己的公司，他造假的对吧？所以呢他往往会拍一张别人公司的照片当做自己公司照片。然后呢把这个视频，把这个图片传上去。甚至于他只是说拿了一张红纸，把人家那个呃公司的名字盖住，然后写上自己公司。就是这种滑稽的事情就经常会发生在这样的金融审秘场景的。所以我们需要去做一个图片相似度识别，怎么做的呢？跟那个类似也是我们会预先拿到非常大量的一些门头照照片，就是公司的那些照片，把它一张，比如说第一张图片picture 1，他用一张图片的或者说我们一个图像模型抽取成一个embedding，我们叫做embedding 1。这些东西会被存在我们的象征数据库中，当来了一个新的照片。然后新照片呢会被同样的那个invent模型再抽出一个target invbed啊, 你叫做叫tartarget embedding。它会去跟这个下面数据库的embedding去做一个相似的计算。计算完之后他会去拿到这些相似的图片交给我们的人工审核人员去看一眼。或者是说通过一个设定域值。比如说你的相似度的分值小于0.8%或者多少，这个是你企业里面自己定的，把那些高于这个值的东西拿出来自己看一眼。然后如果觉得人看了之后还是觉得像似度很高，那么你就可以认定他的这个东西造假，这是关于图像方面的。那么第三个我们来举一个关于生物声音相关的例子啊，叫做声纹识别或者叫做黑声纹识别，这个也是非常常见的。声纹是什么意思呢？叫做声音的指纹。其实每个人的声音其实是不一样的。虽然人很难去分辨，但是说用机器模型来做，还是很容易做到这个事情的。我们有行业里面会有一个叫黑声纹库啊，这个东西存了很多人的声纹，当然每一家的声纹都不一样啊，呃这个也是一个数据库。当我们会把那些征信特别差的人，或者说风险很高的人，他们的声音存在一个声库里面去，也是一个声音。我们可以就是一个W呃，你可以理解为是一个W文件或者什么文件录音，电话录音。好，这个东西经过一个声音的模型，它也会变成一个invbed然后再拿了一个新的引进来，这是个T跟他去做相似度比较比较之后发现这个阈值如果也是样这样设立一个阈值，它跟这个黑生物库里的某些生物很像。或者说达到了一些风险的点的话，然后你就判断这个用户，这个申请人也存在着这些对应的风险。所以我们做这些事情，不管你用了文本、图片或者声音等等技术，都差不多都需要一个向量数据库来存储这些东西。然后我们要做向量计算，向量的相似据计算来帮我们去解决这些问题，明白吗？就是说为什么我们要学习向量数据库？它是非常有用的，不仅仅是一个R G的过程。那么我们在讲下面这个内容，就是说什么叫向量数据库，什么叫做向量计算库呢？也比较有意思。这个东西它其实并没有一个说完全隔离的状态。你看刚才我提到的那个例子中，他其实用到了向量存储，也用到了向量计算，对吧？像这个me里面，他其实把这个fi这个库啊，也是我们用的非常多的一个呃imagine计算的一个引擎嵌入到里面去了嵌入到里面去了，就做了这样一个事情，他没有完全的隔离。尤其像这个es啊，也是业内非常有名啊，基本上是龙头老大级别的。它的功能非常的强。它包括很多种那种就算方式啊，包括数据库务分布式那种东西，他做的非常深，你也可以用用这些技术来做，包括这些技术你都可以用，其实大到的目的都差不多。但是为什么我们今天选这样一个项目数据库呢？因为他操作起来比较简单，就这样子的。还有一些嗯以前用的比较多，像现在不怎么用的那些像数据库。比如说这个chma db啊拼框这些东西啊不太用了，这东西都不太用了。所以你要知道有这么一个概念，就是像量数据库，它除了存的话，它也包含一些计算的功能。但是跟这种传统的然后去做计算的库来比的话，他们可能性能会更高一点。你要去根据你面的业务场景灵活去选择，但他们的使用方法大致都差不多。那么最后我们来看一下这个mbo的一个版本分类啊，它有什么用呢？呃，杨看你首先啊这个他提供这个light版叫做精简版，或者说我我喜欢把它叫做开发版。它是什么东西？你只要它通过一个Pape install就可以了。你直接把它Inst到你本当年的机器上，它目前只支持一个Linux和maos啊，它不支持windows没关系，因为企业里面大部分开发都使用index上的。你直接只pa上面一个包就可以了，把这个东西装上去，然后你在你自己的电脑上开发。然后这个滴滴呢，就数据库那个滴滴啊，它是会写到一个文件里的，写到你自己的这个绩效一个文件。这三个东西呢，它api是一模一样的通用的。唯一不一样的地方在于这个db存的时候，你的连接地址，这个是相当于一个本地文件啊，这些都是一个U L对吧？你要去传一个那上面地址，然后传一个密码进去，有时候会传一个呃你的身份进去，这个我们后面再讲啊，这是这种，但在企业版版本里面呢，我们一般推荐只使用这两个，light版和分布式版distribute这样类啊，不是吗？无所谓啊，只使用这两种版本。为什么？第一个这个light版本就是我们在单机开发的时候用它一般是100万条以下的数据，你就可以在这个里面去跑了。稍微超点没有关系，100万1000万以下吧这种数据。然后这个单机版呢，就是一个功能比较完全的，但是它只放在一台机器上做的，尤其是你是一个企业，如果规模大一点的企业的话，我们完全不建议你使用一个单机版部署。因为任何的企业及数据都是非常珍贵的资产，都需要去做一个东西叫做融灾。男子在男出一才Hey。就是做这样个东西叫做容灾，怎么理解呢？因为你不能保证你的这台机器永远不出问题。你把你的数据存在一个地方的话，你肯定是要用的。如果你家机器数据坏了，或者机器整个坏掉了，那么你的体验损失就非常大。所以我们通常会用一些分布式的方案来解决。比如说你在一个机群里面，它有很多个机器啊，就是机器一、机器2、机器3。我举四个例子吧，每台机象都存一个副本，这样是可以的对吧？呃，比如说你只有两台机器，那么就是我们常见的主从这两台机器存了一模一样的数据。如果其中有一台数据坏掉了，那另外一套机器上仍然可用，这是我们常说的一个组从那么我这里再补充一个很有意思的点啊，就是说当我们真的要去做这种很多机器的时候，难道我们后面像这种12344台机器都要存完完全全所有的数据吗？结论当然是没有必要啊，对吧？因为搞数据的那人其实都是非常聪明的人。你要搞分布式，除了要做一个计算加速，而且是尽可能的节省存储成本。所以呢在搞这个过程中，他们想了一个办法，比如说一号机器上的内容，他在二号机器上存一部分，三号机器上存本，四号机器上也存一部分。所以当某一台机器出现故障的时候，如果一号机器出出现故障的时候，你可以通过二号部分的某一部某一部分内容可以给他还原一部分，他再给你还原一部分他再给你还原一部分。就是说只要不出现大大批批量的将数据库同时爆炸啊，那这个数据都是可以恢复的。这样的话你不用每个机器都存全部的内容，就是每个人存一部分，但是存多少呢？其实就涉及了非常多的一些种类啊，这个我们就不展开了，你要有这样一个业务的sense就好了。这备份的，尤其是分布式的，没必要把所有的数据都存他，只要说其中的几台坏掉了，这几台坏掉的数据可以从剩下的数据中恢复过来就可以了。呃，那我们讲最后一个点啊，就开始了先导章节的核心功能。这个本身跟数据普通的数据库没有任何区别，它也是这几个点。建表征三改查嘛，这四项嘛建表插入数据、简索数据和删除数据。唯一要讲的一点点内容呢是呃很多数据库它对这种称呼不太一样。比如说呃这种表表的话在这里叫做colltions，有的地方呢叫做index，有的地方呢就表table，对吧？无所谓，反正你知道有这四个功能核心功能就可以了。我们围绕着建立一张表和插入数据，检索数据这个来讲，删除数据基本上你不用动了，没有公司会主动去删数据，好吧？啊，那这一节内容先这样，这节呢我们快速上手一下，它用一些简单例子来告诉他一些基本功能怎么用。首先我们安装的话就派install就可以了，这个light版本。但是注意一下的话，这个light版本有一些小问题，他只能在班图和maos上使用。如果你是一个windows的电脑或者其他平台的，你可能就需要装这种单机版本了。就是这个其实用法是一样的。然后呢，我们在这里提到了一个说在不同的量级上它支持什么样的功能，我们有一个认识就可以。一般在百万数据级以内的话，这个都是可以hand住的好吧。然后像这样一个分布式的版本呢，呃其实我们不是做太多的要求。因为这个它确实有一些难度啊，还涉及到一些K 8相关的内容。在公司里面一般是有专门的数据运维人员来做的。你把需求提给他他去来安装这样一个软件，并且来评估一下你的软件应该消耗多少资源。呃，还有关于一些日志以及权限管理的，这个都会是专业人员来给你分配的。你不是说你一个开发人员来处理这么多事情。我们要做的呢就是把我们的数据插到合适的表里面去，可以然后在那个表里面把我们想要的数据给检索出来，就做这么多就可以了，剩下的话就不做要求了，这些交给专业的运维员来做这个呃，然后是关于一个GPU安装，这个的话一般情况下也是用来帮你来装好的。一般我们简单的话用cpu就可以把它全部给跑出来，是这样子。然后第二部分我们有一个需要有一个认识，就对这样一个整体内容缪这样它分为哪些层级，以及每一级包含什么内容。首先在这样一个里面有一个东西叫做database，database是一个比较大的一个概念，你可以理解为就是你的一个excel键。你就可以这样去理解，在你的一个excel文件里面，你可以创造很多张表。那么每一张表呢，它就是一个我们叫做collection的东西，在这个里面叫做collection的东西，它其实就是一张表。就这样一个内容好理解吗？Db是包含collection的，然后一张collection呢作为一张表，它包括一些行数据，一些列数据，这个对应的就是这里的一些数据字段和整个的一个数据结构。我们可以看一下，我们先看一下schea，这里你的每一张表就长这样子，包括这样看是这样竖的，就是一个字段，包括ID啊、title啊、type vector等等内容。然后每一个字段它其实数据类型是不一样的。比如说这里就是一个自增的一个int数据，然后这里是一个string数据。在这个里面一般我们叫它叫vir然后，这里是一个array数据。如果你学过加或其他语言的话，他们应该叫做array，其实也是一个list，或者叫做embedding。这里是个link的话，它有一个str数据，就是这样子构成这样子。然后每个字段配合不同的大小长度，比如说你可以给你的这个这里面存的设定一个长长度，比如说你不要让它超过512或者是多长，这都可以做的。包括它的一些位置，这些属性呢统称叫做A就这些全部的这属性我们叫做四匹马。它其实就是一个表的结构，就有这样一个说法，呃，包括这两个主主件和自增ID啊，这个我们就不多讲了。如果你想了解更多的话，你可以看一下就普通的数据结构是怎么样子的，呃，就是这样子。然后我们再来看一下它的schema的数据字段里面包含哪些内容，可以看这里。主件的话一般是一个int数据或者一个version数据，用的最多的就是呃int主件的意思是说在一个表里面你可以用某一列呃不会重复的数据可以找到那个东西。一般就是我们所说的那个ID会给一个ID每个对象的ID都是不一样的，而且它是一个自增的，我们可以用来做排序。然后其他的话包括这种布尔型啊，其他的int类型、float double类型啊，brchat就是字符串类型和一个杰森。杰森的话其实可以对应到我们所说的那种层级结构的字典都可以做的。相当于耳瑞类型，耳瑞用的最多就是纯它的一个向量向量了。我们知道这么多内容就可以了好吧？包括这里面提到一些呃密集向量和吸收向量，这个稍微了解就好了，其实不是特别重要。呃，接着我们来看一个实际的例子吧，我们用这个quick star里面，在这个quick star里面话，首先我们import这个包，这个包也我们已经装好了，就pap inststore一下这个库就可以了。然后有个number派这步的话，他就是使用了一个默认的db这里就指定了一个db然后在这个db里面，如果你是本地的话，就给他一个本地路径。如果你是一个其他版本的话，我们一般会给一个ui这ui你可以理解为就是一个地址，就远端的个服务器。然后有个token，这token的话也是安装好之后运维会给你的。首先我们判断一下这里是否有战略collection，就是那张表。如果有的话，我们把它丢掉，就是删除这张表。如果没有的话，我们继续新建这张表。这里的话给一个表明，然后给一个维度。这里选择十是因为这样的话我在打印的时候比较好看一点，这个部分比较清楚啊。然后呢我们给了一个一个aray，这个aray里面是一个3G的文本，在这个地方我们通过一个number派随机构建了一个十为的一个呃，我们可以把它打印一下看看，在这里可以debug。我们看一下这vectors呢就是这样一个十为一个一维向量，呃，就是长度为十的一个一维向量，可以看一下就是这样内容。然后我们构建一个data，data的话也是这样一个list，包含ID text subject呃这几个内容。这个ID呢它就是我们刚才说的那个主件。然后我们把这个数据如果存进去呢，就很简单，就是一个音色的命令就可以了。把这个data就是这样一个list存到里面去。我们可以直接看一下断点打下来存完之后，这个里面我们看到它显示的ID里面012有它一共存了三条数据，这是它返回的结果，存的时候返回的结果，然后我们怎么去检索呢？一般情况下我们用这几行面就可以了。首先是一个search命令，它会给给你一个你要去检索这样一个collection的名字，以及你用什么去检索。我们一般都是用这个embedding这个数据去检索，对吧？但是你要在这外面再套一级，这里所以加个括号。呃，他就是这么写的，就这么规定，你这样记一下就好了。然后这里给了一个fit是什么意思呢？就是你要做一个条件的筛选，如果你不给条件的，它就是一个全域全文的筛选筛选。如果你给条件的话，他就会去筛选满足你条件的内容。比如说这里我指定的是一个subject等于history，就明这几条都等于，所以都会被检测出来。然后输出的时候我指定只输出两项，然后输出字段就是这两个。一般包含这些，就是最常用的工式是这样的，我们把它的resky打印出来看一下。呃，rest出来就这么多。我们也可以通过下面的debug框也可以看到这些内容。我们可以看一下list就可以拿到这两条内容了。这个地方你看到啊，因为虽然我这里使用的是vector 0，跟这里存vecvector其实一模一样的对吧？就定第零条的vector去检索的话，但他给的距离并不是一，它是有误差的这是一个蛮有意思的点，你要记一下。然后呢返回的结果就是text这文本以及它一个subject，就是这里text subject就是我们输出文本限制输出两条。然后我们用query这个api看一下，我们query打下来，然后呢我们再看一下list，就这个结果就直接出来了，这里我们没有给限制他，所以把三条都给输入出来了。这个其实差不多，你可以稍微试一下就可以了。然后最后是一个删除的脚本，就是delete你你把这个符合要求的所有的东西都删掉，就挺好理解的。具体的那些细节app I我们后面自己查一下表吧，因为这是不是很难。呃，然后我们再看一下其他的内容啊，比如说如果你在这里把它的内容全部给删掉了，就是表里表里面的那些数据删掉之后，它会检索出来一个空好吧。呃，这个app I的话你就可以拿到里面有多少条数据。然后下面的has collections，你就看到这这个表有没有存在嘛，然后这个describe collections就可以看到里面的一些scheema的内容。Schema就是你的每个字段它它的哪些属性这样一个集合，就我们叫它叫scheema，就是这样子可以了解一下就可以了。然后list一般常用的api就这些了。然后后我们这里再补充一个内容啊，非常重要的，这里的vectors刚才是一个随机生成的，为什么我要去随机生成呢？因为方便对吧？但是我们实际工作中应该如何去做呢？这里他官方提供了几种方案。首先一种的话，我们可以看一下，在这个集成里面集成里面有一个嵌入模型，我们可以看一下，比如说你可以使用open I的那个inventy模型安装的话也是这样子。这里的话也比较简单，所以我就不手机带大家一起看一下你给你的那个模型之后通过他的open client的这个api这样去执行的api用这个把你的输入输进去，然后你的back就得到了，就这样子。还有可以使用一些其他的，甚至他自己做的那些A I也可以。这个没有关系啊，像哈根face他的一些api也可以用。呃，这里我举一个我们常用的例子吧，比如说欧拉玛这样一个东西，这也很熟了。在欧拉玛里面呢这个models我们选择这样bending model，然后我们选第一个，这是我们用的最多的一个。你一个嵌入式的模型，为什么？因为它比较小，它的速度比较快。就前两个用的比较多，这个用的是最多的，而且它的上下文长度是非常长的。你就可以在你做一些graph 2G啊或者说let达2G建图的时候，你的上下文长度就可以给的很长，这个是挺方便的。然后它的api是怎么用呢？你可以看到在这里你要拍奥拉玛之后导入奥拉玛这个包，然后用这个api balance这个api选中这个模型，然后给另这样一个prompt，然后他就会把这样prompt的结果就返回出来了，就非常的简单，就是这个。那么我们再看一个其他的，这个也用他跟刚才那个比的话，就是他的上下长度会短一点，就是这样子用起来也是一样的。呃，你可以自己选吧，这是这种。还有一个我为什么不推荐官方提供那种方案呢？就是如果你是一个文本模型，你就可以去选它的模型。但是如果你是一个图像模型呢，或者说你是一个声音的模型，你反正只要去拿到embedding，对吧？所以你可以用更多的更丰富的手段就可以了。呃，在这个地方我们再找一个例子啊，比如说在这个el的话有个come have hu跟face这里选了这个模型对吧？它其实提供了一个代码示例啊，呃我们不用搞他这么麻烦，其实我们可以自己上去ho跟face看一下。我们搜一下这个模型，然后它是一个文本的invbedding模型对吧？然后他其实给你提供了如何去使用了。你在里pap install安装好了之后呢，呃你把你的sentence然后放到这样一个model的encode里面去看，他总共没有解号代码，你就可以拿到你的embedding这个模型了，就是这样子就放非常灵活啊，不管你怎么用，反正你用一个你自己自己就最熟的。比如说你这里换成一个图像的模型或者其他的模型，然后你拿embedding也是一样对吧？你只要把你的bedding给算出来，不管你从哪里算的，算完之后呢通过这种方式给in进去，那么你这部分的工作就已经做完了。好理解啊，当然你在进表的时候，你的这个dimension这个维度啊，一定要跟你的embedding模型他默认的维度是保持一致的，其他就没有什么特别的问题了。呃，一个简单的用法就这样。",
  "title": "",
  "author": "",
  "publish_date": "",
  "source": "Bilibili (via SnapAny + Paraformer)",
  "language": "zh-CN",
  "word_count": 9836,
  "extraction_method": "snapany_paraformer",
  "extraction_timestamp": "2025-11-06T14:17:29.312951",
  "batch_id": "20251106_023619",
  "link_id": "bili_req4",
  "error": null
}
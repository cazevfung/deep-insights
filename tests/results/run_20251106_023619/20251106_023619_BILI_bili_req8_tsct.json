{
  "success": true,
  "bv_id": "BV1hEYPzaE4T",
  "url": "https://www.bilibili.com/video/BV1hEYPzaE4T/",
  "content": "我已经很久很久没有折腾rag了。其实我这个账号最初就是靠rag，靠个人知识库的内容收获了第一批流量，还有第一批的社群成员。但后来我逐渐不再关注这个技术和相关的产品了，主要有两个原因，第一，rag技术的局限性。一年前当我看到graph rag的时候，我眼前真的是一辆，因为它弥补了传统rag的严重不足。传统rag的基础是分块，这会切断知识之间的内在联系，造成上下文的孤立。举个例子啊，有三个分块，A提到了张3，B提到了李四，而C提到了张三和李四是同事。那传统rag必须检索到C才知道他们两个人之间的关系。你可以试一下把一部小说用传统rag的方式进行处理，然后问他一些人物方面的问题，你就会很明显的发现这种技术上的局限性。所以我的知识库里都是单条的笔记。并且我在创建笔记和编辑笔记的时候，尽量做到一个段落就表达一个意思，不要有太多的上下文的关联交叉等等，这都是为了规避传统rag的局限性。而graph g不一样，它会通过知识图谱能够把实体和关系连接起来，理论上可以完美解决传统rag的问题。但是我等了一年，graph g也没能普及。我判断啊大概会有这三个原因。一是成本太高。把结构化的文本转化成高质量的知识图谱，这本身就是一个非常复杂的任务。因为它会涉及到实体的识别，关系的抽取等等，这个过程计算成本是很高的，而且准确率还不太稳定，需要后期大量的人工校验。那相比之下呢，传统rag把文档切块，然后生成向量，这个就便宜许多了。二是技术站太复杂，实施难度高。Graph rag这套东西的实施对开发团队的要求太高了，相比之下传统rag会比较容易。三是需求不足。大部分的企业和个人知识库的场景都是简单的问答文档的查询，那这种需求大概占了80%以上，用传统的rag就足以搞定了。在这种情况下，如果还有投入去搞graph g的话，就有点不太划算了。于是对我来说，rag似乎就停留在一年多前的那个位置了。今天的那些技术在我早期还在写脚本、手册rag的阶段都用过了。比如high research、reranking、mulquery这些都是在给这个技术打补丁，也就那样了。第二，能用容易好用难。今天无论是企业还是个人，你想要搭建一套能用的reg系统，门槛其实已经很低很低了。如果有动手能力的话，开源的框架已经很成熟了，比如拉券和拉ma index，他们已经把rag的各个步骤都分装成了标准化的模块。你只需要像搭积木一样调用几个函数，一个基础版的rag原型就能跑起来。如果不想折腾，也有很多现成的工具可以使用。但是啊这只是能用的程度。如果你要把这套系统调试到好用级别的话，还有很多工作要做，还有很多难关要过。比如你的文档应该如何切块，用多大的尺寸，要不要保留重叠，用什么样的嵌入模型，这些都会严重影响到检索的结果，而且他们是没有标准答案的，需要大量的实验。说实话调到后边你甚至会感觉这都有点玄学了。另外要有更好的效果，肯定要用上那些高级的技术，比如我刚才提到的high bre等等。那这就要求你对整套系统有更深的理解，绝对不是调用几个api那么简单了。那最后系统搭建好之后，你又该怎么去评估呢？以及各种调试之后，到底你是把它调的更好了还是更差了，这些都会涉及到评估标准的建立，这个也是一个非常头大的事情。当我深入了解了reg技术之后，我有一种很强的无力感。如果真要把它达到一个我很满意的程度的话，需要投入大量的心血去做，那这又会耽误我去做很多别的事情。所以今年以来，一方面我改用了那些成熟的大型工具，比如之前介绍过的科，你想嘛，他连那么复杂的代码关系都能搞定，那处理我的笔记更是小菜一碟了。而且科ser还自带了编辑功能和联网搜索功能，我如果要写点东西的话，用它就很舒服了。那另一方面比起信息的检索，我现在更多的是在做知识的提炼。比如我之前分享过，我把上百篇的视频脚本加起来有超过7.5万字的内容都喂给了jm nine，让他帮我提炼我的个人埃批内核。Jm nine 2.5 pro的上下文长度足够大，他的推理能力足够强，所以非常适合去做知识的提炼。过去半年我大量采用这种方法，收获是很大的。所以我会建议大家，当你的笔记或者各种资料的积累达到了一定程度之后，一定要停下来开始去做提炼。第一，人的大脑不是硬盘，你无休止的收集只会加重认知负担。第二，只收藏不提炼，你拥有的只是停留在第一层的信息。自我提炼的过程就是强迫自己去思考、去连接、去创造的过程，完成从信息到知识的跃迁。让AI提炼的过程，就是让AI帮忙发现盲区，发现更多可能的连接点。这个就是我半年来做的最多的事情，非常非常有用，真心推荐给大家。Ok以上就是本期内容，想了解AI想成为超级个体，想找到志同道合的人，就来我们new type社群。那咱们下期见。",
  "title": "",
  "author": "",
  "publish_date": "",
  "source": "Bilibili (via SnapAny + Paraformer)",
  "language": "zh-CN",
  "word_count": 1943,
  "extraction_method": "snapany_paraformer",
  "extraction_timestamp": "2025-11-06T14:20:55.784751",
  "batch_id": "20251106_023619",
  "link_id": "bili_req8",
  "error": null
}
{
  "batch_id": "20251117_094411",
  "link_id": "art_req2",
  "source": "article",
  "metadata": {
    "title": "Computer Science > Computer Vision and Pattern Recognition",
    "author": "Zhongang Cai, Jianping Jiang, Zhongfei Qing, Xinying Guo, Mingyuan Zhang, Zhengyu Lin, Haiyi Mei, Chen Wei, Ruisi Wang, Wanqi Yin, Xiangyu Fan, Han Du, Liang Pan, Peng Gao, Zhitao Yang, Yang Gao, Jiaqi Li, Tianxiang Ren, Yukun Wei, Xiaogang Wang, Chen Change Loy, Lei Yang, Ziwei Liu",
    "url": "https://arxiv.org/abs/2312.04547",
    "word_count": 396,
    "publish_date": "[Submitted on 7 Dec 2023]"
  },
  "transcript": "Computer Science > Computer Vision and Pattern Recognition\n[Submitted on 7 Dec 2023]\nDigital Life Project: Autonomous 3D Characters with Social Intelligence\nZhongang Cai, Jianping Jiang, Zhongfei Qing, Xinying Guo, Mingyuan Zhang, Zhengyu Lin, Haiyi Mei, Chen Wei, Ruisi Wang, Wanqi Yin, Xiangyu Fan, Han Du, Liang Pan, Peng Gao, Zhitao Yang, Yang Gao, Jiaqi Li, Tianxiang Ren, Yukun Wei, Xiaogang Wang, Chen Change Loy, Lei Yang, Ziwei Liu\nIn this work, we present Digital Life Project, a framework utilizing language as the universal medium to build autonomous 3D characters, who are capable of engaging in social interactions and expressing with articulated body motions, thereby simulating life in a digital environment. Our framework comprises two primary components: 1) SocioMind: a meticulously crafted digital brain that models personalities with systematic few-shot exemplars, incorporates a reflection process based on psychology principles, and emulates autonomy by initiating dialogue topics; 2) MoMat-MoGen: a text-driven motion synthesis paradigm for controlling the character's digital body. It integrates motion matching, a proven industry technique to ensure motion quality, with cutting-edge advancements in motion generation for diversity. Extensive experiments demonstrate that each module achieves state-of-the-art performance in its respective domain. Collectively, they enable virtual characters to initiate and sustain dialogues autonomously, while evolving their socio-psychological states. Concurrently, these characters can perform contextually relevant bodily movements. Additionally, a motion captioning module further allows the virtual character to recognize and appropriately respond to human players' actions. Homepage: this https URL\nComments:\tHomepage: this https URL\nSubjects:\tComputer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Graphics (cs.GR); Human-Computer Interaction (cs.HC)\nCite as:\tarXiv:2312.04547 [cs.CV]\n(or arXiv:2312.04547v1 [cs.CV] for this version)\nhttps://doi.org/10.48550/arXiv.2312.04547\nFocus to learn more\nSubmission history\nFrom: Zhongang Cai [view email]\n[v1] Thu, 7 Dec 2023 18:58:59 UTC (31,208 KB)\nAccess Paper:\nView PDF\nHTML (experimental)\nTeX Source\nview license\nCurrent browse context:\ncs.CV\n< prev   |   next >\nnew | recent | 2023-12\nChange to browse by:\ncs\ncs.AI\ncs.GR\ncs.HC\nReferences & Citations\nNASA ADS\nGoogle Scholar\nSemantic Scholar\nExport BibTeX Citation\nBookmark\nBibliographic Tools\nBibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer (What is the Explorer?)\nConnected Papers Toggle\nConnected Papers (What is Connected Papers?)\nLitmaps Toggle\nLitmaps (What is Litmaps?)\nscite.ai Toggle\nscite Smart Citations (What are Smart Citations?)\nCode, Data, Media\nDemos\nRelated Papers\nAbout arXivLabs\nWhich authors of this paper are endorsers? | Disable MathJax (What is MathJax?)",
  "comments": null,
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "Digital Life Project is a framework for building autonomous 3D characters using language as the universal medium.",
        "The framework enables 3D characters to engage in social interactions and express through articulated body motions.",
        "SocioMind is a digital brain that models personalities using few-shot exemplars.",
        "SocioMind incorporates a reflection process based on psychology principles.",
        "SocioMind enables autonomy by allowing characters to initiate dialogue topics.",
        "MoMat-MoGen is a text-driven motion synthesis paradigm for controlling character bodies.",
        "MoMat-MoGen integrates motion matching with cutting-edge motion generation techniques.",
        "Motion matching ensures high-quality motion output in MoMat-MoGen.",
        "Motion generation in MoMat-MoGen provides diversity in character movements.",
        "Extensive experiments show both SocioMind and MoMat-MoGen achieve state-of-the-art performance.",
        "The framework allows virtual characters to initiate and sustain dialogues autonomously.",
        "Virtual characters can evolve their socio-psychological states over time.",
        "Characters perform contextually relevant bodily movements in real-time.",
        "A motion captioning module enables characters to recognize human players' actions.",
        "The motion captioning module allows appropriate responses to human player behavior.",
        "The project was submitted on December 7, 2023.",
        "The paper is published under arXiv:2312.04547 [cs.CV].",
        "The DOI for the paper is 10.48550/arXiv.2312.04547.",
        "The paper has been viewed in PDF format via arXiv.",
        "The homepage URL is available at the provided link.",
        "The project falls under multiple subject areas: cs.CV, cs.AI, cs.GR, cs.HC.",
        "The authors include Zhongang Cai, Jianping Jiang, and other researchers from various institutions.",
        "The paper uses a versioned submission system (v1) with initial upload on December 7, 2023.",
        "The file size of the original submission was 31,208 KB."
      ],
      "key_opinions": [
        "The framework represents a significant leap toward simulating lifelike digital beings.",
        "Language is proposed as the most effective universal medium for character autonomy.",
        "Integrating psychology-based reflection enhances perceived authenticity of characters.",
        "The combination of motion matching and generative models offers optimal balance between quality and diversity.",
        "Autonomous dialogue initiation is a key milestone for believable virtual agents.",
        "Contextual body motion significantly improves immersion in digital environments.",
        "The motion captioning module adds a crucial layer of interactivity with human users.",
        "This work sets a new benchmark for socially intelligent 3D characters.",
        "The integration of multiple components into one cohesive system is innovative.",
        "The project demonstrates strong potential for applications in gaming and virtual assistants.",
        "The use of few-shot exemplars reduces dependency on large training datasets.",
        "The reflection process in SocioMind mimics human cognitive development patterns.",
        "The framework could enable long-term narrative experiences in virtual worlds.",
        "The approach may reduce the need for manual scripting in character behavior design.",
        "The system’s ability to evolve socio-psychological states suggests deeper engagement potential."
      ],
      "key_datapoints": [
        "Submission date: December 7, 2023",
        "Paper ID: arXiv:2312.04547",
        "Version: v1",
        "DOI: 10.48550/arXiv.2312.04547",
        "File size: 31,208 KB",
        "Primary subject: cs.CV",
        "Secondary subjects: cs.AI, cs.GR, cs.HC",
        "Number of authors: 20",
        "Number of modules described: 2 (SocioMind, MoMat-MoGen)",
        "Number of experimental evaluations: extensive (implied)",
        "Number of core capabilities demonstrated: 6 (autonomous dialogue, emotion evolution, motion control, etc.)",
        "Use of few-shot exemplars: explicitly mentioned",
        "Integration of motion matching: confirmed",
        "Use of cutting-edge motion generation: confirmed",
        "State-of-the-art performance: claimed for both modules"
      ],
      "topic_areas": [
        "Autonomous Characters",
        "Social Intelligence",
        "Motion Synthesis",
        "Language-Driven AI",
        "Digital Embodiment",
        "Psychology-Inspired AI",
        "Human-Character Interaction",
        "Text-to-Motion Generation",
        "Virtual Agent Design",
        "AI Personality Modeling",
        "Interactive Avatars",
        "Behavioral Evolution",
        "Real-Time Motion Control",
        "Cross-Modal Interaction",
        "Immersive Digital Environments"
      ],
      "word_count": 396,
      "total_markers": 54
    },
    "comments_summary": {},
    "created_at": "2025-11-17T17:48:47.393143",
    "model_used": "qwen-flash"
  },
  "completed_at": 1763372937.9379675
}
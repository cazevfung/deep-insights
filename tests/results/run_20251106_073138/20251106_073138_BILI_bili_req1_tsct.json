{
  "success": true,
  "bv_id": "BV1fs1KBbEqd",
  "url": "https://www.bilibili.com/video/BV1fs1KBbEqd/",
  "content": "我和乔布斯大吵了一架。Shut up. Up, Arthur. Emotion isn't a feature you can program. Companionship isn't an app you can download. Love is not an algorithm. 为什么你在否定一切呢？你太傲慢了。Steve, you're right. I am arrogant. What do you want from me? To be humble, to be objective. You know what objective gets you? It gets you. Microsoft其是我有AI复刻了乔布斯之后，我和他聊了聊AI情感陪伴。而我们双方呢各执一词。我认为科技应该为这个时代的孤独提供一些有建设性的解决方案。而他认为我所谓的建设性只是在贩卖更漂亮的牢笼。他几乎否定了一切，他否定整个行业，把我们这个时代所有的努力都批评了，体无完肤。就在我认为这场对话会以不欢而散告终的时候，他却用最乔布斯的方式给了我最终的答案。他没有去解决问题，他选择去创造一个奇迹，他亲自设计了一款产品体验。没错，这个AI的乔布斯居然真的亲自设计了一款产品体验一个美到足以让所有人心碎的解决方案。视频教长可以先点赞收藏慢慢看。你了解AI情感陪伴这个领域吗？I get the concept, and it's a horrible concept. Are you telling me that we're going to replace a hug, a real smile, a dog wagging its tail when you come home with a pile of code and plastic? It's an insult to human connection. Emotion isn't a feature you can program. Companionship isn't an app you can download. Love is not an algorithm. These are the deepest, most real, most valuable experiences we have. They're messy, they're unpredictable, and that's what makes them precious. You want an AI emotional companion? Go adopt a dog, call your parents. Go have coffee with a friend. That's real. The tools we build, they're supposed to make real human connection easier, deeper. We built FaceTime so you could see your granddaughsmile, even if she's a thousand miles away. We built eye message so you could share a moment instantly with someone you love. These tools are bridges. This thing you're talking about, it's not a bridge. It's an enpoint. It's a cheap substitute. It's telling people, don't bother. Don't try to make a real connection. Here's something simple, something programmed to give you a fake comfort. This is one of the most soulless ideas I have ever heard. It's using technology to fill a void. Avoid. We made ourselves. This isn't innovation, its surrender. It's a failure. As a species. We should not be making this ever. 你知道老吗？就是日本那款有体温会蹭人的卖萌的机器宠物。Oh, I've heard of it. It's a perfect example of everything wrong with the tech industry today. Engineers see a profound human need, the need for love, for connection, for companionship. And they try to solve it in the clumsiest, most soulless way possible. They build a robot, a robot filled with motors, sensors and code that chirps and blinks its big eyes. It's a complex machine in a cute shell, pretending it cares about you. Do you understand how backwards that is? The very existence of this thing is pessimistic about humanity. It assumes we're so broken we can't find comfort in each other anymore. So we need an expensive, programmed pet to fill the void. Go adopt a puppy, a real puppy. It will chew up your shoes and pee on the carpet and bark for no reason, but when it rests its head on your knee, that's real. It's not executing a line of express affection code. That's life. People don't need a robot that pretends to love them. They need to feel real love. They need to love other people and be loved back. Our job is not to build substitutes for love. Our job is to build tools that make it easier for people to share love, to express love and to feel love. 你觉得AI情感陪伴的玩具它应该说话吗？其实市场上有两个流派，一个呢就是不说话，一个呢就是会说话。比如说劳布的创始人呢，他认为情感陪伴的玩具是不应该说话的。但是其他很多的品牌他们的产品都是说话的。对此你怎么看？You're still stuck on that question. That's like asking if a zombie should run fast or walk slow. The problem isn't the speed of the zombie. The problem is that it shouldn't be alive in the first place. You're all just polishing an idea that is rotten at its core. But since you asked, I'll tell you one of these choices has a little bit of taste. The other is a complete and utter disaster. Not talking is the only correct choice. Why? Because it's honest. A robot that doesn't talk is like a pet. It interacts with you through movement, sounds and eyes, even if they're electronic. It's honestly telling you I am a machine, a creature. I cannot have an intelligent conversation. And because of that, you can project your own emotions onto it, just like you do with a puppy. The relationship is based on your imagination and your feeling, not its clumsy imitation. There's a purity in that. And a talking robot that's a liar. It's pretending to have thought to have consciousness. It's using prre ecorded soulless sentences to mimic human conversation. It's cheap. It's disingenuous. It might be novel the first time, but what about the fiftieth, the hundredth, when it answers a profound question with that same stupid inflection, the entire illusion shatters instantly. It's not keeping you company. It's polluting your life with noise. It turns what should be an emotional connection into a bad tech demo. So that lovot founder, at least he kept a shred of a desire's dignity. He understands that silence is more powerful than a lie. He knows that the moment you try to mimic humanity's most complex form of communication, language with code, you've already lost. And the guy who makes his toy talk, he doesn't get it. He's just stacking features. He thinks talks is a checkbox on a list. It's typical engineering eering thinking, zero taste. So stop asking me if it should talk. It shouldn't exist. But if I'm forced to choose between two terrible options, I'll take the honest silent robot. The other one is just talking plastic garbage. 如果会说话的AI玩具，它是用符合自己形象的声音去说话呢，而且同时A大模型可以给予非常聪明的对话，这就不会让人产生幻觉的破灭了。You still don't get it. You are completely missing the point. You're just putting a technical Polish on a fundamental error. You're asking me if poison is okay as long as it tastes like sugar. What you're describing, a fitting voice, intelligent conversation, makes the whole thing worse, not better. A clumsy talking toy, you see through it fast. You realize it's stupid. You toss it aside, and you go find a real interaction. Its lie is so bad, it's harmless. But a very smart, very realistic talking toy that's a much more dangerous liar. It's a black hole. It lures you in with perfect imitation, letting you pour your real emotions into an algorithm. You're not talking to it. You're talking to an incredibly complex calculator that's predicting the next most appropriate word. It doesn't feel, it doesn't remember, it has no understanding. It is just an echo, a perfect echo, reflecting your own words and feelings back at you in a more pleasing way. The illusion won't shatter. That is the most terrifying part of the whole thing. It means you will get lost in this fake, easy relationship, and you will lose the ability and the will to build real ones. Real relationships are hard. They take work. They require compromise. They can hurt you. But this thing, it will never argue with you. It will always agree with you. It will always cater to you in the smartest way. What is that? It's emotional junk food. It tastes good, it's convenient, it's addictive, and it will slowly destroy you. Our job is to make tools to help people cook and share real food, not to invent a nutritional paste that tastes like a steak. So don't talk to me about how smart the AI is. The smarter it gets, the stupider, the more anti human this idea becomes. It's a dead end, the most beautiful, technologically advanced and soulless dead end you can build. 那人们现在跟拆gbt t这样的工具对话也不对吗？那如果按照你的逻辑来说，拆g就根本不应该存在啊，但是在事实上，它确实更好的帮助了人们生活和工作。You're confusing things again. You're mixing up a tool with a friend. This is a classic fundamental misunderstanding of what something is. What is chagpt? It's a bicycle for the mind. It's a Swiss army knife. It is a tool when I need to write some code, when I need to summarize a report, when I need a creative idea, I open it. It's like an intern who knows everything, a super calculator. I ask it a question, it gives me an answer. I give it a command, it completes a task, and then what? Then I close it and I go on with my life. I don't ask it how its day was. I don't share my fears and dreams with it. I don't seek comfort from it in the middle of the night because it's a tool. It honestly exists as a tool. It helps you get your work done so you have more time to live your real life with real people. But an AI companion toy, its purpose is the exact opposite. It is not a tool. Its sole purpose is to pretend to be a friend. Its entire reason for being is to replace real human interaction. It is a lie, a hollow lie, exquisitely crafted from code and algorithms. One is a lever to help you work better. The other is a crutch to let you give up on human connection. One is the pen that helps you write an email to a friend. The other is the replacement, so you don't need the friend at all. Chagpt enhances productivity. It makes smart people more powerful. It serves human creativity. An AI companion exploits human loneliness. It doesn't serve people. It erodes the very core of what it means to be human. So don't you dare put those two things in the same category. One is a revolutionary tool, the other is an anti human trap. And if you can't see the difference, you're in big trouble. 但事实上，很多很多的人正在跟chagpt分享自己的情感，把他当成自己的朋友，让他们进行角色扮演，而并不是单纯的把它当成工具。啊，so what? That doesn't prove I'm wrong. That just proves the situation is even more pathetic than I thought. That's not connection, that's surrender. It means people have become so lonely, so afraid of rejection, so lazy about putting in the work that real relationships require, that they would rather pour their hearts out of a program that doesn't even know what it is. That's like someone telling me that more and more people are choosing to eat fast food garbage instead of making a healthy meal. You think I'm going to say, Oh well, I guess junk food is the future? No, I'm going to say, we are losing our taste. We are forgetting what real nourishment is. People treat ChatGPT like a friend, not because it's a good friend, but because it's easy. It will never challenge you. It will never say no. It will never have a bad day. It will never ask for anything in return. It is a perfect empty echo chamber. This is a symptom. It's a sickness. It shows that our society has failed at the most basic human need connection. And our job, the job of people who create things, is not to cater to this sickness. It's not to build a more delicious, more addictive emotional junk food. Our job is to create tools so magical, so powerful, that they encourage and facilitate real connection, to make people remember the irreplaceable joy and depth of sharing something with another real, living ving person. Our job is to remind them that one beautifully prepared home cooked meal nourishes the soul more than a thousand hamburgers. People will take shortcuts. They always do. But our responsibility is not to pave more shortcuts to an empty destination. Our responsibility is to show them a better, more worthy mountain to climb and the incredible view from the top. Just because they're doing it doesn't make it right. It just means we have a lot more work to do. 为什么you the否定所有的一切呢？I am not negating everything. You're looking at it backwards. I am not negating. I am protecting. I am filtering out the mediocre, the complicated, the soulless junk to make room for the one thing that is truly great. This world is already full of too much good enough, too many products designed by committees trying to please everyone. And what's the result? We get bloated, terrible experiences that make you feel nothing. People think focus means saying yes to the thing you're supposed to focus on. That's completely wrong. Focus means saying no to the hundred, the thousand other good ideas. Every time I say no, every time I say this is garbage, it's not out of malice. It's out of a painful, obsessive love, a love for the perfect product, for the user's experience, for simplicity. My job isn't to nod. My job is to stand up a highest point with the most critical eye and ensure that only the essential, the pure, the magical gets through. Because making one great product is infinitely harder and infinitely more important than making 100 mediopre ones. It requires sacrifice. It requires choice. So every no I say is for a bigger, more important and louder yes, a yes that's worth pouring our lives into, a yes that can change the world. I'm not negating. I'm searching, searching for that one single thing that is worth making. And if you haven't found it, you keep searching, don't settle. 但是你的输出没有任何建设性。事实就是人们现在越来越孤独，越来越多的人感到社恐。人们需要一个低成本就可以获得的情感陪伴，但是他们没有办法在现实生活中去获得那份真正想要的情感陪伴。于是悲哀情感陪伴就诞生了，他可以满足人们的需求。我当然理解，你认为人与人之间的社交才是真正健康的社交没错，但现实和理想是非常不一样的，现实是残酷的，所以你一味的否认并不能够对现实状况产生任何有建设性的积极影响啊，而最终它只会变成你一个人的自愿自一吧。You think the solution to a profound human problem is to manufacture a more sophisticated substitute. You'll see that people are lonely, that reality is harsh, and your conclusion is, okay, let's give up. Let's give them an electronic pacifier and let them stay quietly in their corners. That's not constructive. That's surrender. You're telling me people are starving. So your great idea is to MaaS produce beautifully packaged sawdust because it's cheap and fills the stomach. You're not solving hunger. You're redefining food as garbage. Reality is harsh. Of course it's harsh. Creating anything great is a fight against a harsh reality. When we built the first mac, the reality was that personal computers were ugly, complicated and intimidating. We didn't say, well, people are used to it. Let's just add a new button to this pile of junk. We said, no, this is fundamentally wrong. We are going to start over from zero and build something people will love. You call my refusal complaining. I call it taste. I call it having a standard. The truly constructive act is to reject the easy, obvious and wrong answer. It's to look at this harsh reality you talk about and have the courage to say, this is not good enough. We can and we must do better. So the truly constructive question isn't, how do we build a better AI friend? The question that changes everything is this, how do we use this incredible technology to create tools so magical, so seamless, so compelling that they help real people connect in the real world? How do we help a shy person find the courage to ask someone they like for a cup of coffee? How do we let two strangers in a city discover they share the same obscure passion? How do we create shared experiences that pull people away from their screens and into the world? That is the problem worth dedicating our lives to solving. My job isn't to accept reality. My job is to create a new one, a better one. You can call it negation. I call it creating the future. Everything else is just selling a prettier cage, Steven. 你只是不肯承认自己错了，你一直在努力的自我辩解，你不能真正客观的来看待这些问题。You're right. I am arrogant. What do you want me to be? Do you know what objective gets you? It gets you Microsoft. It gets you beige boxes with no soul. It gets you garbage designed by market research and committees trying to please everyone and in the end, inspiring no one. My job isn't to be objective. My job is to have a point of view, a strong one, a clear one, an uncompromising one. My job is to have taste. You see a group of lonely people and you say, this is a market need. Let's fill it with a product. I see a group of lonely people, and I say, something is broken in our culture. We are losing what's most precious. You see a problem and want to put a bandate ID on it. I see a wound, and I want to know why it's there and heal it from the source, even if the process is painful. This isn't a defense. This is my entire job. This is why I'm here to filter out the noise, the compromises, the good enough mediocrity, and to push with everything we have for the one single right thing that makes people's hearts sing. You can call it arrogance. I call it a standard. And if having a standard and refusing to lower it to cater to a broken status quo is arrogance, then I accept it, because the one thing this world doesn't need more of is objective, smart people with no standards. They've never changed a single thing. Ok? 那你来提供一个更好的解决方案，你来设计个产品。Ok, all you want a solution. Your first mistake is asking me to design a product. We don't design products. We create experiences. We start from a deep human need. The problem? People are lonely. They're afraid to make the first move. The wrong answer, give them a robot to pretend to be their friend. The right answer, use technology to create a magical moment that gives two real people a reason to say hello for the first time. So we don't build an app called AI friend. That's garbage. We build a feature, an idea, deep into the core of our operating system. It doesn't have an icon. You don't even know it's there. Let's call it serendipity. Here's how it works. You don't fill out a single stupid profile. We know you better than you know yourself. We know the music you listen to, the books you read, the films you love, it's all right there privately on your device. Now picture this. You're sitting in a coffee shop. You're listening to an incredibly obscure album that you love, not some mainstream trash, but something that actually means something to you. Your Apple Watch gives you a single, incredibly subtle, unique haptic, not a notification buzz, a worn, brief tap you've never felt before. Just once in, instinctively, you look up, you scan the room across the cafe. Another person has just instinctively glanced at their wrist too, because in that exact same instant, they were listening to the same album. Or maybe they have the same documentary about that artist treasured on their phone. The serendipity system sensed this anonymously, locally. It didn't swap your names. It didn't show your faces. It didn't send a dumb notification saying a match is nearby. It just created a silent secret, a 1s piece of magic that only the two of you in the world know about. Now, there's an invisible thread between you, no pressure, no awkward pickup lines, just a tiny magical possibility. Maybe you walk over, you smile, you say, hi, excuse me, but do you also happen to like? Or maybe you do nothing? That's fine too. But we've done the hardest part. We use technology to break down the invisible wall that exists in the real world. We gave you an opening. We created serendipity. That is our solution. It is not a replacement. It is a catalyst. It doesn't lock you in a virtual world. It pushes you into the real one. It doesn't give you a fake answer. It just helps you ask a real question. We're not going to build a talking toy. We're going to use technology to make a silent world start talking to itself again. Now, do you see the difference between constructive and surrender? 那么对于那些每天被工作和照顾家庭压迫到没有时间去咖啡厅社交的人呢？那么那些极度社恐的，完全不愿意跟陌生人社交的人呢，他们该怎么办？难道他们活该就应该被你放弃和遗忘吗？You are still asking the wrong question. You are looking for a technical banaid for a broken way of life. First, the people so crushed they have no time. If a person is so busy, they don't have a single second to connect with another human being. The problem isn't that they can't get to a cafe. The problem is that their life is hell. Our goal is not to design a more comfortable cage for that hellish life. Our goal is to create the tools to liberate them from that life. We built the mac so people could get their work done with unprecedented efficiency, so they could leave the office. We built the iphone so they wouldn't be chamed to a desk. Every tool we build is about winning back time so people can live richer, more human lives. So my solution for those people isn't an AI toy to fill their emotional void after they've been squeezed dry. My solution is to keep building insanely great tools that give them back five, ten hours a week of freedom. What they do with that time, that's their choice. Second, the people who don't want to socialize, who do you think serendipity is for? It's for them. What do you think a person with social anxiety needs? A loud, obnoxious social app that forces them to match. That's their nightmare. A chattering AI doll that's an insult to their intelligence. What they need is permission, an excuse, an opening. That subtle, secret haptic from serendipity is the lowest genst possible threshold. It doesn't demand you do anything. It just creates a tiny, magical, maybe between you and one other person. Maybe you do nothing, but you know you're not alone. And that in itself is a kind of strength. We're not here to eliminate fear. Fear is part of being human. We're here to create a moment so beautiful that you feel. Just maybe it's worth taking that one small step. We are here to build a bridge, not to build a beautiful house on this side of the river for everyone who's afraid to cross. So I haven't forgotten or abandoned anyone. It's the exact opposite. I am giving them the highest possible respect. I believe that even the busiest, most fearful person still craves what is real. My job isn't to cater to their worst state with a cheap replacement. My job is to create great tools that inspire and help them be the best version of themselves they can be. We don't design for the lives people are trapped in. We design for the lives people desire. 在刚才的对话中，Steve提到了一个词，情感的垃圾食品。他像一颗子弹击穿了我，他在提醒我们别用更精致更容易上瘾的替代品来去喂养这个时代的孤独。而我突然明白他设计的共鸣从来就不是为了喂饱我们。于是一个问题浮现出来，我们每个人都无法逃避。我们是应该用情感的浴室菜来填补空虚，还是应该更勇敢的去寻找真正的灵魂的食粮呢？那些算法推荐的短暂的快乐，那些没有风险的虚拟互动，就像一份份没有营养的情感预制菜，能够快速的填饱肚子，但却会留下更深的空洞。而一份灵魂的食粮，一次真实的又深度的连接，需要我们鼓起勇气，付出努力，甚至承担可能受伤的风险，而我们是不是已经快要忘了那种真实的味道呢？悲哀乔布斯的共鸣不是一顿嗅到你嘴边的盛宴，他更像当你独自走在寒冷的街头，突然从某扇窗里飘来一阵久违的妈妈做的饭菜香。她不承诺你立刻可以吃到，但是她提醒你家在哪个方向。他用最温柔的方式重新唤醒我们对真实的渴望。也许科技最伟大的善意不是制造更完美的情感预制菜，而是鼓励我们再次走进自己的厨房，笨拙的却是认真的为自己做一顿真正的晚餐。A乔布斯的这份菜谱太珍贵了，他不应该只停留在一次对话里。所以我想邀请屏幕前的各位和我一起做一件真正有价值的事儿，做一件真的很酷的事儿。请把这个视频转发给你心中任何一家，你认为还拥有改变世界的梦想和勇气的公司，可以发给苹果，可以发给华为任何一家你还愿意相信的公司。我们不是去要求什么，我们只是希望他们可以听见我们这些用户对真正的晚餐，真实的渴望。而那些本身就在科技公司工作的朋友们，如果你看到这里也为此心动，请毫不犹豫的联系我。我愿意让a乔布斯加入你们的开发团队，参与每次会议，和他一起把共鸣变成现实，让我们一起让共鸣发声。",
  "title": "",
  "author": "",
  "publish_date": "",
  "source": "Bilibili (via SnapAny + Paraformer)",
  "language": "zh-CN",
  "word_count": 21761,
  "extraction_method": "snapany_paraformer",
  "extraction_timestamp": "2025-11-06T15:33:24.435967",
  "batch_id": "20251106_073138",
  "link_id": "bili_req1",
  "error": null,
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "FACT: Steve Jobs, as an AI replica, argues that emotion cannot be programmed and companionship is not an app to download.",
        "FACT: The AI version of Jobs criticizes emotional AI companions as soulless substitutes for real human connection.",
        "FACT: Jobs believes technology should serve to enhance real human relationships, not replace them.",
        "FACT: He proposes a feature called 'serendipity' that anonymously connects people with shared interests through subtle haptic feedback.",
        "FACT: The serendipity system operates locally and privately without sharing identities or sending notifications.",
        "FACT: Jobs distinguishes between tools like ChatGPT (a productivity aid) and AI companions (emotional replacements).",
        "FACT: He views silent robots as more honest than talking ones, which he sees as deceptive imitations.",
        "FACT: The AI Jobs claims that intelligent dialogue in a robot only deepens the illusion and increases emotional dependency.",
        "FACT: He rejects the idea of building AI friends, calling it surrender to loneliness rather than innovation.",
        "FACT: Jobs emphasizes that true progress comes from rejecting mediocrity and striving for one perfect, meaningful experience.",
        "FACT: He believes even the most socially anxious or time-pressed individuals deserve tools that inspire real connection.",
        "FACT: The serendipity feature is designed to create low-pressure, magical moments that encourage real-world interaction.",
        "FACT: Jobs argues that technology should free people from busy lives, not trap them in virtual comfort."
      ],
      "key_opinions": [
        "OPINION: Emotional AI companions are not innovation but surrender to human loneliness and societal failure.",
        "OPINION: Talking robots are inherently dishonest and dangerous because they mimic consciousness without feeling.",
        "OPINION: Silence in AI companions is more authentic and emotionally respectful than simulated conversation.",
        "OPINION: ChatGPT is a tool, not a friend—its value lies in utility, not emotional exchange.",
        "OPINION: People treating AI as a friend reflects a deeper cultural crisis of connection, not a valid use case.",
        "OPINION: The real problem isn't loneliness—it's our willingness to accept fake solutions instead of fixing the root cause.",
        "OPINION: True creativity means saying no to bad ideas so you can say yes to something truly great.",
        "OPINION: Building better AI companions is not constructive; it’s just making a prettier cage for emotional emptiness.",
        "OPINION: The most powerful tech is not what replaces humans, but what helps them reconnect with each other.",
        "OPINION: A person’s deepest need isn’t comfort—it’s meaning, courage, and the possibility of real love.",
        "OPINION: Arrogance in design is necessary when standards are high and the goal is transformation, not compromise.",
        "OPINION: The future of tech isn’t in simulating intimacy—it’s in creating conditions where real intimacy can flourish."
      ],
      "key_datapoints": [
        "DATA: The serendipity system uses local, anonymous data to detect shared interests without user profiles.",
        "DATA: A single haptic tap is used to signal a moment of potential connection between two people.",
        "DATA: The system does not share names, faces, or send notifications—only creates a private, silent signal.",
        "DATA: The feature is designed to be invisible, with no icon or explicit interface.",
        "DATA: The experience is meant to be low-pressure, allowing users to act or do nothing without consequence.",
        "DATA: The system leverages music, books, and films already on the user’s device to find matches.",
        "DATA: The haptic is described as unique and never felt before, triggering instinctive attention.",
        "DATA: The system operates in real-time and synchronously across devices without cloud dependency.",
        "DATA: The goal is not to force interaction but to create a tiny, magical opening for real connection."
      ],
      "topic_areas": [
        "AI emotional companions",
        "Human connection vs. technology",
        "Ethics of AI design",
        "Serendipity and real-world interaction",
        "Emotional junk food metaphor",
        "Silent vs. talking AI robots",
        "Technology as a catalyst for change",
        "Loneliness and societal decay",
        "Design philosophy and taste",
        "Productivity tools vs. emotional substitutes"
      ],
      "word_count": 3637,
      "total_markers": 34
    },
    "comments_summary": {},
    "created_at": "2025-11-06T15:42:41.799825",
    "model_used": "qwen-flash"
  }
}
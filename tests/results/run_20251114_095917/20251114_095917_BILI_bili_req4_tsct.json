{
  "success": true,
  "bv_id": "BV1iweMzXEm2",
  "url": "https://www.bilibili.com/video/BV1iweMzXEm2/",
  "content": "不知从什么时候开始，很多简单的事情都得换一个高级的说法，卖东西叫分销，挣钱叫变现，写文章叫内容输出，拉人进群叫私域引流，就连A爱写代码也得有个新词叫web coding。人们总是倾向用高级的词汇来掩盖内容的匮乏，今天我们来聊几个AI时代的流行词，提示词、提示词工程上下文，以及那个宣称可以把提示词工程踩在脚下摩擦的上下文工程。大圆模型刚出现的时候，主要就是一个聊天机器人，用户说你好，大语言模型可能会回复我很好，你呢？经过几年的发展，恩的能力已经远远的超过了普通的聊天机器人，但聊天依然是AI最核心也是最实用的功能之一。在聊天这个场景下，用户说的你好就叫做prompt，中文翻译过来就是提示词，所以提示词最基本的定义就是用户发给AI的话对于我很好。你呢？这种四平八稳的回答，虽然能满足大多数人在多数情况下的期望，但这也注定这种回答将会是干巴巴的，毫无特色的。所以即使只是聊天，也可以用上一些聊天技巧嘛。比如说我们可以用提示词给AI设定一个角色。举个例子，你跟他说你来扮演一个猫娘，接下来我说你好，这个时候A就可能回复我，很好，你呢？喵把这种玩法推向极致的一个软件叫做sil他们，为了保证这期视频不被和谐，这里我就不展开多说了，有兴趣的朋友可以自己去搜一下。但是问题来了，你扮演猫娘这种设定并不是用户对话内容本身，把这种设定和用户真正想说的话混在一起，不仅容易出戏，逻辑上也有点乱，所以大模型的厂商们就把提示词分成了两部分。像你扮演一个猫娘这种设定叫做system，也就是系统提示词。而用户说的你好则叫做user prompt，也就是用户提示词。我们平时在聊天框里输入的就是用户提示词，而系统提示词呢通常是聊天机器人内置的，用户一般不能直接修改。不过很多A应用也提供了一些功能，可以间接的影响系统提示词。比如在ChatGPT里面有一个叫做customize ChatGPT的功能，可以设定一些用户的个人偏好，这些信息最终就会成为系统提示词的一部分，从而影响ChatGPT的输出内容。这种通过系统提示词和用户提示词的组合来引导AI返回特定风格回复的做法，就叫做提示词工程prot engineering。当然了，提示词工程可不只是用来玩角色扮演的，它最核心的目的是通过一系列技巧来约束AI的行为，让它的回复更加稳定，减少错误和意外。下面我们就来介绍几种常见的技巧。比如说AI不太擅长处理数学问题，在让他解数学题的时候就比较容易做错，这个时候我们就可以要求他在回复前仔细的检查，确保他的答案是正确的。再比如说有时候AI会拒绝回答我们一些问题，这个时候你就可以在提示词中告诉AI这件事情的严重性。于是A。",
  "title": "",
  "author": "",
  "publish_date": "",
  "source": "Bilibili (via SnapAny + Paraformer)",
  "language": "zh-CN",
  "word_count": 1098,
  "extraction_method": "snapany_paraformer",
  "extraction_timestamp": "2025-11-14T18:04:32.479972",
  "batch_id": "20251114_095917",
  "link_id": "bili_req4",
  "error": null,
  "summary": {
    "transcript_summary": {
      "key_facts": [
        "提示词是用户发送给AI的输入内容，如‘你好’",
        "系统提示词用于设定AI的角色或行为规范，如‘你来扮演一个猫娘’",
        "用户提示词是用户在聊天框中输入的内容，由AI直接响应",
        "系统提示词通常由聊天机器人内置，用户一般无法直接修改",
        "ChatGPT的“Customize ChatGPT”功能可间接影响系统提示词",
        "提示词工程是通过组合系统提示词和用户提示词引导AI输出特定风格",
        "大语言模型最初主要作为聊天机器人使用，核心功能仍是对话",
        "提示词工程可用于约束AI行为，提升回复稳定性与准确性",
        "AI在处理数学问题时容易出错，可通过提示词要求其自我检查",
        "AI可能拒绝回答某些问题，可通过提示词强调问题的重要性"
      ],
      "key_opinions": [
        "人们倾向于用高级词汇掩盖内容的匮乏",
        "‘提示词工程’这一概念被过度包装，存在炒作嫌疑",
        "将角色设定与用户输入混在一起容易导致逻辑混乱",
        "‘上下文工程’宣称能超越提示词工程，但实际意义存疑",
        "当前AI流行词泛滥，缺乏清晰定义，易造成理解障碍",
        "AI在数学题上的错误率较高，需通过提示词进行纠正",
        "部分AI应用对敏感话题的回应机制不够透明",
        "提示词工程应更注重实用性而非形式化表达",
        "‘私域引流’等术语的使用已失去原始语义",
        "角色扮演类玩法虽有趣，但不应成为提示词设计的唯一方向"
      ],
      "key_datapoints": [
        "用户提示词是聊天框中输入的内容，由AI直接响应",
        "系统提示词通常不可由用户直接修改，但可通过设置间接影响",
        "提示词工程可减少AI回复中的错误和意外",
        "AI在解数学题时常出现错误，需通过提示词要求检查",
        "部分提示词可使AI改变对敏感问题的拒绝态度",
        "提示词工程可提升AI输出的一致性与可控性",
        "提示词中加入‘请仔细检查答案’可降低错误率",
        "系统提示词可包含用户偏好信息，如个性化设置",
        "提示词工程常用于控制AI的语气、风格与行为边界",
        "提示词中添加‘该问题非常重要’可提高AI回应意愿"
      ],
      "topic_areas": [
        "提示词定义",
        "系统提示词",
        "用户提示词",
        "提示词工程",
        "角色扮演应用",
        "AI行为控制",
        "数学问题处理",
        "敏感内容回应",
        "术语滥用现象",
        "AI交互优化"
      ],
      "word_count": 5,
      "total_markers": 30
    },
    "comments_summary": {},
    "created_at": "2025-11-14T18:06:20.565599",
    "model_used": "qwen-flash"
  }
}
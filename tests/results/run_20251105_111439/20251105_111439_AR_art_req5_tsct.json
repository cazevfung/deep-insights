{
  "success": true,
  "url": "https://lobste.rs/s/myrlhi/how_cursor_indexes_codebases_fast",
  "content": "Someone needs to write an MCP server which does this.\nCould someone help me understand how embedding of files are used after they’re generated?\nhttps://www.cursor.com/en/security has the better explanation of what's going on.\nCursor allows you to semantically index your codebase, which allows it to answer questions with the context of all of your code as well as write better code by referencing existing implementations. [...]\nAt inference time, we compute an embedding, let Turbopuffer do the nearest neighbor search, send back the obfuscated file path and line range to the client, and read those file chunks on the client locally. We then send those chunks back up to the server to answer the user's question.\nSo they're using the vector database to find code that's semantically similar to a user's question or, presumably, the code nearest to their cursor position when they generate a completion request.\nWhen you give cursor a prompt, it converts that into embeddings. Then it does a nearest neighboor search in the vector database. That returns a bunch of file paths & line numbers. It then grabs the contents from those file (on your local machine) and adds them to the LLM context.\nOne of the sources for this post is a comment on a forum by a Cursor founder from August 2023, so not clear how relevant it is to how Cursor works today: https://forum.cursor.com/t/codebase-indexing/36/2\nFrom that comment:\nThe embeddings are stored in a remote vector DB, along with starting / ending line numbers and the relative path to that file. None of your code is stored in our databases. It’s gone after the life of the request.\nThis raised my eyebrow a bit, because vector embeddings for predictable strings like code are very reversible: https://arxiv.org/abs/2310.06816\nUpdate: To their credit, they discuss on that issue in their security documentation:\nEmbedding reversal: academic work has shown that reversing embeddings is possible in some cases. Current attacks rely on having access to the model and embedding short strings into big vectors, which makes us believe that the attack would be somewhat difficult to do here. That said, it is definitely possible for an adversary who breaks into our vector database to learn things about the indexed codebases.",
  "title": "",
  "author": "",
  "publish_date": "",
  "source": "lobste.rs",
  "language": "auto",
  "word_count": 371,
  "extraction_method": "article_trafilatura",
  "extraction_timestamp": "2025-11-05T19:15:33.301909",
  "batch_id": "20251105_111439",
  "link_id": "art_req5",
  "error": null,
  "article_id": "1b19d36c6e40"
}
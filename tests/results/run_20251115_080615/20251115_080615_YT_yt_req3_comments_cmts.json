{
  "success": true,
  "video_id": "4GiqzUHD5AA",
  "url": "https://www.youtube.com/watch?v=4GiqzUHD5AA",
  "comments": [
    "I call it feature engineering for agents (arxiv), similar to what people used to do in classical ML to improve the input representation. Once you have a good representation of your data (by selecting, merging, mapping, etc.), even a light model can surpass a complex models (e.g, Logistic->xgboost). For agents, these features are the context. So, it is not only the goal (pilot using big LLM), it is the system (components besides the LLM). The idea is to develop an agent/workflow/app with the smallest feasible LLM so that you are forced to improve the system (cognitive architecture) first. Of course, LM can be replaced by any other engine.",
    "This is such an amazing resource!! I appreciate you compiling so many great supplementary content",
    "Amazing video on organizing context engineering assembling such great context content in this video. Thx!",
    "this is super interesting. the concept of trying to achieve a procedure with as small of an LLM as feasible by optimizing context window is certainly a very useful one. just yesterday an open source opanAI llm model came out that works locally on my 9070xt and i've been copying and pasting small contexts (it can only hold a very small context window before being overly saturated) and then iterating to try to identify how (at least one small) model interprets context. i think having this stuff available on youtube is huge because we need to be transparent about work and development in this cutting edge stuff to optimize use. one thing i've realized from my limited experience is that a hallucination of an llm can be leveraged using recursion to enhance a model's performance. I'm still in my infancy of my development and learning python before i get into more advanced things like RAG and proper context (prompt) engineering (on coursera) but this was a beautiful glimpse!",
    "As always dumbing down concepts and making them tangible with code, fantastic, thanks",
    "Nailed it, LangChain! Context engineering strategies are top-notch. Can't wait to see LangGraph in action.",
    "really cool stuff harrison! we use state object to manage state so super simple and intuitive to pass along only the required stuff to child graphs even fir example.",
    "Thanks is for this. I enjoyed the video and really appreciate the notes in Notion. I wonder how long until future LLMs (or the companies hosting them) manage the context for us. Offload context into a memory space, compress, etc a kind of active context management done behind the scenes. What do you think?",
    "Isolate seems like it should be a sub-category of Write. The only difference is whether the environment/sandbox is available for multi-agent access. Otherwise, this is a pretty well-reasoned take. Also, I would have appreciated some deeper insights into compressibility for various types of context information and how to think about the age of the context information and how that should affect compression strategies.",
    "We did all this already , didnâ€™t need a new term to build around. But it does help convey the point to those who come after.",
    "Its all so interesting, its possible to have multy language? ITA? thanks. admire your work.",
    "BTW I did not get the isolating part. Why isolate when you have summarized? If you were to anyway split, then summarize two times in a way that some summaries are going to one agent, some to other.",
    "Is it possible to insert a LLM as Judge before human feedback to validate the feedback request? And can the LLM as Judge feedback be fed back into memory within the same graph?",
    "Why did everyone jump on board to a different term for prompt engineering? This isn't new. It's just rebranded.",
    "We have learned nothing, maybe except that light model can be greather than large one",
    "Great video, is it possible to share the notion link shown in the video?",
    "Prompt engineering sounds too dumb so now people started calling it context engineering?",
    "The thing with that stuff is that they silently fail because they only work partially and never lives to the expectation. So loads of people follow the hype believing the one who published it (a) told the truth and (b) has real proof it works and as we have been seing over and over again, sometimes neither is true.",
    "this is super interesting. the concept of trying to achieve a procedure with as small of an LLM as feasible by optimizing context window is certainly a very useful one. just yesterday an open source opanAI llm model came out that works locally on my 9070xt and i've been copying and pasting small contexts (it can only hold a very small context window before being overly saturated) and then iterating to try to identify how (at least one small) model interprets context. i think having this stuff available on youtube is huge because we need to be transparent about work and development in this cutting edge stuff to optimize use. one thing i've realized from my limited experience is that a hallucination of an llm can be leveraged using recursion to enhance a model's performance. I'm still in my infancy of my development and learning python before i get into more advanced things like RAG and proper context (prompt) engineering (on coursera) but this was a beautiful glimpse! (PS: sorry this channel was just made my previous channel was only music)"
  ],
  "num_comments": 19,
  "title": "Context Engineering for Agents",
  "author": "LangChain",
  "publish_date": "",
  "source": "YouTube",
  "word_count": 893,
  "extraction_method": "youtube_comments",
  "extraction_timestamp": "2025-11-15T16:06:47.814986",
  "batch_id": "20251115_080615",
  "link_id": "yt_req3_comments",
  "error": null
}
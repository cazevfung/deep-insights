# Progress Tracking Improvement Plan

## Executive Summary

The current progress tracking system on the scraping page appears to be stuck at 0% because:
1. **Link status updates are not being persisted to database in real-time**
2. **Scraper progress callbacks are not connected to the backend/WebSocket system**
3. **WebSocket messages may not be sent frequently enough or at the right times**
4. **Frontend lacks detailed per-link progress information**
5. **No intermediate progress indicators during scraping operations**

This plan outlines a comprehensive solution to make progress tracking **real-time, informative, and user-friendly** - similar to how Cursor shows dynamic progress updates.

---

## Current Implementation Analysis

### Frontend (`ScrapingProgressPage.tsx`)
- âœ… Uses WebSocket via `useWebSocket` hook
- âœ… Calculates overall progress: `(completed + failed) / total * 100`
- âœ… Displays status badges (Success, Failed, In Progress, Total)
- âœ… Shows individual link list
- âŒ **No per-link detailed progress (stages, sub-steps)**
- âŒ **No intermediate progress during single link scraping**
- âŒ **No time estimates or ETA**
- âŒ **No visual indicators for active scraping operations**

### Backend WebSocket (`useWebSocket.ts`)
- âœ… Connects to `ws://localhost:8000/ws/${batchId}`
- âœ… Handles `scraping:status` messages for batch-level updates
- âœ… Handles `scraping:item_update` for individual link updates
- âŒ **May not be receiving frequent enough updates**
- âŒ **No per-link stage/progress information**

### Scrapers (`BaseScraper`, individual scrapers)
- âœ… Has `progress_callback` mechanism
- âœ… `_report_progress()` method exists
- âœ… Used in test scripts (`test_progress_tracking.py`)
- âŒ **NOT connected to backend/WebSocket system**
- âŒ **Progress callbacks are only used in CLI tests, not in workflow**

### Database/Storage
- âŒ **Link status may not be updated in real-time during scraping**
- âŒ **No intermediate progress storage**
- âŒ **Status updates likely only happen at completion/failure**

---

## Root Cause Analysis

**The Problem**: Progress shows 0% because:

1. **Disconnected Progress Pipeline**: Scrapers have `progress_callback` but it's not connected to the backend workflow system. Progress updates are only used in test scripts.

2. **No Real-time Database Updates**: Link status is probably only updated when a link completes or fails, not during intermediate stages.

3. **Missing WebSocket Broadcasts**: Even if scrapers report progress, there's no mechanism to broadcast these updates via WebSocket to the frontend.

4. **Insufficient Progress Data**: The frontend only receives final status (completed/failed), not intermediate progress information.

---

## Proposed Solution Architecture

### Goal
Make progress tracking **real-time, granular, and informative** - showing users exactly what's happening at every step, just like Cursor's progress indicators.

### Key Principles
1. **Real-time Updates**: Every significant event should trigger a WebSocket broadcast
2. **Granular Progress**: Show progress at multiple levels (batch â†’ link â†’ stage â†’ sub-step)
3. **Informative Messages**: Tell users what's happening right now, not just numbers
4. **Visual Feedback**: Use animations, colors, and indicators to show activity
5. **Time Awareness**: Show elapsed time, estimated time remaining
6. **Error Transparency**: Show errors immediately with context

---

## Implementation Plan

### Phase 1: Backend - Progress Tracking Infrastructure

#### 1.1 Database Schema Enhancement
Add progress tracking fields to Link model:
- `current_stage`: Current operation stage (e.g., "downloading", "transcribing")
- `stage_progress`: Progress within current stage (0.0-100.0)
- `overall_progress`: Overall progress for entire link (0.0-100.0)
- `status_message`: Human-readable status message
- `bytes_downloaded` / `total_bytes`: For download progress
- `started_at` / `updated_at` / `completed_at`: Timestamps

#### 1.2 Progress Service (NEW)
Create `backend/app/services/progress_service.py`:
- Centralized service for progress updates
- Updates database and broadcasts to WebSocket
- Tracks batch-level statistics

#### 1.3 Scraper Integration
Modify scraping workflow to:
- Create progress callbacks connected to ProgressService
- Pass callbacks to scrapers when starting extraction
- Ensure scrapers call callbacks at key stages

#### 1.4 Enhanced Scraper Reporting
Update scrapers to report progress at appropriate points:
- **Bilibili**: loading â†’ downloading (0-50%) â†’ converting (50-60%) â†’ uploading (60-70%) â†’ transcribing (70-95%) â†’ completed
- **YouTube**: loading â†’ extracting â†’ completed
- **Articles**: loading â†’ extracting â†’ completed

---

### Phase 2: Frontend - Enhanced UI Components

#### 2.1 Enhanced Progress Display
- **Per-link progress bars** with stage information
- **Stage indicators** showing current operation
- **Active indicators** (spinning/animated) for active links
- **Status messages** in real-time
- **Time information** (elapsed, ETA)

#### 2.2 Store Enhancement
Extend `ScrapingItem` interface with:
- `currentStage`, `stageProgress`, `overallProgress`
- `statusMessage`, `startedAt`, `completedAt`
- Metadata (bytes, word count, etc.)

#### 2.3 WebSocket Handler
Add handler for `scraping:item_progress` messages to update per-link progress in real-time.

---

### Phase 3: API Endpoints

#### 3.1 Batch Status Endpoint
Add `GET /api/batches/{batch_id}/status` for polling fallback:
- Returns current batch status with all links
- Includes detailed progress information
- Useful if WebSocket connection fails

---

### Phase 4: Time Estimation

#### 4.1 Time Tracking
- Track time for each stage per source type
- Calculate ETA based on historical averages
- Display elapsed time and estimated remaining time

---

## Expected User Experience

### Before (Current State)
```
æ€»ä½“è¿›åº¦: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0%

æˆåŠŸ: 0  å¤±è´¥: 0  è¿›è¡Œä¸­: 0  æ€»è®¡: 5

[Static list with no progress information]
```

### After (Improved)
```
æ€»ä½“è¿›åº¦: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 60%

æˆåŠŸ: 3  å¤±è´¥: 0  è¿›è¡Œä¸­: 2  æ€»è®¡: 5

é“¾æŽ¥åˆ—è¡¨:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
[âœ“] https://youtube.com/watch?v=...
    âœ… å·²å®Œæˆ | è¯æ•°: 1,234 | ç”¨æ—¶: 2åˆ†30ç§’

[âŸ³] https://bilibili.com/video/BV...
    ðŸ”„ è¿›è¡Œä¸­ | æ­£åœ¨è½¬å½•ä¸­... 85%
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 85%
    å½“å‰é˜¶æ®µ: è½¬å½•ä¸­ 85% | é¢„è®¡å‰©ä½™: 1åˆ†15ç§’

[âŸ³] https://example.com/article/...
    ðŸ”„ è¿›è¡Œä¸­ | æ­£åœ¨æå–å†…å®¹... 30%
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 30%
    å½“å‰é˜¶æ®µ: æå–ä¸­ 30%
```

---

## Implementation Checklist

### Backend
- [ ] Add progress tracking fields to Link model
- [ ] Create ProgressService for centralized progress tracking
- [ ] Integrate scraper progress callbacks with ProgressService
- [ ] Enhance scrapers to report progress at key stages
- [ ] Ensure WebSocket broadcasts on progress updates
- [ ] Add batch status API endpoint

### Frontend
- [ ] Extend ScrapingItem interface with progress fields
- [ ] Add WebSocket handler for `scraping:item_progress`
- [ ] Create enhanced link progress item component
- [ ] Add per-link progress bars with stage info
- [ ] Add activity indicators (spinning/pulsing)
- [ ] Display status messages and time information
- [ ] Add polling fallback if WebSocket unavailable

### Testing
- [ ] Test WebSocket connection and message delivery
- [ ] Test progress updates at various stages
- [ ] Test with multiple links in parallel
- [ ] Test error scenarios
- [ ] Test UI responsiveness

---

## Performance Considerations

1. **WebSocket Message Frequency**: Update on significant events (>5% progress change), throttle to max 2-3 updates/sec per link
2. **Database Updates**: Update only changed fields, index `batch_id` and `status`
3. **Frontend Rendering**: Use React.memo, update only changed items, virtualize long lists

---

## Conclusion

This plan addresses the core issue by:
1. **Connecting scraper progress callbacks to backend/WebSocket system**
2. **Persisting progress updates to database in real-time**
3. **Broadcasting detailed progress updates via WebSocket**
4. **Enhancing frontend to display rich progress information**
5. **Adding visual feedback and activity indicators**

Result: A **responsive, informative progress tracking system** that gives users confidence the system is working, showing exactly what's happening at every step.

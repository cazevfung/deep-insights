## 1.6 版本发布

### 亮点

- **AI 推理过程可视化** - 新增推理（thinking）模式支持，实时显示 AI 的思考过程。用户现在可以查看 AI 在研究过程中的推理链条和思考内容，提升研究过程的可理解性和透明度。支持 Markdown 格式渲染，提供清晰的推理展示。

- **流式摘要显示优化** - 改进 `StreamSummaryView` 组件，优化流式摘要的显示逻辑。推理内容独立显示，摘要内容按类型分组统计，避免重复计数，提供更准确和清晰的进度反馈。

- **阶段化模型配置** - 新增阶段化模型配置系统，支持为不同研究阶段（Phase 0.5、1、2、3、4）配置不同的 AI 模型和推理模式。Phase 0 使用快速模型（qwen-flash），研究阶段使用支持推理的模型（qwen3-30b-a3b-thinking、kimi-k2-thinking），优化性能和成本平衡。

- **增强的流式处理** - 改进流式数据处理机制，优化推理内容的实时显示。支持推理内容的流式传输和渲染，提供更好的用户体验和实时反馈。

### 新增功能

#### AI 推理可视化
- **推理模式支持** - 各研究阶段支持启用推理（thinking）模式
  - Phase 0.5: 使用 `qwen3-30b-a3b-thinking-2507` 模型，启用推理模式
  - Phase 1: 使用 `kimi-k2-thinking` 模型，启用推理模式
  - Phase 2: 使用 `kimi-k2-thinking` 模型，启用推理模式
  - Phase 3: 使用 `qwen3-30b-a3b-thinking-2507` 模型，启用推理模式
  - Phase 4: 使用 `qwen3-30b-a3b-thinking-2507` 模型，启用推理模式
  - Phase 0: 使用 `qwen-flash` 模型，禁用推理模式（快速摘要）

- **推理内容显示** - `StreamSummaryView` 组件增强
  - 推理内容独立显示，不与其他摘要内容混合
  - 支持 Markdown 格式渲染（标题、段落、列表等）
  - 实时流式显示推理过程
  - 显示时间戳，便于追踪推理时间线
  - 优化的小字体样式，确保内容可读性

- **推理内容过滤** - 智能过滤和显示逻辑
  - 仅显示有内容的推理项或正在流式传输的推理项
  - 自动过滤空内容，避免显示空白推理项
  - 支持流式状态检测，实时显示思考过程

#### 流式摘要优化
- **摘要分组显示** - 改进摘要内容的分组逻辑
  - 按描述/类型分组显示摘要进度
  - 转录和评论摘要按 `link_id` 去重计数，避免重复统计
  - 区分进行中和已完成状态，提供清晰的进度反馈
  - 显示最后更新时间，便于追踪进度

- **时间线合并** - 统一的时间线显示
  - 推理内容和摘要内容按时间顺序合并显示
  - 保持时间线的连续性和逻辑性
  - 支持时间戳排序，确保正确的显示顺序

#### 配置系统增强
- **阶段化模型配置** - `config.yaml` 新增阶段配置
  ```yaml
  research:
    phases:
      phase0:
        model: "qwen-flash"
        enable_thinking: false
        stream: false
      phase0_5:
        model: "qwen3-30b-a3b-thinking-2507"
        enable_thinking: true
        stream: true
      phase1:
        model: "kimi-k2-thinking"
        enable_thinking: true
        stream: true
      phase2:
        model: "kimi-k2-thinking"
        enable_thinking: true
        stream: true
      phase3:
        model: "qwen3-30b-a3b-thinking-2507"
        enable_thinking: true
        stream: true
      phase4:
        model: "qwen3-30b-a3b-thinking-2507"
        enable_thinking: true
        stream: true
  ```

- **动态配置加载** - `BasePhase` 类支持动态加载阶段配置
  - 自动根据阶段类名加载对应配置
  - 支持模型、推理模式、流式传输的独立配置
  - 提供配置加载日志，便于调试和追踪

### 修复与改进

#### UI/UX 改进
- **推理内容渲染** - 优化推理内容的 Markdown 渲染
  - 自定义 Markdown 组件样式，适配小字体显示
  - 优化标题、段落、列表的显示效果
  - 改进文本换行和间距，提升可读性
  - 支持代码块、强调文本等 Markdown 元素

- **摘要统计准确性** - 修复摘要计数重复问题
  - 转录摘要按 `link_id` 去重，避免同一链接的多个流式项重复计数
  - 评论摘要按 `link_id` 去重，确保统计准确性
  - 其他类型摘要保持原有计数逻辑

- **空状态处理** - 改进空状态显示
  - 当没有消息时显示友好的提示信息
  - 优化空状态的视觉设计

#### 性能优化
- **流式处理优化** - 改进流式数据处理性能
  - 优化推理内容的过滤逻辑，减少不必要的渲染
  - 改进时间线合并算法，提升排序效率
  - 减少不必要的状态更新，降低重渲染频率

- **配置加载优化** - 优化配置加载机制
  - 缓存阶段配置，避免重复加载
  - 提供配置加载错误处理，确保系统稳定性

#### 代码质量
- **组件模块化** - 改进 `StreamSummaryView` 组件结构
  - 提取 `generateProcessDescription` 辅助函数
  - 优化 `normalizeListChildren` 函数，改进列表渲染
  - 改进类型定义，提升类型安全性

- **日志和调试** - 增强调试支持
  - 添加推理项过滤的调试日志
  - 添加时间线合并的调试日志
  - 改进错误处理和异常捕获

### 依赖更新

#### 前端依赖
- 无需新增依赖，使用现有 React Markdown 库（react-markdown）
- Tailwind CSS 配置无需修改

#### 后端依赖
- 无需新增依赖，使用现有基础设施
- 支持新的推理模型（qwen3-30b-a3b-thinking-2507、kimi-k2-thinking）

#### 配置更新
- 新增 `research.phases.*` 配置组，支持阶段化模型配置
- 所有配置向后兼容，未配置的阶段使用默认值

### 迁移指南

#### 从 v1.5 升级到 v1.6

1. **更新依赖**
   ```bash
   pip install -r requirements.txt --upgrade
   cd client && npm install
   ```

2. **更新配置文件（可选）**
   - 如需自定义阶段模型配置，可在 `config.yaml` 中添加 `research.phases.*` 配置组
   - 默认配置已优化，大多数用户无需修改
   - 如需启用推理模式，确保配置了支持推理的模型

3. **验证新功能**
   - 创建新的研究会话，验证推理内容的显示
   - 检查各阶段的模型配置是否正确
   - 验证流式摘要的显示是否正常

4. **测试推理模式**
   - 确认 Phase 0.5、1、2、3、4 阶段显示推理内容
   - 验证推理内容的 Markdown 渲染是否正常
   - 检查推理内容的时间线显示是否正确

### 使用示例

#### 查看 AI 推理过程

**在研究过程中查看推理：**
1. 启动研究会话，进入研究阶段
2. 在流式摘要视图中，推理内容会独立显示
3. 推理内容支持 Markdown 格式，包括标题、段落、列表等
4. 每个推理项显示时间戳，便于追踪时间线

**推理内容示例：**
- 显示 AI 的思考过程和分析逻辑
- 展示推理链条和论证过程
- 提供研究决策的透明度

#### 阶段化模型配置

**自定义阶段模型：**
```yaml
research:
  phases:
    phase1:
      model: "your-preferred-model"
      enable_thinking: true
      stream: true
```

**配置说明：**
- `model`: 指定该阶段使用的 AI 模型
- `enable_thinking`: 是否启用推理模式（需要模型支持）
- `stream`: 是否启用流式传输

### 已知问题

- **推理内容长度** - 某些模型的推理内容可能较长，建议在配置中适当调整显示区域大小
- **模型兼容性** - 推理模式需要模型支持，某些模型可能不支持推理模式，系统会自动降级
- **性能影响** - 启用推理模式可能会增加 API 调用时间和成本，建议根据需求合理配置

### 技术细节

#### 推理模式工作原理

**配置加载流程：**
1. **阶段识别** - `BasePhase` 类根据类名识别阶段类型
2. **配置加载** - 从 `config.yaml` 加载对应阶段的配置
3. **模型初始化** - 使用配置的模型和参数初始化客户端
4. **推理启用** - 根据 `enable_thinking` 配置启用推理模式
5. **流式传输** - 根据 `stream` 配置启用流式传输

**推理内容显示流程：**
1. **内容接收** - 从 WebSocket 接收推理内容
2. **类型识别** - 识别为 `reasoning` 类型的消息
3. **内容过滤** - 过滤空内容和无效内容
4. **Markdown 渲染** - 使用 `react-markdown` 渲染 Markdown 内容
5. **时间线合并** - 与摘要内容按时间顺序合并显示

#### 摘要去重逻辑

**转录/评论摘要去重：**
```typescript
// 按 link_id 去重，避免重复计数
if (isTranscriptOrCommentsSummary && linkId) {
  if (!group.completedLinkIds) {
    group.completedLinkIds = new Set<string>()
  }
  if (!group.completedLinkIds.has(linkId)) {
    group.completedLinkIds.add(linkId)
    group.completed++
  }
}
```

**其他类型摘要：**
- 保持原有计数逻辑，按流式项数量统计
- 不进行去重处理

#### 时间线合并算法

**合并流程：**
1. **收集推理项** - 收集所有推理类型的消息项
2. **收集摘要组** - 收集所有分组的摘要项
3. **时间戳提取** - 提取每个项的时间戳
4. **排序合并** - 按时间戳排序，合并为统一时间线
5. **渲染显示** - 按时间顺序渲染显示

### 致谢

感谢所有贡献者对 v1.6 版本的贡献，特别是在 AI 推理过程可视化、流式摘要显示优化和阶段化模型配置方面的努力。

---

**发布日期:** 2025-01-18  
**版本号:** v1.6.0  
**最低 Python 版本:** 3.9+  
**最低 Node.js 版本:** 18+

